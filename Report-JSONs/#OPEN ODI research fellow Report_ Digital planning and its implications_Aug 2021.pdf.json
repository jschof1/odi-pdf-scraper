{"numpages":43,"numrender":43,"info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"#OPEN ODI research fellow Report: Digital planning and its implications_Aug 2021","Producer":"Skia/PDF m109 Google Docs Renderer"},"metadata":null,"text":"\n\n\n\n1\nAbout\nThis report was produced as part of the ODI research fellow scheme. Its author is Dr\nSue Chadwick, a Strategic Planning Advisor at Pinsent Masons LLP, with\ncontributions from Jeni Tennison, ODI.\nIf you want to share feedback by email or would like to get in touch, contact Sue at\nsue.chadwick@pinsentmasons.com.\nIf you would like to learn more about the ODI research fellow scheme, please visit the\ninformation and application page, or contact us atfellowships@theodi.org.\n1\nTitle page quotation is from “In Memory of Sigmund Freud”FromAnother Timeby W. H. Auden,\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 20212\n\nContents\nIntroduction5\n1 Reconceiving land and development.7\nDigital twins8\nDealing with data: current mechanisms9\nDigital Planning – beyond the rhetoric10\nThe need for change – and where to start11\nSection 1 Summary13\n2 Automation of the planning function14\nPlanning decisions14\nAutomation and planning15\nAdministrative process15\nAssessing Environmental Impacts16\nAutomation: barriers to adoption17\nCurrent responses: policy19\nCurrent responses in law21\nAI governance: next steps...21\nSection 2 summary23\n3 Ethical planning in a digital world25\nEngagement25\nEqualities28\nHuman rights30\nEthics31\nDigital Ethics32\nSection 3 summary33\nConclusion35\nSection 2 Appendix 1: AI Strategy36\nSection 2 Appendix 2: AI procurement checklist39\nSection 2 Appendix 3: Report on adoption of chatbot41\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 20213\n\nIntroduction\nThe ‘fourth industrial revolution’, characterised by exponential developments in\nemerging technologies, has been described as a ‘newchapter in human\ndevelopment’ by the World Economic Forum. As divisionsbetween the digital and\nphysical worlds become increasingly liminal, the built environment has a digital\nexistence which precedes, enmeshes with and survives the physical.\nData is the fuel – and the product – of this revolution. When a new development is\nproposed, data offers powerful new ways of assessing and mitigating its impacts, of\nengaging with the current and future populations affected by it and the opportunity to\nuse the development as a source of rich data repositories to facilitate informed and\nintelligent urban management.\nThe revolution represents an existential challenge to the way that land is currently\nplanned and developments are managed, while data presents a range of new and\ncomplex risks, especially when it is used as source material for machine learning (ML)\nalgorithms. The current legal rules and procedural norms will need to adapt into an\nevolved, agile governance infrastructure.\nThis paper explores three areas of established planning law and practice, in each\ncase examining how they are disrupted by emerging technology and how regulation\nand procedure should change to adapt. It argues that we should:\n●\nreconceptualise the current definition of land in planning legislation to include its\ndigital counterparts and begin to assess digital as well as environmental impacts\nand benefits.\n●\nrecognise the potential for Artificial Intelligence (AI) to replace an increasing\namount of the human function in the decision-making process and build in\nappropriate levels of risk assessment and mitigation.\n●\nexpand current ethical norms to include emerging concepts of digital intrusion,\ndigital discrimination, algorithmic bias and data ethics.\nIn the 1902 bookGarden Cities of Tomorrow, EbeneezerHoward recognised that his\nradical re-visioning of urban development could only be achieved through ‘the hearty\nco-operation of men and of women experienced in very numerous departments of\nhuman activity’. This paper also calls for everyone involved in the modern planning\nsystem – local and central government, applicants, agencies, institutions and\nstakeholders – to engage with the required change.\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 20214\n\n1 Reconceiving land and\ndevelopment.\nAt a fundamental level, planning is about land – what is built on it and how it is used.\nPlanning law formalises these core concerns through a regulatory system that defines\nboth ‘land’ and ‘development’ and requires formal consent for development to\nproceed. The emergence of a digital world challenges these fundamental principles.\nThis section begins by exploring current definitions of land and development in the\nplanning system and how they should be reconceived to include digital notions of\nboth. It then considers practical changes that could be made to existing regulations\nand planning application processes to encompass digital aspects of land and\ndevelopment.\nThe current definitions of land and development are contained in theTown and\nCountry Planning Act 1990. They are fundamental tothe planning system because\nanything that comes within the definition of ‘development’ requires consent; the\ndefinitions mark the point where what an individual does with land is a matter of\npublic interest and state control. Section 55 of that act defines development as ‘the\ncarrying out of building, engineering, mining or other operations in, on, over or under\nland, or the making of any material change in the use of any buildings or other land’.\nSection 336 defines land as ‘any corporeal hereditament, including a building’, so\nland as defined by the 1990 Act as an exclusively physical entity.\nThirty years after this legislation was drafted, and more than 70 years after the\nconcepts of land and development were first defined, both land and buildings now\nhave a digital identity that precedes, enmeshes with, and survives the physical. Land\nis no longer just a ‘corporeal hereditament’, but also an increasingly dynamic store of\ndata sourced and shared in real time.\nAs last year’s reviewfrom the Centre for SustainableInfrastructure and Construction\nnoted, we are moving from a concept of buildings as ‘static inanimate systems’ to\ncombinations of technology and data analytics that will ‘bring the building to life’. A\nrecent paperby the Centre for Digital Built Britain(CDBB)proposes that our current\nconceptions of land should expand to include a ‘cyber physical layer’. TheConnected\nPlaces Catapult advocates the notion of ‘Space as a Service’ (SPaaS)in place of\ntraditional concepts of ownership and the UK government is exploringthe potential\nfor regulating Mobility as a Service (MaaS)as partof its transport review – these are\njust two examples of a transition from acquisition of an entity or service to more of a\nsubscription model where use and experience are integrated and monetised into on\ndemand service.\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 20215\n\nBuildings are also developing capacity for autonomous adjustment and reporting: the\nAlan Turing Instituteis working on abridgeto explore the potential for ‘infrastructure\nto act as living objects’ and University College London has recently completed the\nPearl Building, an experimental ‘Person EnvironmentActivity Research Laboratory’\nthat can test the impact of environmental change on human experience.\nData connects land and buildings with each other; with the infrastructure that\nservices both; with the pavements, streets and roads that enclose them; with the\nbiophysical environment that surround them; and with the humans who inhabit and\nuse it all. This digital proliferation challenges the planning profession to consider new\nways of thinking about both land and development, beginning with an\nacknowledgement of digital twins.\nDigital twins\nA digital twin has beendefinedby theRoyal Instituteof Chartered Surveyors(RICS)\nas ‘A 3D digital model connected in real time to a real physical asset which could be a\nbuilding, group of buildings, a piece of land or an infrastructure system’. As\nrecognisedby CDBB, these twins can be static modelsused for longer term strategic\nplanning or dynamic models, with live data flows and feedback.\nAs soon as any aspect of development has data connected with it, its digital twin is\nconceived. All development proposals are shadowed by their digital equivalents,\nwhether this be the outline proposal used for illustrative purposes in a pre-application\ndiscussion or a BIM level 3 model where data is shared, collected and stored as a\nsingle open source.\nAt the planning stage the twin is embryonic and will include:\n●\ndiscussions between the applicant and the local authority\n●\nenvironmental information from initial studies\n●\nlegal information on the ownership rights and restrictions relevant to the land,\nand\n●\nsocial information from initial engagement exercises.\nAs the proposals mature through the submission, consultation and decision stages,\nthe associated data also matures and proliferates to include construction plans,\nenvironmental assessments, design papers and consultation responses. Legal\ndocumentation, from subsequent appeals or court actions, can also be added to the\nstore of data. As such, the proposal has an evolved and complex digital identity well\nbefore anything substantial happens to the land itself.\nOnce the concept of land includes its digital twin, then the notion of land as a fixed\nphysical entity also evolves into one where the material elements combine with\nrelated data to provide a digital/real hybrid where land is still the physical site on\nwhich buildings are constructed but is also part of a complex, interactive supply chain\nof goods and services. The resulting digital environment mirrors the physical forms,\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 20216\n\nwith data stored and shared by individuals, authorities, and businesses. This is where\nthe digital life of the development becomes useful for strategic planning as it\ngenerates connective possibilities allowing data to be shared with other digital twins –\nof buildings, infrastructure and spaces.\nDealing with data: current mechanisms\nAs the planning system adjusts to new notions of land, it becomes increasingly clear\nthat the current law needs to recognise that land has a digital identity, and to legislate\nfor it.\nFor most property practitioners, the primary source of regulation is the General Data\nProtection Regulation, (GDPR) transposed into UK law through the Data Protection\nAct 2018. A guideproduced jointly by the Local GovernmentAssociation and the\nPlanning Advisory Servicerecognised that planningapplications could include\npersonal and special category data, that decision making could involve data\nprocessing, and recommended putting ‘appropriate measures and procedures in\nplace’ for data management in this context. Local authorities must also consider their\ndata sharing obligations under the Freedom of Information Act 2000 (FOIA), the\nINSPIRE regulations, and the Re-use of Public Sector Information Regulations 2015.\nThere is also information regulation specific to the planning process:\n●\nThe 2015Development Management Procedure Orderregulatesa wide range\nof issues relevant to the administration of planning applications and this\nincludes requirements relevant to information including consultation\nrequirements in Article 3, 4, and 18–21, publicity requirements in Article\n13–16 and the requirement in Article 40 to establish and maintain a public\nregister of applications and decisions.\n●\nTheEnvironmental Information Regulations2004 givethe public a general\nright of access to environmental information. Environmental information is\ndefined very broadly; according to theInformationCommissioner's Office\n(ICO) the term should be interpreted to include genetically modified\norganisms, drawings, sound recordings and CCTV coverage, and there is\nalready onecasewhere a film about the Lea ValleyPark was ruled to be\nenvironmental information and required to be disclosed.\n●\nTheLocal Government Act 1972regulates local authoritydecision making,\nincluding planning committees. Section 100A-H regulates access to\ninformation in the committee process including access to agendas and\nreports, disclosure of background papers and retention of documents for\ninspection. Compliance is essential to the planning process: in a recent case\nthe judge ruled that non-disclosure of background materials amounted to\n‘egregious unfairness’and the permission was quashed.\nFor now these separate regimes – all dealing with data in one way or another – have\nbeen reasonably effective in ensuring that information about planning applications\nwas publicly available and that decisions were made in a transparent way. However,\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 20217\n\nthey all predate the digital revolution and many are based on analogue notions, such\nas paper notices and physical presence at meetings.\nThe Covid-19 pandemic exposed the weaknesses of this system. A range of changes\nwere introduced including electronic publication of notices, electronic planning\nregisters and digital consultation and publicity. However, these changes simply\nretrofitted the existing system to facilitate digital rather than analogue compliance,\nalmost all of them were temporary and there is no indication yet that there is or will be\na digital by default approach in the future.\nDigital Planning – beyond the rhetoric\nThe planning system operates in a world where there is an exponential expansion\nboth in the amount of data available and the technological capacity and commercial\nincentive to grab, share, manipulate and monetise it. The government is close to\nadopting aNational Data Strategy(NDS), the G7MinisterialDeclarationincluded\naspirations around an international roadmap for co-operation on data free flow with\ntrust, and the National Infrastructure Commission has recentlyreportedon the public\nbenefits of data sharing.\nHowever, the planning system has not even formally recognised the existence of the\ndigital twin, and its regulatory foundations are built on a definition of land that\nexcludes all but its physical manifestations. As described above, there are several\nexisting regulatory requirements relevant to data and information, but they are not\nintegrated, and do not anticipate or accommodate a digital world.\nThere are calls for change. The Royal Town Planning Institute (RTPI)Digital Planning\nManifestocalls for a standardised digital processesfor planning applications and last\nyear’s ‘Living with beauty’report proposed digitisationof data entry and the\nintroduction of digital building passports. The 2020 planning white paper, ‘Planning\nfor the future’, encouraged local authorities to usedigital engagement tools, draft\nmachine-readable policies, rely on core datasets, automate processes and work with\nspecialists on adopting new software. In November 2020, the Scottish government\npublished the firstdigital strategy for planning,‘Transforming places together’, with\nmissions including an end-to-end digital planning experience.\nThere are also some tools emerging that could help to implement changes. The Data\nStandards Authority has published standards and guidanceon how to improve data\nsharing across government, the CDBB has publishedanInformation Management\nFrameworkincluding approved formats for open data;and the emerging NDS\nproposes standard data formats, data sharing and data management based on an\n‘open by default’ principle. TheBuilding Safety Billhas just been introduced to\nparliament (July 2021) and includes a requirement for a digital register – described as\na golden thread – of information to be established and maintained for all new\nbuildings above a certain height, with the planning consent process identified as\n‘Gateway One’ in a digital register of fire safety documentation and compliance\nprocesses.\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 20218\n\nThe regulatory landscape for data is also changing. Thegovernment's response to\nthe Smart Data Reviewproposes legislation to ‘mandateindustry involvement’ in a\nrange of industry sectors;the government’s responseto the consultation on the NDS\npoints to a ‘bold new approach’and new data partnerships;and theTaskforce on\nInnovation Growth and Regulatory Reform reportrecommendsreplacing the GDPR\nwith a Framework of Citizen Data Rights.\nIn the meantime, actual change across the planning sector has been slow to\nnegligible. The planning white paper introduced a discourse of digitisation, but the\ngovernment has not engaged with the practical complexities of integrating digitalised\nprocesses with existing data protection regimes; the complexities and risks of\nautomated processes; or even prescribed a data standard. A reportby CDDBfound\nthat BIM was not well-understood by local authorities and that the benefits of\nadoption were perceived as not justifying the costs. Another reportby the\nParliamentary Committee on Housing Communities and Local Governmentstated\nthat though the system was seen as 'antiquated’ they recommended continuation of\npaper-based engagement as the online Planning Portal needed updating and there\nwere deficits in access to digital skills and infrastructure.\nThe need for change – and where to start\nEveryone involved in the modern planning system shares some of the responsibility to\nexpand and adapt current processes so they are fit for purpose in a digital future.\nDigital impacts and benefits should be viewed as core planning considerations\nalongside traditional concerns such as design and infrastructure.\n“\nEveryone involved in the modern planning\nsystem shares some of the responsibility to\nexpand and adapt current processes so they\nare fit for purpose in a digital future\nThe government must lead the way because it is the only stakeholder with the ability\nto make legislation, adopt guidance and enter into agreements that create instant\nchange and apply to everyone. A recent example of effective use of these powers is\nits agreementwith Ordnance Surveyallowing open publicaccess to every Unique\nProperty Reference Number (UPRN) and Unique Street Reference Number (USRN) in\nBritain. There are a number of future changes that government could sponsor or\nsupport that would make a significant difference to the implementation of digital\nplanning by the planning profession:\n●\nPrimary legislation to amend the current definition of land to include its digital\nequivalents or promote a definition of ‘the digital twin’.\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 20219\n\n●\nThe Covid-related changes to the Development Management Procedure\nOrder should be made permanent, ensuring that a wide range of planning\nprocesses are ‘digital by default’, including publication of notices, and\nvalidating e-consultation as the primary method for engagement.\n●\nThe government could mandate use of UPRNs when planning applications\nare submitted alongside clarity on data standards, either by introducing and\nmandating its own standard as it has forbrownfielddata, or validating\nexisting industry standards such as those promoted byRICS.\n●\nDigital impacts and benefits should be formally recognised as a material\nconsideration, at least for major developments. This would require the\napplicant to consider how data is generated from the development, how it is\nused and shared, and what the impacts are both on the new and existing\ncommunity. This would then facilitate relevant conditions and obligations\nrequiring digital benefits such as 5G infrastructure, specific levels of\nconnectivity and even mandate public data sharing.\nLocal authorities could also do more to bring forward digital planning. Last year’s\nplanning White Paperdetailed existing deficienciesincluding a legacy of paper\ndocuments that could not be machine read, a reliance on document management\nand storage rather than process transformation, and a lack of data standards and\nschemas. The UK government has not yet responded to the White Paper consultation\nnor is there any sign that it will follow the Scottish government in issuing\ndigital-specific planning guidance for local authorities. In the absence of central\ngovernment direction, there are simple changes that all local authorities could make,\nany one of which which would be relatively easy to implement while making\nsignificant steps towards digital planning systems:\n●\nDevelopment of digital planning policies at strategic levels.\n●\nRequiring electronic submissions to be submitted in accordance with\napproved data standards. Local authorities are comfortable with a range of\n‘Registered Providers’ when it comes to affordable housing; a similar\napproach could be taken to a range of industry-approved standards including\nthe RICS standard mentioned above or the Planning Inspectorate standards\nset out in Appendix One of itsProcedural Guideforplanning appeals.\n●\nIntroducing training on digital planning for local authority officers and\nmembers.\n●\nCollaborating with other local authorities on the creation and maintenance of\ndatastores and exploring opportunities for collaborative data sharing.\nImplementing digital planning is best led by the government and requires a significant\nculture change within local authorities but it also depends on involvement from\neveryone involved in the system: planners, lawyers, local authorities, and applicants.\nBut change needs to be immediate and incremental and this means that applicants,\nagents and lawyers can play a part in building consideration of digital impacts and\nbenefits into every stage of the process.\nAs soon as a development is proposed, there should be a review of the digital\nlandscape, alongside surveys of the physical topography and investigation of legal\ntitle. This initial audit would register the identity of the data suppliers, the types of\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202110\n\ndata to be disclosed and identify special categories of data, such as that disclosable\nas environmental information or needed as a background paper for any committee\nreport. It would also identify areas of potential future risk (such as embedded\nbiometric technologies) and ways that the risk could be mitigated with embedded\nsafeguards and robust consent processes. The digital benefits of the proposal could\nalso be identified, such as the creation of real-time environmental information on air\nquality or transport impacts and the potential for this data to contribute to national or\nlocal data stores, or the provision of enhanced connectivity for disadvantaged\npopulations. The impacts and the benefits would then be available for consideration\nalongside the physical changes, integrating the physical and digital elements of\ndevelopment within normal consent processes.\nSection 1 Summary\nWhen Ebeneezer Howard produced what some still see as an idealvision of the\ngarden cityhe referred to the town and country astwo magnets, each with their own\nbenefits and the garden city as an ideal combination of both. It is time for the\nplanning system to realise that we are again situated between two magnets – the\ndigital and the physical – and that planning can benefit from a combination of both.\nHardwiring digital awareness into every stage of the planning process could lead to\nincreased community participation, an enhanced appreciation of development\nbenefits and risks and improved connectivity between homes and their wider\nenvironment.\nIn‘GardenCitiesofTo-morrow’Howardreflectedthat‘therehaveinthepastbeen\ninventionsanddiscoveriesonthemakingofwhichsocietyhassuddenlyleaped\nupwardtoanewandhigherplaneofexistence’.AIoffersthesametransformational\nbenefitstomodernplanningassteampowerdidforHoward,butisprovingequally\ntrickyto‘harnesstothetaskitwasfittedtoaccomplish’.Thenextpartofthispaper\nlooksathowthispowerfulandcomplextechnologycouldplayitspartinadigital\nplanning system.\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202111\n\n2 Automation of the\nplanning function\nThe year 1947 established the foundations of the modern planning system and also\nwitnessed the quiet dawn of a digital age. TheTownand Country Planning Act 1947\nestablished a legal definition of development and the requirement for all works or\nuses to be subject to a particular decision-making process carried out by a public\nbody. As details of that legislation were being finalised, Alan Turing was working on\nanother kind of decision-making function: the Automatic Computing Engine. As he\npredicted, the power of those machines and the pervasive nature of the technology\nmeans that they are beginning to replace the human function in areas. As a recent\nHouse of Lords reportrecognises, AI has the potentialto ‘lead to more personalised\nservices; and provide solutions to some of the most complex and challenging policy\nproblems’.\nThe UK government’splanning white paperwas the firstformal recognition that AI\nand ML should have a role in the planning system too. AI will not wholly replace the\nhuman in planning decisions, but it will perform an increasing number of previously\nhuman functions; this part of the paper considers its scope and limits.\nThe white paper summarises the existing law on how planning decisions are made,\nand briefly explains the concepts of AI and ML. It explores the extent to which\nautomation could replace the human function in planning processes and the legal and\nethical implications of this shift. It ends with some concrete proposals on how the\ncurrent procedural context can and should adapt to an increasingly automated future.\nPlanning decisions\nThe legal test for making planning decisions is a conflation of section 70(2) of the\nTown and Country Planning Act 1990and Section 38(6)of thePlanning and\nCompulsory Purchase Act 2004. Essentially, the decisionmaker is required by law to\nconsider the extent to which the development proposal accords with local policies,\nand also its particular merits, and consider both in coming to a balanced decision. In\nsome circumstances the decision maker must apply a presumption in favour of\nsustainable development; or specific legal tests when listed buildings and\nconservation areas are involved, and other ‘material considerations’ include\nEnvironmental Impact (EIA) or Habitats Impact Assessment (HA); and designations\nthat apply to land of particular value such as Sites of Special Scientific Interest, Areas\nof Outstanding Natural Beauty and green belt.\nThese decisions can be challenged in two ways. If the application is refused, an\nappeal can be made to the Planning Inspectorate who will reconsider the proposal on\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202112\n\nits merits. Where a decision appears to be legally defective, any party with standing\ncan apply to the courts. The courts may quash a permission ifpolicy is\nmisinterpreted, ifcommittee members are misledora decision ismanifestly\nunreasonableorinconsistent, or ifno reasons havebeen given, but the decision\nmaker has wide discretion on the way that policies are applied and the weight that is\ngiven to planning considerations – in fact, the courts have warned against the\ndangers of ‘excessive legalism’.\nAutomation and planning\n‘Artificial intelligence’ is a blanket term for a range of digital technologies that can\ntake the place – partially or entirely – of human intelligence. TheUK government\ndescribes AI as ‘the use of digital technology to create systems capable of\nperforming tasks commonly thought to require intelligence’.AI can be used to\ngenerate predictions, recommendations, or classifications and used in a range of\nprocesses. Its functions are performed through algorithms – pre-programmed rules\napplied to the data in question. Algorithms can be transparent and explainable, with\nclear rules and consistently repeated functionality, but recently there have been\nsignificant developments in machine learning, a type of AI, where the machine can\ndevise its own rules that achieve the objective more effectively. These processes are\npowerful, complex and opaque and are commonly referred to as non-interpretable or\n‘black box’ AI systems.\nTuring himself acknowledged that some judgments – such as the artistic merits of\nPicasso – should be reserved for human judgment, and that the more important\nquestion was whether automation could be trained tomimic part of the human\nfunction. The same question can be addressed to planningdecisions – not whether\ncomputers can replace humans altogether but to what extent the human function can\nbe replaced in making planning decisions.\nAdministrative process\nOne area where automation can replace the human function is in administrative\nelements of the planning application process, currently regulated by the Development\nManagement Procedure Order 2015 (DMPO):\n●\nArticles 6, 7, 8, 11 and 27 set out the documents that must be submitted in an\napplication; this could be automated including rejection of non-compliant\napplications.\n●\nArticle 9 design and access statements could be converted into standard\ntemplates pre-populated with some content generated from relevant local and\nnational policies.\n●\nArticles 13, 14, 17 and 26 relate to service of notices; where a particular format of\nnotice is required this could be linked to a template form and generated\nautomatically.\n●\nArticles 15, 16, 18, 19, 20, 21, 22, 23 and 24 specify how applications are to be\npublished and who should be consulted; if applications were submitted online\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202113\n\nand the current notices were turned into templates, information such as a\ndescription of the site and the development could automatically populate the\nrequired forms or letters.\nSeveral local authorities are already exploring the potential for administrative\nfunctions to be automated:\n●\nRedbridge Council is working withAgile Datumto detectcommon mistakes in\napplications and improve validation.\n●\nThe London Borough of Lambeth is testing AI in theprocessing of planning\napplications.\n●\nThe Ministry of Housing, Communities and Local Government (MHCLG) has\nrecently\nannounced\nthat two new apps will be testedto help with small scale\nplanning applications and processes.\nAssessing Environmental Impacts\nAssessment of environmental impacts is an essential element of any decision to\napprove or refuse a planning application. In many cases, aformal assessmentof\nthose impacts and their mitigation is required. The process involves submission of a\ndaunting amount of largely static information which is then assessed by the local\nauthority, involving the use of specialist advisers. Thisprocess has been validly\ncriticised for being paper-heavy and impenetrable,with outputs archived rather than\nbeing made available for re-use and it is overripe for change.\nThere is a growing range of real-time sources of environmental information. The\n‘Geo6’ are creating acatalogue of geospatial data,the Geospatial Commission has\nstarted work on aNational Underground Asset Registerand has published a\ncollection of 65 housing, land and planningopen datasets.The National Energy\nEfficiency Data-Framework collects national data about gas and electricity\nconsumption data, property attributes and household characteristics, and publishes\nregularstatistical summaries. Meanwhile regionalresources such as theLondon\nDatastoreare also emerging.\nThere is a parallel movement towards metrification of environmental impacts and\nbenefits. In March 2020 the government presented nature as an asset that could be\nassessed with a range of tools including an assessment template, biodiversity metric\nandnew valuation methods. The environment bill dueto be introduced to parliament\nthis year’s session proposes the calculation of biodiversity credits through ametric\nwhere habitats are used as a proxy for value.\nFinally, there are experimental projects where real time environmental information is\ncombined with predictive analytics to model environmental impacts. Current projects\nat the Alan Turing Institute include:\n●\nSPENSER(synthetic population estimation and scenarioprojection) a tool that\nuses dynamic microsimulation to produce a range of population projections in a\nwide range of scenarios.\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202114\n\n●\nThe development of acausal inference modelto quantify the effect of a planning\nintervention, such as the introduction of public transport, on human behaviour.\n●\nProject Odysseuswhich combines existing datasetsto understand urban activity\nand facilitate targeted interventions to mitigate the impacts of Covid-19.\nAs well as automating processes, this is an area where, due to developments in\nsensory technology and predictive analytics, the assessment itself could be\ntransformed into a real-time platform of information flows, analytics and predictive\nmodelling which can be interrogated by any interested party to predict both the\nimpacts of development and the effect of mitigating measures.\nIn March 2020, the Institute of Environmental Management and Assessment issued\nanImpact Assessment Primerand theDigital EIA Projectwas launched. It may not be\nlong before the established assessment processes are replaced by a continuous\nharvesting of information from large, open, rich datasets accessed in real time and\nused as the basis for accurate predictions of environmental impacts and mitigations\nin a range of scenarios through the life of the project.\nAutomation: barriers to adoption\nAutomation has the potential to replace the human function in both planning\nprocesses and assessment of planning impacts, but the transition will generate some\nsignificant issues.\nFirst, the planning profession is not equipped with the skills or resources to make the\nmost of automated processes. The planning White Paper may have raised the\nimportance of a digital planning system but it is only just beginning to be recognised\nas a relevant topic for training for planners and local authority members.\nNext, there are significant ethical issues associated with automation (considered in\nthe next section of this paper) including the privacy implications of embedded\nsensory technology in buildings and places, algorithmic bias and the emergence of a\n‘digital divide’. The government has already been criticised for theproposed use of a\npredictive algorithmin the context of assessing housingneed requirements that was\n‘blind to geography’ and concentrated growth in London,the South East and the\nSouth West.\nThere are also legal issues. The current legal framework for planning decisions was\nenacted in 1990 and rests on principles established in 1946 when machine-made\ndecisions were hypothetical mathematical propositions. It anticipates decisions being\nmade by corporations composed of human individuals. The High Court has recently\nruledthat an algorithm is not ‘a natural or legalperson’; if a decision is made even in\npartial reliance on an algorithm, it can be challenged on the basis that the decision\nwas not actually made by a human at all. When permissions are refused – and\nsometimes when they are approved – planning law requires that reasons should be\ngiven.The House of Lords has ruledthat: ‘The reasonsfor a decision must be\nintelligible and they must be adequate. They must enable the reader to understand\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202115\n\nwhy the matter was decided as it was’. Where a process is automated, and a decision\n.has been made in reliance – even partially – on predictions generated by an opaque\nalgorithm it is difficult to see how it can also be fully reasoned in a human sense.\nThe problem of opaque algorithms is already attracting attention. In June 2018,\nOswaldwarned that the introduction of algorithmsin the place of humans\nrepresented a challenge to the rule of law and created a specific risk of ‘genuine\ndoubt as to why decisions were made’.Shortly afterwardsCobbe’spaper on the\njudicial review of automated decisions in the public sector proposed that the greatest\nchallenge to those decisions was ‘the explainability of machine learning decisions’. In\nOctober 2019, anopinion on automated decision makingconcluded that the ‘inability\nto peer inside an algorithm, AI or ML process... has real legal implications’. In April\n2020 Webley’s paper ‘Ethics, Technology and Regulation’noted that ‘the\ntransparency of algorithms is currently insufficient to allow for many algorithmically\nrendered decisions to be subject to proper challenge’.\nThese concerns are not limited to academia. In January 2020, a reviewby the\nCommittee on Standards in Public Lifeadvised thatpublic bodies ‘should not\nimplement AI without understanding the legal framework’. In June 2020, the Centre\nfor Data Ethics and Innovation (CDEI) ‘AI BarometerReport’ identified ‘lack of\nexplainability’ as one of the principal risks to the adoption of the technology. In\nDecember 2020, the House of Lords Liaison Committee recommendednational\nstandards for the ethical development and deployment of AIand a recent reportfrom\nthe Institute for Governmentnoted that ‘policymakers,in particular, need to be critical\nusers of models and algorithmic systems’.\n“\nthe technology is pervasive and the concerns\nare universally relevant\nThe same issues are emerging in case law too. In February 2020, theHague District\nCourt ruled that ‘SyRI’, an AI-based system used to detect fraud, was unlawful\nbecause it was insufficiently transparent and verifiable. In April 2020,Le Conseil\nConstitutionnel (the French Constitutional Court) dismissed a claim disputing the\nvalidity of an AI platformused to select studentsand the subjects they should study,\npartly because the system was relatively transparent and not fully automated. In May\n2021 theItalian Supreme Court prohibited the processingof personal databy\nalgorithms to create reputational rankings for use by third parties. The court ruled that\nthe algorithm was so opaque that it created a situation where a human could not\nvalidly consent to their data being used.\nSome of these cases relate to algorithms in the private sector, some in the public, but\nthe technology is pervasive and the concerns are universally relevant. As planning\ndecisions are increasingly informed by automated inputs and predictions, it is likely\nthat these kinds of challenges will proliferate in this area too. However, it is\nquestionable whether the planning court has either the will or the capacity to\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202116\n\nintervene. In February 2020, Dove J was asked to consider competing claims about\nthevalidity of evidence on air quality. He ruledthat ‘it is not the role of the court to\nembark on its own technical appraisal of the issues’. A similarly ‘hands off’ approach\nwas taken by Jay J in relation toexpert evidenceon tunnel structuresin June 2020. In\nboth cases the judge did not analyse the evidence; instead, they considered only\nwhether it was reasonable for the decision maker to rely on it. It is likely that the same\napproach would be taken to expert evidence on the use of AI.\nCurrent responses: policy\nThere is no shortage of guidance in this area – if anything the crowded landscape\nmakes it difficult to decide what the best approach is.\nIn 2019, the UK government issued guidance on ‘Understandingartificial intelligence\nethics and safety’ and a collection of guidance onusing AI in the public sector. The\nAlan Turing Institute issued its own guidance onAIin the public sector. The\nConfederation of British Industry (CBI) also issued guidance onethics in practice\nrecommending an embedded approach, updated governance processes, impact\nassessments, and a commitment to engagement and explainability in relation to the\nworkforce and the public.\nIn May 2020, the ICO issued, in partnership with the Alan Turing Institute,\ncomprehensive guidance for organisations onexplainingdecisions made with AI. In\nJune 2020, the Office for Artificial Intelligence (OAI), BEIS and the Department for\nDigital, Culture, Media and Sport (DCMS) issued jointGuidelines for AI procurement\nand in July 2020 the ICO issued further guidance onAI and data protection. In\nOctober 2020, the Ada Lovelace Institute issued its review oftransparency\nmechanismsin the public sector. It identified practicalsteps public sector bodies can\ntake including impact assessments, procurement processes, open data standards\nand disclosure protocols. In November 2020, the Local Government Association\npublished a practical guide for local authoritiesworking on or considering predictive\nanalytics. It includes specific criteria to consider at each stage of the process that\ncould be used as the basis for structuring reports on the adoption and use of some AI\nsoftware and processes, and recommends internal consultation with data teams, data\nprotection officers, and establishing a board or group of senior managers. TheCDEI\npublished its review of bias in algorithmic decision-makingin the same month,\nincluding guidance for local authorities on decision-making tools.\nIn January 2021, the World Economic Forum proposed a10-step approachfor\ndeveloping corporate knowledge about AI fairness and the UK AI Council published\nitsAI Roadmapincluding a recommendation that theUK should encourage public\nscrutiny of automated decision-making. In February 2021, the ICO issued itsdata\nanalytics toolkit, integrating existing regulatoryrequirements with issues specific to\ndata modelling, including the use of AI. It recommends the use of an impact\nassessment and includes guidance where deficits are identified. In March 2021 Digital\nScotland published Scotland’s newAI Strategyhighlightingthe importance of trust,\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202117\n\nethics and inclusivity as being intrinsic to the effective and proper use of AI, and the\nUK government announced its intention to develop anAI strategy– currently the topic\nof a consultationwith the Alan Turing Institute.\nBetween 15 and 17 April 2021, CDEI issued three blog posts on AI Assurance. The\nfirst recognised the need for AI to be used in a consistent and compliant way,\nfounded on anassurance approachcomprising governancetools such as audits,\ncertification, accreditation, and impact assessment. The second identified a range of\n‘user roles’ in relation to AI and the need for anassurance ecosystem to meet all of\ntheir needs. The third examined differenttypes ofassuranceand standards. All three\nended with an open call for stakeholder collaboration on creating an AI assurance\nroadmap. In June 2021 the Business Software Alliance proposed an AIRisk\nManagement Frameworkto build trust in AI and AI systemswith proposals including\na governance framework (policies, personnel) and impact assessments carried out\nthrough the AI lifecycle.\nIn May 2021 the Cabinet Office, the Central Digital and Data Office (CDDO) and the\nOffice for AI published the‘Ethics, Transparencyand Accountability Framework for\nAutomated Decision-Making’ for use by government departments.It is aimed at\ngovernment departments using either solely automated or automated-assisted\ndecision-making and distinguishes between solely automated decision-making and\nautomated assisted decision-making. It begins with a general recommendation to\ncarry out a risk assessment, use data in accordance with the Data Ethics Framework,\nfollow data protection law and engage with third-party experts, and sets out a\nseven-step framework process to follow when using automated decision-making. The\nrecommended steps are set out and summarised below:\n●\nTest to avoid any unintended outcomes or consequences.This includes\nrecommendations to carry out risk assessments, Data Protection Impact\nAssessments (DPIAs) and an Equality Impact Assessment (EQIA).\n●\nDeliver fair services for all of our users and citizens.This step recommends\ncarrying out an EQIA, having a diverse team and assuming that ‘the algorithm or\nsystem that you are developing is capable of causing harm and injustice’.\n●\nBe clear who is responsible.This includes the recommendationfor ministerial\nownership of significant decisions.\n●\nHandle data safely and protect citizens’ interests.This reminds operators of\ntheir responsibility to be compliant with data protection legislation and the Data\nEthics Framework, a cautious approach to repurposing of datasets and carrying\nout a DPIA when required.\n●\nHelp users and citizens understand how it impacts them.This step\nrecommends working on a ‘presumption of publication’, plain English\nexplanations of automated systems, traceability mechanisms, and the\nappointment of an accountable officer.\n●\nEnsure that you are compliant with the law.This includesearly engagement\nwith legal advisors and compliance with data protection law and theEquality Act\n2010\n●\nBuild something that is future proof.This recommendscontinuous monitoring,\nformal reviews and end user challenges.\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202118\n\nThere is no shortage of guidance; at the same time it is difficult to identify what\nCentral Government guidance on the use of AI for public sector decisions is.\nCurrent responses in law\nThe only formal regulation of AI in England is the GDPR, transposed into UK law\nthrough the Data Protection Act 2018. Articles 13–15 create individual rights to\ninformation about solely automated decision-making when that decision-making has\nlegal or similarly significant effects; Article 21 provides a right to object to the\nprocessing of personal data in some circumstances; Article 22 gives individuals the\nright not to be subject to a solely automated decision producing legal or similarly\nsignificant effects without appropriate safeguards; and Article 35 requires\norganisations to carry out DPIAs where data processing, including processing using\nnew technologies, is likely to result in a high risk to individuals.\nInternationally, the picture is more evolved: Canada has aDirective on Automated\nDecision-Making, New Zealand has anAlgorithm Charter,and the Singapore\ngovernment has adopted anAI Governance Framework.In April 2020, the European\nCommission published adraft AI regulationwith aimsincluding the need to ensure\nlegal certainty and enhance governance. It defines ‘artificial intelligence systems’ in\nterms of techniques used and outputs generated and distinguishes between three\ntypes of AI techniques: machine learning approaches, logic- and knowledge-based\napproaches, and statistical approaches. It has a graded approach to regulation\ndepending on whether AI system risks are unacceptable, high risk, limited risk, or\nminimal risk. High-risk systems include the administration of democratic processes\nand proposed obligations include transparent risk assessment and mitigation\nmeasures including documentation on the system used, human oversight and activity\nlogging. Voluntary codes of conduct are proposed for non-high-risk AI, as well\nas regulatory sandboxes to facilitate responsible innovation.\nAI governance: next steps...\nThe new ‘Ethics, Transparency and Accountability Frameworkfor Automated\nDecision-Making’ is a welcome development, becauseit is this kind of central\ngovernment guidance that will give local authorities the basis to help them use\ntechnology effectively and to minimise the risk of challenges to decisions based on\nprocedurally unfair decision-making. It is also useful because it includes references to\ncase studies, detailed practical guidance, a glossary of terms and a template ‘Ethics\ntransparency and accountability’ risk assessment form.\nHowever, it appears to be aimed only at central government departments, and it is\nnot clear whether or not it should be taken as authoritative in other contexts,\nincluding by local authorities. It is guidance, not law, so it would be difficult for an\nindividual or organisation to assert non-compliance as a successful basis for\nchallenging a government decision. It refers to the need for legal compliance but the\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202119\n\nonly specific legal reference is to Article 22 of the GDPR. There is no reference to the\nparticular risks of biometric technologies, which is surprising given that algorithmic\nbias was successfully asserted tochallenge the useof facial recognition technology\nby the South Wales police. Equality Impact Assessments are recommended, but the\nexamples given relate toWelsh Government policy onEnglish for Speakers of Other\nLanguages (ESOL) Policy for Wales,andgeneral guidancefrom the UKRI; neither of\nwhich offer any real help in this context.\nIn February 2020 theCommittee on Standards in PublicLifepublished a report\n‘Artificial Intelligence and Public Standards’ including15 recommendations. The\ngovernment issued itsresponsein May 2021. That responsemakes few specific\ncommitments to taking forward any of the recommended actions and no response at\nall to recommendations 9-15 which were addressed to ‘front-line providers, both\npublic and private, of public services’:\nThe CDEI has since issued ablogsummarising areporton its work with theCDDO\nandBritainThinkson the potential for a ‘mandatorytransparency obligation on all\npublic sector organisations using algorithms when making significant decisions\naffecting individuals’. The proposal is that two tiers of information would be available:\nsome provided automatically as a ‘signpost’ that an algorithm was being used, with\nmore available on request. The recognition of a need for greater transparency is\nwelcome, as well as the proposal but the proposal is based on very limited research\ncarried out over four weeks with 36 people. It is intended to inform the development\nof a prototype standard for future testing and there is no indication of whether or\nwhen it will be formally adopted.\nThe breadth of the range of guidance available, without clear government advice on\nwhich should take priority could discourage local authorities from engaging with the\nissues. In the absence of a coherent national policy position or emerging regulation\nthere is an urgent need for practical guidance on how a decision maker can integrate\nthe procedural considerations specific to emerging technologies into the mechanisms\nof public sector decision-making on planning applications.\nRegulatory technology is promoted as a way to automate compliance with the law\nbut its utility has been questioned in arecent paperarguing that concepts such as\ndiscrimination require human assessmenton a case-by-casebasis. In any case, the\nplanning system already has an established statutory framework for making\ndecisions, supported by a wide range of guidance. The most effective way to\nintegrate emerging concerns about the new technology into the current system is to\naddress those issues in a transparent way at all levels of the planning function.\n●\nPolicy:All local authorities have a range of policiesthat support and inform\ntheir decision-making. In relation to planning decisions, there is likely to be an\nadopted development plan which sets policies on how particular areas are to\nbe developed or how particular issues such as highway impacts should be\naddressed. Some local authorities have policies relevant to the use of\ntechnology such as theLondon Tech CharterandManchester’sDigital\nStrategy. The ideal foundation for the use of automatedtechnologies within\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202120\n\nthe planning function is a formally adopted strategic policy document based\non internal and external consultation. The policy should include, at a\nminimum, an explanation of what AI is, the principal benefits and risks, the\nrelevant legal and policy context and where to go for further information. A\ntemplate example of such a policy document is attached asAppendix One.\n●\nProcurement:Most local authorities implement theuse of automated\ntechnologies through the use of externally procured software, and it is\nrecognised that good procurement of AI can support the development of the\ntechnology and promote sound ethical standards. The UK Government’s OAI\nhas producedguidance for AI procurementwhich isclearly written and can\neasily be used as the basis for evolved procurement processes and\ndocuments in parallel withspecific trainingon procurementprocesses and\ndata management. As a minimum, the invitation to tender should include\nquestions on data sourcing and training, equalities issues, cyber security,\nliability for defects, and data ownership and sharing, and the decision to\nprocure and any contract entered into afterwards should include\nconsideration of the same issues. A template example of a procurement\nchecklist is attached asAppendix Two, as well asa template for a formal\ndecision to adopt a chatbot attached asAppendix Three\n●\nIndividual decisions:With a strategic policy andimproved procurement\npractices in place, the risk of challenges to planning decisions based on\nopaque AI systems would already be reduced, but where AI is involved in any\naspect of a planning decision, it would be good practice to acknowledge and\naddress this in the decision. It is accepted practice for planning decisions to\nconsider, as a matter of course, whether those decisions have an impact on\nequalities, and to consider the environmental impacts, benefits and\nmitigations, as well as wider legal implications. There is no reason why a\nsimilar risk-based approach could not be taken in relation to AI.\nSection 2 summary\nAI has developed in ways that perhaps only Turing might have predicted in 1947 and\nthere is significant scope to automate the way planning information is accessed and\nassessed. Algorithms are much more efficient than humans in processing large and\ncomplex datasets; automation can also provide a rich, real-time record of\nenvironmental impacts and make sophisticated predictions about the impacts of\ndevelopment proposals with reduced investment of human time and resources.\nHowever, the complexity of the legal test regulating the decision-making function in\nplanning makes it difficult to automate. The planning process is a locus for conflicting\nviews on how land should be used, and an arena where irreconcilable interests\nintersect. Planning policies often have an inherent ambiguity and subjectivity that is\nirreducible to an if-then process. Decisions about land are also about the humans\nwho inhabit it; the machines are not yet capable of factoring empathy into their\ndecisions or to evaluate aesthetic merits as a human might.\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202121\n\nMachine learning has not yet found a way of reconciling the need for landowners and\ndevelopers to derive profit from the development of land, the need for new\ncommunities to access affordable homes supported by good infrastructure and the\nneed for existing communities to preserve the land they inhabit free from radical\nsocial or aesthetic change. The prospect of entirely machine-made planning\ndecisions is both dystopian and unrealistic.\nMany elements of the process are either routine procedures or empirical assessments\nthat do not need any human involvement. If algorithms are trained to do this work\nthen human resources can be freed up to exercise judgment in those parts of the\ndecision-making process where judgment and discretion are required. However,\nmachines cannot be held accountable in the same way as humans, and their\ndecisions cannot be challenged in the same way as human decisions. Moreover,\nhumans are not yet comfortable with machine-made or even machine- assisted\ndecisions; a recent reportby the Committee on Standardsin Public Liferecorded that\n69% of those polled said that they would be more comfortable with a public body\nusing AI if a human was involved in the final judgement.\nIt can be argued that human decision-making is also flawed, and that the human\nbrain is the ultimate black box, influenced by unconscious bias, daily experience, or\neven the contents of its host’s last meal. Existing legal and procedural mechanisms –\nsuch as planning committees – are created to impose coherent regulatory\nframeworks on these human frailties, to make public decision-making more\ntransparent and accountable. If the planning system is to make the most of AI while\nstill maintaining public trust, existing regulatory frameworks need to readjust and\nexpand to accommodate its strengths and weaknesses.\nAs well as procedural requirements for the processing of applications and a legal test\nfor determining planning applications, planning decision-making is also subject to\nethical requirements set out in legislation, common law principles, and codes of\nconduct. These also need to expand to adjust to a digital world and the final section\nof this paper looks at what that might mean in practice.\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202122\n\n3 Ethical planning in a\ndigital world\nUrban planning is, and always has been, about more than land. Thefirst planning\nlegislation was introduced to parliament in 1909withthe intention of providing ‘a\ndomestic condition for the people in which their physical health, their morals, their\ncharacter, and their whole social condition can be improved’. More than a century\nlater, these social concerns remain: one of the aims of theplanning White Paperwas\nthe need to achieve a ‘fair balance between consumers, producers and wider\nsociety’.\nThe ethical context of planning decisions is important: not just because human\ndecisions need to be made as transparent and accountable as possible, but because\nplanning decisions are made in a specific socio-political environment which shifts\nover time and in response to changes in wider society. There is no legal definition of\nethics nor are they acknowledged as a discrete concept in planning policy, but ethical\nconcerns are relevant both to the planning process and its outcomes.\nEthics are also highly relevant to data: the UK government has established aData\nEthics Frameworkfor responsible use of data in thepublic sector and Mission 2 of\nthe emergingNational Data Strategyrecognises theimportance of maintaining public\ntrust.\nThe first part of this section examines three specific areas – public engagement,\nequalities, and human rights – where ethical concerns are regulated; in each case\nlooking at how existing regulatory norms are disrupted by developments in digital\ntechnology. The second part of this section reviews the existing landscape of data\nethics and its relationship with existing ethical norms. It concludes with a brief\nexploration of ways that existing practice and procedure could adapt to embrace\nemerging notions of data ethics, so that digital planning can develop with embedded\nsound ethical principles.\nEngagement\nEngagement is often used as a blanket term referring both to the informal\nengagement processes that happen throughout an application process and the\nformal consultation requirements required by law. The planning system has come a\nlong way since the1909act when better homes andenvironments could be endowed\non the working classes by those who were ‘more fortunately situated’ but many\nwould argue that we are barely halfway upSherry Arnstein’sLadderwith true citizen\ncontrol of decisions.\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202123\n\nFor most planning applications, consultation is highly regulated, primarily through\ndetailed requirements in the Town and Country Planning (Development Management\nProcedure) (England) Order2015 (DMPO)where the requirementscan be summarised\nas follows:\nRequirementDetail\nConsultationArticles 3 and 4 require pre-application consultation when a wind turbine is\nproposed.\nArticle 18 is the general requirement for consultation; schedule 4 sets out who is\nto be consulted depending on the size of the proposal and the type of land\ninvolved.\nArticle 19 requires consultation for Crown land applications.\nArticle 10 requires consultation on applications to amend existing permissions.\nArticles 22 and 23 contain a duty to respond to consultations and report on them.\nArticles 24, 25 and 26 establish notification requirements specific to district\ncouncils, parish councils and neighbourhood forums.\nArticle 33 imposes a duty on the decision-making authority to take\nrepresentations into account before deciding a planning application.\nAdditional consultation requirements are imposed by ‘The Town and Country\nPlanning (Consultation) (England) Direction’.\nNotificationArticle 13 requires the owner of land to be notified of an application and Article 14\nrequires the application to certify that this has been done.\nThere are additional notification requirements forheritage applications.\nPublicationArticles 15 and 16 require the local authority to publicise an application.\nschedules 2 and 3 prescribe the form of the notice.\nArticle 40 requires a public register of planning documents and decisions to be\nmaintained.\nIn addition to these regulations, the ‘Gunning Principles’established in case law\napply to all consultations:\n1) consultation must take place when the proposal is still at a formative stage \n2) there should be enough detail to allow for intelligent consideration and response\n3) adequate time must be given for responses\n4) the consultation responses must be conscientiously taken into account\nThe principles were established in 1985 but remain highly relevant: in 2019 the\ngovernment was forced to withdraw part of its National Planning Policy Framework\nafter a judgmentthat ‘the consultation on the draftrevised framework paragraph\n204(a)was so flawed in its design and processes asto be unlawful’.\nNeither the DMPO nor case law currently acknowledges the digital world. The DMPO\nassumes that notices are posted on land or buildings and published in paper\nnewspapers and that consultation is carried out by post. Case law is similarly\ntethered to paper rather than its digital equivalents – and there is a2014 judgment\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202124\n\nwhere the court ruled that relying solely on electronic consultation was insufficient to\ncomply with relevant regulatory requirements.\nThe deficiencies of these assumptions were exposed by Covid-19, and regulations\nwere made to allow electronic publication of noticesand use of websites and online\npublications in place of paper editions and inspection of documents at physical\npremises. Subsequent guidanceon local planspromotedonline engagement\nmethods including ‘virtual exhibitions, digital consultations, video conferencing, social\nmedia’. Theplanning White Paperencouraged localauthorities to ‘reinvent the\nambition, depth and breadth with which they engage with communities’. MHCLG has\nintroduced anew framework for consultationsand theLocal Digital Declarationand is\nfunding severalprojects, including one for digitalplace-based engagement, and a\ncommunity engagement playbook.\nThese are positive steps as they could make planning decisions more accessible and\nfacilitate responses from a much broader range of the people potentially affected by\nthe proposals. However, the transition to digital engagement is not unproblematic.\nThere is a risk, explored in greater detail below, that while smart engagement has the\nability to open up the planning process to new participants, it may exclude others\nunless adequate protections are put in place. The communicative possibilities of\nemerging technologies sit awkwardly with the established regulatory norms, all of\nwhich are based on analogue engagement methods. For example, the courts have\nrecently confirmed that reference in legislation to physical meetings cannotinclude\nvirtual meetingsand that reference to public attendancecannot include attendance\nonline.\n“\nwhile smart engagement has the ability to\nopen up the planning process to new\nparticipants, it may exclude others unless\nadequate protections are put in place\nThe adoption of platform-based engagement raises its own issues. The House of\nLords recently issued a reporton Democracy and DigitalTechnologies, ‘Digital\nTechnology and the Resurrection of Trust’. This focusedprimarily on social media\nplatforms but it also noted the increased use of platforms for democratic engagement\ngenerally. It expressed concern about the lack of accountability, the potential for\nplatforms to be used as a forum for bullying and abuse, and the lack of content\nmoderation or regulation. Planning is highly political and developments are often\ndivisive; provoking strong emotions and allegations of misconduct. Major\ndevelopments already use social media platforms as a way of engaging with the\npublic; many of the concerns raised by the House of Lords are increasingly relevant\nto these engagement methods.\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202125\n\nEqualities\nThe Public Sector Equality Duty (PSED) is contained insection 149 of the Equality Act\n2010and requires any public authority, when exercisingits functions, to have due\nregard to the need to\n(a) eliminate discrimination, harassment, victimisation and any other conduct that is\nprohibited by or under the Act;\n(b) advance equality of opportunity between persons who share a relevant protected\ncharacteristic and persons who do not share it; and\n(c) foster good relations between persons who share a relevant characteristic and\nthose who do not share it.\nThe relevance of these issues to planning decisions was established in 2010 when a\nconsent for redevelopment of an indoor market was quashedbecause of a lack of\nregard to the implications of that decision on traders. Its relevance has not declined\nover the years – for example in 2016consent for anoffice block was quashed\nbecause the planning inspector had insufficient regard to use of the car park and\naccess by the disabled; in 2018 apermission to redevelopan estate was quashed\nbecause of a lack of regard for the implications on the elderly and disabled and last\nyear, anapplication by the London Borough of Bromleyfor an injunction preventing\nencampmentswas refused because there had been noassessment or any\nengagement with the traveller community.\nEmerging technologies disrupt equalities considerations in two areas.\nFirst, there is the issue of digital discrimination during the consultation process. As\nseen above, paper consultation and notification methods are being displaced by their\ndigital counterparts and engagement is more likely to be achieved through an online\nplatform of resources than face-to-face meetings. Alongside the demonstrable\nbenefits of these changes there is a risk of reduced access for members of the\npopulation with insufficient skills, devices or connectivity. In January 2020 aHouse of\nLords reportnoted that 19% of individuals lackedbasic digital skills; in June a further\nreportwarned against the adoption of digital engagementas a replacement for other\nmethods.The House of Commons Committee on Housing Communities and Local\nGovernment has reportedon the planning White Paper;noting that 9 million people in\nthe UK struggle to use the internet and 11.9 million people lack digital skills. Although\nthe emerging environment bill includes the first definition of a ‘digitally excluded\nperson’ and there is someplanning guidance on howto reach people without internet\naccess, the planning White Paper does not engage withthe concept of digital\ndiscrimination and digital exclusion.\nThe other emerging issue is algorithmic bias. There is already aconcept of bias,\nestablished in case law: whether a fair-minded andinformed observer with access to\nall the relevant facts concludes that there was a real possibility that the\ndecision-maker was biased. The test is based on human assessment of human\nbehaviour – in a recent case a judge ruled thatThanetCouncil mishandled a planning\napplication,leading to his conclusion that a “fair-mindedobserver would have\nthought there was a real possibility that the decision-maker was biased”.\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202126\n\nAlgorithmic bias occurs when an algorithm has been trained on inadequate data or\nprogrammed badly so that outputs can embed and amplify social inequities in a way\nthat can neither be seen or understood by the humans they affect. The risks of such\nprocesses became apparent in summer 2020 whereautomatedexam grading\nresulted in the perception of preferential treatment of students from private over state\nschools. AnAlan Turing Institute reportcommentedthat the algorithm operated in a\nfunctionally discriminatory way, whilethe ODI criticisedOfqualfor its lack of\ntransparency, its unwillingness to acknowledge and address issues early in the\nprocess, and the inadequate assessment of potential impacts.\nAlgorithmic bias is a particular problem for planning where developments are\napproved including sensory technology embedded either in the buildings or the\nspaces around them. TheNeuroscience Playbookpromotesthe use of\nelectroencephalograms (EEGs) and eye tracking in public settings to create ‘scientific\nbaselines’ for assessing how humans interact with the environment. There is\nemerging work on usinggait analysisto assess intoxicationand onmeasuring\nemotional responsesin a court environment.Moda ispromoting a build-to-rent\ndevelopmentwhere ‘multiple sensors’ measure motionand occupancy, and residents\nconnect directly with the building through the relevant app and the Connected Places\nCatapult is promoting 15 projects under the umbrella ofForever Living Homes, most\nof which appear to use sensors or monitoring or both.\nThe use of such technology, combined with automated processing, creates a\nsurveillant environment recording and processing a range of data about human\nmovements and activities. Facial recognition technology (FRT) is an area of particular\nconcern. In September 2020 theCourt of Appeal ruledthat use of FRT by the South\nWales Police was in breachof the public sector equalityduty and that police\nintending to use the technology in the future should ‘satisfy themselves that\neverything reasonable which could be done had been done in order to make sure that\nthe software used does not have a racial or gender bias’. In January 2021 the\nBiometrics and Forensics Ethics Group publishedareport on the public-private use\nof live FRTnoting its increased use in shops, shoppingcentres and housing estates.\nA reportby the Ada Lovelace Institutehas calledfor comprehensive legislation for\nbiometric technologies, an oversight body and minimum standards for the design and\ndeployment of biometric technologies and has just started alegal review on the\ngovernance of biometric data.\n“\npublic spaces and even private homes could\nbecome places and spaces where inequality is\nembedded, yet unseen\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202127\n\nTheInformation Commissioner has recently published a blog postand anOpinionon\nthe use of FRT in public spaces following six investigations of its existing or planned\nuse. She reported that ‘controllers often gave insufficient consideration to the\nnecessity, proportionality and fairness of the use of Live Facial Recognition (LFR)\nsystems and failed to be sufficiently transparent’ and that ‘controllers did not always\ndo enough to demonstrate a fair balance between their own purposes and the\ninterests, rights and freedoms of the public’.\nNone of these concerns look likely to halt the development of sensory technology or\nits potential to infer information about humans. Unless the planning system starts to\naddress the full implications of these technologies, public spaces and even private\nhomes could become places and spaces where inequality is embedded, yet unseen.\nHuman rights\nThe European Convention on Human Rights (ECHR) is embedded in UK law through\nthe Human Rights Act 1998. A number of rights are relevant to proposals for\ndevelopment but the one most commonly asserted is Article 8 that protects the right\nto a private life, including specifically family life, home, and correspondence. The\nrelevance of Article 8 to planning decisions has been shown in numerous cases\ninvolving developments by the traveller community and continues to be relevant; in\nJanuary 2020 aninjunction for a borough-wide prohibitionon travellers in Bromley\nwas refusedin partial reliance on Article 8 rights.\nArticle 8 is generally asserted in the context of development proposals to challenge\nthe use of legal powers to deprive communities from occupying land – such as the\ninjunction mentioned above. However, the courts have ruled thatArticle 8 included a\n‘reasonable expectation of privacy’and Article 8was one of the grounds of challenge\nto the use of FRT by the South Wales Police in the Bridgescase, where the Court of\nAppeal ruled that use of AFR technology both engaged and infringed Article 8. The\nintrusive nature of the new technologies, and their capacity to be embedded within\nphysical structures, means that their human rights implications are potentially relevant\nto any development consent where these technologies are used.\nIn June 2020 the Surveillance Camera Commissioner’s annual report noted that: ‘The\ngrowing capabilities of overt surveillance technologies...are increasingly ‘a question\nof trust’ for society’ and the draft EU AI regulation recognises the potential for AI to\nimpact on a number of fundamental rights including Article 8. It may not be long\nbefore the ‘reasonable expectation of privacy’ is asserted in challenges to\ndevelopments where buildings themselves perform an ‘overlooking’ function and blur\nthe lines between physical and psychological boundaries, making surveillant\ntechnologies a planning as well as a human rights issue.\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202128\n\nEthics\nEthics are not defined in the same way as protected characteristics or human rights,\nnor are they regulated in the same way as consultation requirements, but they are\nrelevant to the planning system because the decisions about development are\nmanaged by local authority officers, and taken by local authority members, or\nplanning inspectors, or by the Secretary of State within the context of policies\nadopted by the UK government. The conduct of individuals in any of these roles is\nunderpinned by the need to observe the Nolan Principles (the Principles) for conduct\nin public life promoted and upheld by the Committee on Standards in Public Life (the\nCommittee):\n●\nSelflessness\n●\nIntegrity\n●\nObjectivity\n●\nAccountability\n●\nOpenness\n●\nHonesty\n●\nLeadership\nIn 2019,the committee reviewed the standards as theyapply in local governmentand\nidentified four core elements of an ethical cultures:\n●\nA civil and constructive standard of behaviour\n●\nTraining that embeds this culture across all parties\n●\nObjective oversight\n●\nOpenness to scrutiny and change\nThe Principles underpin the codes of conduct adopted by central and local\ngovernment, including those for planning authorities and planning processes, but\nthey are based on established conventions rather than legal rules and rely on\ncollective and continued observance. In July 2020Transparency International UK\nissued a reportthat identified a decline in transparency,scrutiny and oversight, an\nincrease in cronyism and the adoption of local standards rather than the principles. In\nNovember 2020, the Chair of the Committee gave aspeechthat noted a tendency for\n‘those in public life’ to ignore the Principles. The Committee has since reviewed the\ncurrent standards and published an interimreportnoting that adherence to the\nPrinciples is being considered in a number of parliamentary and government inquiries\nand recommending immediate reform in four areas of government practice. The Law\nCommission has gone further, recommendingthe creationof two new offences:\ncorruption in public office and breach of duty in public office.\nIn November 2020, the CDEI published a reviewon biasin algorithmic\ndecision-makingand noted a lack of clarity on ‘howlegislation such as the Equality\nAct 2010 and Human Rights Act 1998 should be applied’. A June 2020House of\nLords report on digital technologynoted not onlythat regulation lags behind\ninnovation but that democracy itself could be considered ‘increasingly outmoded and\nirrelevant in a digital era’. The existing ethical norms that frame planning decisions\nseem increasingly unfit for purpose.\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202129\n\nDigital Ethics\nThere is no formal definition of data or digital ethics, but there is a wide range of\nguidance saturated with principles and recommended actions that encourage ethical\napproaches to data.\n●\nSection 7 of theNDSrecognises government responsibilityto drive ‘safe and\ntrusted’ use of data, including provision of ‘a clear and predictable legal\nframework’ and willingness to be ‘transparent and prepared to open itself up\nto scrutiny’.\n●\nThe nationalData Ethics Frameworkidentifies threeoverarching principles:\ntransparency, accountability and fairness.\n●\nThe Open Data Institute defines data ethics as: ‘a branch of ethics that\nevaluates data practices’. ItsData Ethics Canvasidentifies issues relevant to\ndigital ethics including the need to take existing legislation and policy into\naccount, the importance of keeping personal and sensitive information\nsecure; the need for transparency and the availability of appeal mechanisms.\n●\nThe CDEI has not identified a core set of ethical principles but its reporton\ntrust in public sector use of datastresses the needfor accountability,\ntransparency, and control.\nThere are also data ethics principles emerging that are specific to property. TheRED\nFoundationhas proposedsix principles to be appliedto all data used in real estate\ntransactionsthroughout the supply chain:\n●\nAccountable\n●\nTransparent\n●\nProportionate\n●\nConfidential and private\n●\nLawful\n●\nSecure\nAndEthicalGEOhas issued theLocus Charterwith 10principles:\n●\nRealise opportunities\n●\nUnderstand impacts\n●\nDo no harm\n●\nProtect the vulnerable\n●\nAddress bias\n●\nMinimise intrusion\n●\nMinimise data\n●\nProtect privacy\n●\nPrevent identification and\n●\nProvide accountability.\nAlthough they differ in context, content and purpose, these ethical data standards are\nconsistent both with established ethical norms and have many values such as\ntransparency and accountability in common. However, they have no legal weight.\nThey cannot be asserted in the same way as a human right, they are not protected in\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202130\n\nthe same way as equalities characteristics, they have no canon of case law behind\nthem to give them force as a precedent for future judgments.\n“\nLocal authorities besieged by housing delivery\nrequirements and staffed with overstretched\nplanning officers are unlikely to invest the\nnecessary time and effort to evaluate\ncompeting principles or to adapt them for use\nin the planning process\nNew blogposts, articles, reviews, toolkits, playbooks, reports, and recommendations\nemerge on what seems like a daily basis. The emerging guidance rarely references\nestablished legal controls on human rights and equalities or established ethical norms\nsuch as the Principles. Local authorities besieged by housing delivery requirements\nand staffed with overstretched planning officers are unlikely to invest the necessary\ntime and effort to evaluate competing principles or to adapt them for use in the\nplanning process. It is difficult to see why commercial property entities would invest\nin digital ethics while the policy landscape is so crowded and lacking in central\ndirection.\nThe government has issued a Data Ethics Framework and consulted on a National\nData Strategy, but universal regulatory controls look unlikely and it is difficult to\nidentify a clear national policy position either. There is an immediate need for an\nevolved approach that accommodates recent developments in technology,\nanticipates future changes and integrates the current approaches with emerging\nguidance from new sources.\nSection 3 summary\nThe core challenge is how to embed emerging principles of digital ethics as a\ncomplementary element in a system of law and policy that has yet to acknowledge\nthat land has a digital identity. There is no simple, or single fix, but there are a number\nof changes that, if made, would improve the ethics of digital planning immediately.\nBecause of the scope of its powers and its central role in making law and policy the\ngovernment has primary responsibility to demonstrate good ethical practice in action.\nThe recent parliamentary report‘Digital Technologyand the Resurrection of Trust’\nrecommended the creation of ‘an independent democratic information hub’ providing\ninformation and creating a way of sharing best practice. The government could also\ncentralise its guidance on consultation in the planning process and provide clear\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202131\n\nprinciples on how to carry out an online consultation together with specific\nrecommendations for ensuring that digitally excluded individuals are still kept\ninformed.\nLocal authorities could also do a great deal to embed digital ethics in the\nconsideration of planning applications. The ICO has recently issued an opinionon the\nuse of LFR technology in public places; this giveslocal authorities the perfect\nopportunity to ask whether development proposals include embedded sensory\ntechnology, and to require compliance with the Information Commissioner’s\nrecommendations for its use.\nIn January 2021, the ICO launched a consultationondata ethics and the GDPR\nrecognising that legal compliance could be enhanced with a ‘structured\nconsideration’ of ethical implications. The ICO has not yet reported on the outcome,\nbut in the meantime there is an opportunity for any organisation with responsibility for\ndata to adopt a set of ethical principles that can be applied in both by planning\npractitioners adjusting to a digital world and specialists who want to see digital ethics\nembedded in all decision-making processes.\nIn December 2020 the World Economic Forum issued itspaper‘Agile Regulation for\nthe Fourth Industrial Revolution’ proposing that the‘regulate and forget’ model could\nbe replaced with a cycle of continuous learning that tests regulation in parallel with\nthe development of the technology. As the WEF recognises in itspaper on agile\ngovernance: ‘If government alone can no longer providesufficient governance of\nemerging technologies in the Fourth Industrial Revolution, then new sources of\nauthority need to emerge’. Rather than waiting for government regulation or guidance,\nthis is the perfect time for a co-operative local authority to establish a regulatory\nsandbox and work with developers and data institutions within this safe space on the\nco-creation of good digital practice that could be tested in other contexts and\ndevelop into an industry standard.\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202132\n\nConclusion\nTheplanning White Paperpromised changes including‘harnessing the benefits’ of\ndigitisation and moving towards a system ‘based on data, not documents’. All\nstakeholders in the planning system acknowledge the need to shift to a digital future,\nand the need to improve the way that data is monitored, shared, processed and\nstored. There is less clarity and agreement on how this is to be achieved.\n●\nThere is much talk of digitisation but the system continues to be based on a\ndefinition of land that excludes its digital counterparts.\n●\nMuch of the recent shift to digital was reactive, we have already defaulted to\n‘physical’ planning committees and many other procedural changes will\nrevert to their analogue origins at the end of the Covid-19 restrictions.\n●\nAn increasing number of local authorities are using AI to replace human\nfunctions and inform planning decisions but there is no apparent intention to\nacknowledge its role, explain its function or mitigate its risks.\n●\nThe planning system is accustomed to taking the potential impacts of\ndevelopments on equalities and human rights into account, but ethical norms\nare shifting and there is no evidence that the system is ready or able to\nadjust.\nThere is no single, or simple, solution to these issues but the future offers\nopportunities as well as challenges.\nIn the 1902 bookGarden Cities of Tomorrow, EbeneezerHoward recognised that his\nradical re-visioning of urban development could only be achieved through ‘the hearty\nco-operation of men and of women experienced in very numerous departments of\nhuman activity’. Civil society organisations such as theAda Lovelace Institute, the\nAlan Turing Instituteand theOpen Data Institutehave emerged in parallel with the\nnew technologies. These institutions are rich sources of expertise and insight on data\nand technology; developing relationships with them would be one good step towards\ndeveloping awareness of the digital as well as the physical aspects of new\ndevelopments.\nIn the 2020report on Global Technology Governancethe World Economic Forum\nargued that governing new technologies ‘will require new principles, rules and\nprotocols’. A more agile approach to governance is also promoted in a recentwhite\npaperby the BSI, the CDBB and the Construction InnovationHub. Neither the legal\nnor the planning professions are known for their agility and flexibility but if we really\nwant to build an evolved system of regulation and governance, a regulatory sandbox\nis a great place to start.\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202133\n\nSection 2 Appendix 1:\nAI Strategy\n| The appendices relate toSection 2: Automationof the planning process|\nIntroduction\nArtificial Intelligence (AI) is a powerful tool in delivering modern, agile, and efficient\npublic services. It is also a disruptive technology which comes with its own risks, is\nconstantly evolving, and is not always well understood. It is important to ensure that\nthis Council maximises the current and future opportunities offered by this new\ntechnology while minimising the risk of harm from unintended consequences.\nThe purpose of this Strategy is to provide a brief explanation of what AI is and the\nbenefits it offers as well as the major risks. It outlines the existing governance context\nfor AI and introduces this Council’s principles for the way we will procure, implement\nand use this new technology.\nWhat is AI\n‘Artificial Intelligence’ is a blanket term for a range of digital technologies that can\ntake the place – partially or entirely – of human intelligence. The UK government\ndescribesit as ‘the use of digital technology tocreate systems capable of performing\ntasks commonly thought to require intelligence’. AI can be used to generate\npredictions, recommendations, or classifications and used in a range of processes.\nIts functions are performed through algorithms – pre-programmed rules applied to the\ndata in question.\nAlgorithms can be transparent and explainable, with clear rules and consistently\nrepeated functionality, but recently there have been significant developments in\nmachine learning (ML), a type of artificial intelligence, where the machine can devise\nits own rules that achieve the objective more effectively. These processes are\npowerful, complex and opaque, and are commonly referred to as non-interpretable or\n‘black box’ AI systems.\nThere are three main types of outputs: classifications, predictions and\nrecommendations. An algorithm could be trained to recognise different types of trees\nand use this to classify the composition of a forest. An algorithm could be trained to\nunderstand which trees do well in warmer climates and use this to predict which trees\nwould thrive best if temperatures increased. An algorithm could be written to combine\nboth of these outputs to produce a good recommendation of what kinds of trees\nshould be planted in a particular area.\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202134\n\nThe benefits of AI\nAI can process large amounts of information very quickly. This offers a range of\nopportunities, for example it can:\n●\nimprove the evidence base we use to make policies\n●\nmaximise human resources and reduce environmental impacts by replacing\nsome administrative functions\n●\nhelp us make decisions by providing a range of predictions about the\npotential impact of those decisions\nAI: issues and risks\nAI offers specific benefits but also has particular risks, especially when used in a\npublic sector context where people often do not have a choice over whether or not to\nuse a service.\n●\nAI relies on large quantities of relevant high-quality data, raising questions\nabout how this data should be collected, stored and shared, and according to\nwhat restrictions.\n●\nML relies on algorithms that create their own ways of achieving outputs, this\nmeans that they are not transparent and it will be difficult to give reasons for\ndecisions made by that algorithm.\n●\nIf an algorithm has been trained to operate using poor datasets or based on\ninaccurate assumptions, it may operate in a biased way, and the bias may\nbecome embedded or amplified over time.\n●\nThe combination of sensory technology and powerful algorithms facilitates\nthe capture of a wide range of human information including biometric data.\nThis raises significant issues in terms of privacy and intrusion.\nGovernance context\nThe only current law on AI is the General Data Protection Regulation (GDPR)\ntransposed into UK law through the Data Protection Act 2018. This protects principles\nof data protection including lawfulness, transparency, minimisation and\naccountability. Article 22 protects the right of the individual not to be subject to a\ndecision based solely on automated processing which produces legal effects or\nsimilarly significantly affects him or her.\nIn addition, for public sector decisions the Public Sector Equality Duty (PSED)\nrequires local authorities to have due regard to the need to eliminate unlawful\ndiscrimination, harassment and victimisation; advance equality of opportunity and\nfoster good relations between people who share a protected characteristic and those\nwho do not. The use of AI raises new issues to be considered, including digital\ndiscrimination and algorithmic bias.\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202135\n\nFinally, Article 8 of the Human Rights Act 1998 protects an individual’s right to\nrespect for private and family life, home and correspondence. It is engaged when AI\nis used in partnership with biometric technologies such as Live Facial Recognition\n(LFR) and may need to be considered when, for example, developments are\nproposed that include these technologies.\nThere is a large and growing amount of guidance on the ethical use of AI; these are\nsome of the most relevant and useful sources:\n●\nThe government’sguidanceon use of AI in the publicsector\n●\nThe Committee on Standards in Public LifereportonAI and public standards\n●\nThe Information Commissioner's Office (ICO) and Alan Turing Institutejoint\nguidanceon explaining decisions made with AI\n●\nThe NESTAPrinciplesfor public sector use of algorithmicdecision-making\n●\nThe emerging NationalAI Strategy\nOur Principles\nThese principles are intended to act as a statement of intent, not the answer to every\nrelevant issue, but they form the basis of all of our actions and decisions in relation to\nAI:\n●\nAt all times during the consideration or use of AI there will be a transparent\nchain of responsibility for procurement, implementation, or management of\nthe technology.\n●\nThe public will be informed of any intention to use AI in any process.\n●\nThe proposed use or subsequent modification of an AI system will be subject\nto internal and external consultation.\n●\nProcurement of AI software will include considerations specific to its use,\nincluding whether AI is the best solution to the problem.\n●\nAny decision to use AI will include transparent assessment of risks, benefits\nand mitigations including consideration of cybersecurity, equalities\nimplications, employment implications and risk mitigation.\n●\nAny decision to employ automated capture of biometric information will take\ninto account legal implications and compliance requirements under GDPR,\nPSED and Article 8.\n●\nThere will be robust monitoring of any AI system in use including compliance\nwith GDPR and potential discriminatory outputs.\n●\nAll adopted AI systems will include human oversight and the ability to\nchallenge decisions made using AI.\n●\nThere will be training for members and staff on the benefits, risks and\nmitigations specific to AI and on the responsible use of AI.\n●\nThese principles will be reviewed regularly and at least once a year.\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202136\n\nSection 2 Appendix 2:\nAI procurement checklist\n| The appendices relate toSection 2: Automationof the planning process|\nPrior to procurement\n●\nIdentify the problem you are trying to fix, the likely benefits for the local\nauthority and the public and why there is a need for external procurement.\n●\nLet relevant members and officers know what you were doing, and consider if\nwider internal/external engagement might be useful – for example contacting\nother local councils to see whether this technology has been used before and\nif so what the issues were.\n●\nConsider widening the scope of the exercise to non-traditional suppliers\nincluding academic research institutes, SMEs and startups.\n●\nSet up a team that is as diverse as possible in terms of representation and\nskills, and agree who will have access to what data and information.\nProcurement questions\n1.The algorithm:\n1) How was it trained?\n2) Is it interpretable - can we explain it in a way everyone can understand?\n3) Is there proof of concept?\n4) Who owns it?\n5)Who has the authority to change and/or modify thecode?\n2.The data:\n1) Is there any special category data?\n2) Have open standards been used - and are these standards consistent with\nany industry standard?\n3) Who can use this data in the future\n4) Can the data be shared in the wider public context?\n3.Interoperability:\n1) What software has been used?\n2) How easy/difficult is integration with current systems?\n3) Who is liable for errors?\n4.Equalities issues:\n1) How diverse is the data and is it appropriate for the context?\n2) Was tagging outsourced and if so where to?\n3) How diverse is the team who developed this technology?\n5.Other impacts:\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202137\n\n1) Canexisting staff will be trained to run and maintain the system?\n2) Will there betraining for staff and members?\n6.Future:\n1) Potential for improvements to be built into future operations\n2) Who owns future data?\n3) Will there be regular reports on its usefulness?\nThe decision to procure\n●\nDecide who makes the decision and check that it is covered by the\nconstitution\n●\nCarry out an initial impact assessment including risks, such as impact on\njobs, and benefits, such as savings of time and costs, and legal issues,\nincluding equalities, human rights,General Data ProtectionRegulationand\nEnvironmental Information Regulations\n●\nAddress the interpretability of the algorithm and any mitigation measures\nproposed\n●\nConsider requiring specific contract terms covering:\n○\nResponsibility for each element of the model and any output failures\n○\nData ownership, management and sharing arrangements\n○\nOwnership of algorithm and outputs\n○\nEthical standards – compliance with recognised principles\n○\nDisaster recovery/business continuity and roll-back provisions\n○\nProcess logs andincident management framework\n7.Record the decision in writing with reasons even if the decision is well within\ndelegated powers\nUseful Resources:Office for AI’Guidelines for AIprocurement’, World Economic\nForum ‘AI Procurement in a Box’\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202138\n\nSection 2 Appendix 3:\nReport on adoption of\nchatbot\n| The appendices relate toSection 2: Automationof the planning process|\nTitleAdoption of chatbots for planning queries\nDate\nName:xxx Council\nPurpose of Report:To consider and approve the useof chatbots in the\nplanning service\n1.Executive summary\na.The planning service proposes to implement the use of chatbots in its\nplanning service.\nb.Chatbots are a form of Artificial Intelligence (AI) which is a novel and\ndisruptive technology. The public are entitled to expect that decisions\nto use this technology are taken as transparently as possible, as is\nrecognised by the Centre for Data Ethics and Innovation.\nc.The purpose of this report is to identify the specific issues relevant to\nthe use of this technology so that all implications and benefits are\nclear before it is implemented.\n2.Recommendation\na.The planning service adopts chatbots to deal with routine queries\nwithin the development planning service.\nb.The use of this technology is formally reviewed no less than 12\nmonths from the date of this decision.\n3.The technology\na.Chatbots are conversational tools based on software designed to\nsubstitute human verbal interaction with automated processes to aid\ncustomer service on online platforms. They rely on a number of\ndifferent algorithms:\ni.Robotic Process Automation (RPA): where a robot or bot\nmimics the actions a human takes to complete a specific\ntask such as completing a form;\nii.Natural Language Processing (NLP): a process facilitates\ncommunication between computers and humans,\nrecognising words, their meaning, context and the narrative,\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202139\n\nconverting speech into text that generates automatic replies\nto human queries;\niii.NLP relies on predictive analysis to help to anticipate the\ncontent of the exchange, sentiment analysis to help decide\nthe meaning of a phrase in context and text classifications to\nunderstand specific phrases and colloquialisms.\nb.Chatbots are already in use at theDriver and VehicleLicensing\nAuthority (DVLA)to automate frequent customer enquiriesand by the\nMinistry of Justiceto investigate the usefulnessof different ways of\npresenting information online.\n4.This project\na.The planning service is keen to maximise officer time by focussing\nhuman resources on complex work and areas of the service where\nhuman interaction is most useful.\nb.A significant amount of officer time is currently taken up in answering\nvery routine questions. Members of the public are frustrated by lack\nof access to officers who can answer their questions, especially\noutside office hours and at weekends.\nc.A recent review of resources examined records of telephone inquiries,\nemails and commonly raised concerns and reviewed the existing\nanalytics for the most searched and visited webpages and combined\nthis with feedback from users, advisors and team to identify\nproblems that could be solved by the use of this technology.\nd.It was decided to investigate the potential to use a chatbot to provide\na public service providing automated answers to routine questions\nasked by the public including:\ni.Whether or not a property is listed or subject to other\nsignificant development constraints on development;\nii.The development plan policies relevant to a particular site;\niii.The fees payable for a range of planning applications;\niv.Whether or not consent is required for a specific list of small\nhousehold developments.\ne.XX was selected as the preferred provider for this project because\n(more detail on selection process). In addition, this programme is\nseen as particularly helpful because it has the capacity to record the\nquestions which it cannot answer. This facilitates constant human\nintervention and for new answers to be programmed in, so that the\nsystem improves continuously as it is used.\n5.Risks, benefits and mitigation\na.It is also important that all of the potential risks identified with the use\nof this technology in this context are identified and the mitigations\nthat have been put in place are clearly explained.\nb.The known risks, together with appropriate mitigating measures, are\nset out in this table.\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202140\n\nRiskDetails and mitigation\nOpenness: the decision to use AI\nshould be an open one\n●\nInternal consultation and engagement was carried out. It\nis also intended to carry out a similar engagement\nexercise within six months of implementation of the\nservice.\n●\nThere is no current intention to repurpose the software for\nuse in other services and the council will consult on such\nproposals before they are adopted or implemented.\nData compliance and quality: The use\nof AI technology is considered special\ncategory data by the Information\nCommissioner’s Office (ICO) and has\nparticular regulatory requirements.\n●\nA DPIA (Data Privacy Impact Assessment) has been\nundertaken and will be reviewed regularly. It is available\nas a Background Paper to this report.\n●\nWe used structured data that was carefully sourced\ntagged and organised in a way that was as relevant to\nplanning as possible and we tested response accuracy a\nnumber of times in the process.\n●\nRecords are maintained on the programming of the\nalgorithm, and they are stored and available on request\nfor testing or inspection.\n●\nWe will add and reorganise data as the project develops.\nBias: AI can lead to biased decisions\nfrom flaws in the overall design, from\nthe use of biased data and by the\ncreation of new personal data through\nautomated de-anonymising.\n●\nThe supplier has shown that the system was trained on\ndatasets that were sufficiently broad, covering all relevant\ndimensions of gender, ethnicity and other possible\ngrounds of prohibited discrimination.\n●\nWe have documented what the model optimises for and\nwhich weights are designed to certain parameters..\n●\nAn EQIA (Equalities Impact Assessment) has been\nundertaken and will be reviewed regularly. It is available\nas a Background Paper to this report.\nAccessibility: The service needs to be\nuser-friendly so that it does not exclude\nmembers of the community who do not\nhave digital skills.\n●\nThe service is easily identifiable within the council’s\nwebsite.\n●\nIt is clear to anyone using the service that they are not\ntalking to a real person.\n●\nUsers have the option to download and/or have\ntranscripts of their exchange emailed to them.\n●\nWhere users do not have access to a computer or are\nuncomfortable engaging with a chatbot, they can always\nspeak to a member of staff.\nSecurity: The technology may be\nvulnerable to being hacked. It must also\nintegrate fully with the council’s existing\nsoftware.\n●\nThe system has been designed to self-report on its\naccuracy during all life cycle phases including all errors or\ninconsistencies.\n●\nLiability for design flaws has been assigned to the\nsoftware developer within the contract for the service.\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202141\n\n●\nThe software used to build the chatbot is Microsoft\nAzure, a cloud computing service that enables\napplications to be built, tested, used and managed\nthrough Microsoft data centres. This enables full\nintegration with all existing systems and ensures\nresilience to cyber attacks.\n●\nAlthough the software is externally provided the system\nwill be operated by council officers who will be fully\ntrained in its use.\nOpacity: The algorithm has the capacity\nto self-learn. As it becomes more\nsophisticated it will become more\ndifficult to explain or challenge what it\ndoes.\n●\nWhile the algorithm is capable of working autonomously\nits basic function has been defined and constrained by\nhuman developers.\n●\nOutputs are regularly reviewed and validated by humans.\n●\nThere is a retained human function of human intervention\nand/or deactivation, implementable in real time.\n●\nThe system is regularly monitored and reported on.\nHuman Impact\n●\nThe adoption of this technology is not expected to lead\nto any loss of jobs.\n●\nFuture impacts of the wider adoption of this technology\nwill be mitigated by offering all members of staff access\nto training on use of AI systems and the development of\ndigital skills.\n6.Benefits\na.\nIt is expected that this technology could automate up to 60% of\nroutine queries, which will improve our responsiveness as a service.\nb.Staff time will be freed up to deal with more complex applications\nwhere human input is required, which will also benefit the service as\na whole.\nc.Testing the technology in one service and in a relatively limited\ncontext will inform wider adoption of this technology in other services\nand help set a sound foundation for the use of more complex and/or\npervasive technologies in the future.\n7.Options\na.The council could decide not to adopt the technology or to adopt this\ntechnology on a strictly temporary basis.\n8.Conclusion\na.Although there are some novel issues associated with the use of a\nchatbot, in this context the risks have been clearly identified and are\nsufficiently mitigated.\nb.\nThis decision is consistent with our strategic policiesthe UK\ngovernment guidance ‘Using chatbots and webchat tools’and the\nreport‘Artificial Intelligence and Public Standards’,and is informed by\n‘Chatbots RESET A Framework for Governing ResponsibleUse of\nConversational AI in Healthcare’ produced by the WorldEconomic\nForum.\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202142\n\nc.The technology is recommended for adoption, subject to a review of\nits use no later than twelve months from today.\nBackground Paper: Data Protection Impact Assessment\nBackground Paper: Equalities Impact Assessment\nOpen Data InstituteODI Fellow Report: Digital planning and its implications | July 202143","version":"1.10.100"}