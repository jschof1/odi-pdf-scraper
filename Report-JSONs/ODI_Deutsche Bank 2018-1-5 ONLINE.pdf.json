{"numpages":20,"numrender":20,"info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Adobe InDesign CC 13.0 (Macintosh)","Producer":"Adobe PDF Library 15.0","CreationDate":"D:20180105122911Z","ModDate":"D:20180105122914Z","Trapped":{"name":"False"}},"metadata":{"_metadata":{"xmp:createdate":"2018-01-05T12:29:11Z","xmp:metadatadate":"2018-01-05T12:29:14Z","xmp:modifydate":"2018-01-05T12:29:14Z","xmp:creatortool":"Adobe InDesign CC 13.0 (Macintosh)","xmpmm:instanceid":"uuid:3c9136e1-f1b4-f748-9b64-7f5cad1c6404","xmpmm:originaldocumentid":"xmp.did:02774db3-794f-4b6b-9d8b-1cf3c4d3c759","xmpmm:documentid":"xmp.id:7c510f1b-c72a-456b-9484-33325f2ec56c","xmpmm:renditionclass":"proof:pdf","xmpmm:derivedfrom":"xmp.iid:fc52c9ff-7e93-4f89-90bd-6b793ad52419xmp.did:fc52c9ff-7e93-4f89-90bd-6b793ad52419xmp.did:02774db3-794f-4b6b-9d8b-1cf3c4d3c759default","xmpmm:history":"convertedfrom application/x-indesign to application/pdfAdobe InDesign CC 13.0 (Macintosh)/2018-01-05T12:29:11Z","dc:format":"application/pdf","pdf:producer":"Adobe PDF Library 15.0","pdf:trapped":"False"}},"text":"\n\nOpen Data Institute / Whitepaper ODI-WP-2018-001\nLibby Young, Amanda Smith, Simon Troup\nOpen Data Institute supported by Deutsche Bank\nUsing data to take \nan open approach to \ninvestment banking\n\n\n\nContents\nOpen Data Institute 2017 / Whitepaper   Using data to take an open approach to investment banking 3\n4 About\n5 Executive summary \nDraw on industry expertise with an independent facilitator    5\nManage control and access of data    5\nAssess opportunities for a more open approach that creates \n \nlong-term value    5\n6 About the investment banking sector\n7 What is the challenge?\n9 Defining data infrastructure for investment banking \nWhat data assets are produced in investment banking?     9\nWhat technologies and processes are used in investment banking?    10\nWhat organisations are involved in investment banking?    11\n12 Building a more open data infrastructure\nThe Open Banking Standard    12\nThe Open Protocol    12\n13 Recommendations\nDraw out industry expertise via working groups     13\nManage control and access of data     13\nAssess opportunities to create long-term value    13\n14 Open approaches to data problems: existing policies and technologies\nCollaborative maintenance models     14\n Case study: Legislation.gov.uk    14\n Case study: OpenStreetMap    14\nUsing open data to map beneficial ownership    14\n Case study: OpenCorporates    15\nOpen standards for data    15\nOpen registers and APIs    15\nOpen source code and shared vocabularies     15\nBlockchain technology    16\n Case study: Everledger     16\n Case study: Provenance    16\n17 Conclusion\nAnnex: The ODI’s design principles for data infrastructure    17\nBibliography    18\n\nOpen Data Institute 2017 / Whitepaper   Using data to take an open approach to investment banking 4\nAbout\nThis report was produced by the Open Data Institute and \nsupported by Deutsche Bank. \nAbout the ODI \nThe ODI works to build a strong, fair and sustainable data \neconomy by helping governments and businesses around \nthe world get data to people who need it. It is independent, \nnonprofit and nonpartisan, founded in 2012 by Sir Tim \nBerners-Lee and Sir Nigel Shadbolt. From its headquarters \nin    London and via its global network of startups, members \nand nodes, the ODI offers training, research and strategic \nadvice for organisations looking to explore the possibilities \nof data.\nAuthors: Libby Young, Amanda Smith, Simon Troup \n \nEditors: Anna Scott and Charlotte Fleming \nDesign and art direction: Adrian Philpott / PHILPOTT design\n\nOpen Data Institute 2017 / Whitepaper   Using data to take an open approach to investment banking 5\nExecutive summary\nInvestment banking is one of the world’s oldest and most data-rich \nindustries. It provides a large range of financial products and services \nto businesses, governments and investors, helping them to grow and \nto manage risk. The sector is undergoing significant change: adopting \nnew technologies and regulations, transforming organisational \ncultures and reducing costs.\nInvestment banks collect, share \nand use data every day to make \ndecisions and execute \ntransactions.\nThe return on data held by banks has historically been limited \nby a low interest in data infrastructure amongst client-facing \nteams and friction in data processing.\nHowever, as clients want more data – and as technology \nadvances and costs less – a more open approach is \nemerging. At the same time, regulators are mandating banks \nto share more, and the growth of open data in other sectors \nhas shown its positive impact on innovation. A more open \ndata infrastructure in investment banking is inevitable, and \nbanks must respond and adapt in a timely and \ninformed manner. \nThe ODI wants to support this shift by facilitating a discussion \non investment banking data infrastructure, and working with \nstakeholders to identify, test and implement solutions that \nmake data more accessible. This report considers:\n the sector’s existing data infrastructure – in terms of data \nassets, processes, technologies and organisations\n where data assets are currently mapped on the Data \nSpectrum, from closed to open\n challenges and opportunities in using open data to create \na strong data economy\n open data case studies from other industries\nTo take an open approach to the investment banking sector’s \ndata infrastructure, we make the following recommendations.\nDraw out industry expertise via \nworking groups\n Working groups can help bring industry \nexpertise into an agile decision-making \nframework. Working groups could \nharness collective insights from banks \ninto where the greatest data challenges lie. \nManage control and access \nof data\n Organisations can be protective of the \ndata they control, because of the \ncompetitive advantages they think it \naffords them. However many groups \nhave a stake in banking data – clients, \ncompetitors and wider ecosystems. \nOpen solutions can provide more flexible \nways to manage how data is controlled \nand accessed. \nAssess opportunities for a more \nopen approach that creates \nlong‑term value\n An open solution that serves the needs of \nall key stakeholders ensures committed \nand aligned participation from across the \nindustry. Some organisations committing \ntime or capital may not experience an \nimmediate return on investment from \na   more open data infrastructure, \nbut sustainable data initiatives will \nultimately benefit all industry participants. \nThe report then highlights existing policies and technologies \nthat the investment banking sector can take inspiration from \nin finding open approaches to data problems: collaborative \nmaintenance models, mapping beneficial ownership, open \nstandards, open registers and APIs, open source code and \nshared vocabularies and blockchain technology.\n\nOpen Data Institute 2017 / Whitepaper   Using data to take an open approach to investment banking 6\nRegulators, industry bodies and investment banks are \nexchanging vast amounts of public and private data, while \nthe latter facilitates the movement of investment capital \naround the world. In this modern manifestation, data is \nparticularly valuable to building trust and understanding risk. \nIn recent years, efforts by regulators to improve transparency \nand stability\n[1]\n in the sector have significantly increased costs \nfor investment banks,\n[2]\n as they struggle to keep up with \ndemand for better ways to track and secure data that is \nexchanged. Low interest rates and advances in technology \nhave also put pressure on traditional operating models.\nAt the same time, the speed of technology and infrastructure \ninnovation in capital markets – where investment banks \nprimarily operate – has been slower than in retail and \ncorporate banking.\nThe role of investment \nbanking has changed \nover the years.\nInvestment banks emerged in the 1400s to support \nmerchants trading in goods such as silks, metals and spices. \nIn these early manifestations, trust and risk management \nwere important measures for those using these services. \nSince then, the role of investment banking has changed, and \nthe sector has continued to adapt at the centre of a complex \nnetwork of institutions. \nAbout the \ninvestment  \nbanking sector\nInvestment banks are at the centre of a complex network moving capital around the world\nRegulators and industry bodies\nFinancial Conduct Authority\nPrudential Regulation Authority\nIndustry bodies     \nInvestment\nbanks\nMarket particpants\nAsset managers\nCustodians\nInsurers\nTechnology and data\nData and terminal vendors\nMessaging networks\nSettlement technology\nExchanges and clearing houses\nClearing houses\nExchanges\nMultilateral trading facilities\nFigure 1: Investment banks are at the centre of a complex network, moving capital around the world.\n1 Bank for International Settlements (2012), ‘Principles for financial market \ninfrastructures’, http://www.bis.org/cpmi/publ/d101.htm.\n2 L Michael Meyer (2016), ‘Regtech 123’, https://www.linkedin.com/pulse/regtech-1-2-\n3-l-michael-meyer-cfa?trk=hp-feed-article-title-like.\n\nOpen Data Institute 2017 / Whitepaper   Using data to take an open approach to investment banking 7\nIn researching this paper, sector participants highlighted \nthree broad data challenges in investment banking:\nSearch: discoverability and accessibility of data\nTrust: transparency of data provenance\nQuality: accuracy and timeliness of data\nAt the organisational level, the relevance of each data \nchallenge varies across different parts of a bank. Bespoke, \nlower frequency investment banking services (top-left in \nFigure 2, overleaf) rely more on search and trust – here, \ndata has a material impact on reputational, counterparty \normarket risk. Higher-volume and more commoditised \nbusinesses (bottom-right) tend to focus on data quality and \ncost – they use large amounts of data where errors have a \nsmaller economic impact per transaction, but in aggregate \nare material. \nThe following three examples demonstrate the breadth \nof impact that more open and shared data could have in \nthe sector.\n1)    Historically proprietary reference data – for example, \nBloomberg’s Instrument Reference Data or Reuters \nInstrument Codes (RIC) – add costs and processes to \ndata access and collection, as well as the potential for \nerrors. A more open infrastructure could remove these \nbarriers, something which is already being explored by \nThomson Reuters in the form of PermID.\n[6]\n \n2)    Know‑Your‑Customer (KYC) processes and \nregulations – which guide identity management and \nhelp to establish data provenance – can be a burden for \nbanks and clients alike. A global survey carried out by \nThomson Reuters found that the average onboarding had \nreached 26 days, and half of those respondents thought \nthe time taken to onboard would increase in the coming \nyear.\n[7]\n Furthermore, annual KYC costs for large \nintermediaries can be several hundred million dollars. \nAlthough a handful of utility-like KYC entities selling \ndue diligence data services have emerged in recent \nyears, KYC remains cumbersome and costly. A more \ncollaborative, sector-wide process with the appropriate \npermissions could simplify counterparty risk \nmanagement, improve customer experience, and \naggregate data to develop new client services. \nData is underused \nin investment banking.\nInvestment banks, their clients and regulators, increasingly \nview data as an underused strategic asset and are actively \nexploring new ways to maximise its value and potential.\nThree factors in particular are driving this shift: \n the industry’s growing recognition of shared needs that \nit can collectively address and benefit from\n clients and regulators requiring more and better data, \nand clients in particular looking for ways to access data \nthat match advances in consumer technology \n innovation in other industries being driven by more \nopen infrastructures\nThe sector collects, shares and uses vast quantities of data \nevery day, primarily via transactions. In 2015, the value of \nshares traded was $99.8 trillion\n[3]\n (greater than global GDP), \nand the harder-to-track derivatives market is estimated to \nbe at least 20 times that. \nOperationally, administrative data and data-related tasks \nalone are estimated to generate $4.4bn annually in IT and \nprocessing costs.\n[4]\n And while 70% of investment banks \nknow data quality affects costs, only 11% actively measure \nthe cost of bad data quality.\n[5]\n Finally, 80% of any bank’s data \nis unstructured and dynamic, which the sector is only in its \nearly stages of exploring how to use.\nWhat do we mean by static and dynamic data? \n‘Static’ data is a fixed dataset that does not change \nonce it is created. ‘Dynamic’ data changes as further \ninformation becomes available. \nWhat is the \nchallenge?\n3 The World Bank (2017), ‘Stocks traded, total value’  \nhttp://data.worldbank.org/indicator/CM.MKT.TRAD.CD.\n4 BCG Perspectives (2016), ‘Fintech in Capital Markets: A Land of Opportunity’ https://\nwww.bcg.com/en-gb/publications/2016/financial-institutions-technology-digital-\nfintech-capital-markets.aspx.\n5 Accenture (2016), ‘Reference Data Management: Understanding True Cost’, https://\nwww.accenture.com/t20151202T165846__w__/us-en/_acnmedia/Accenture/next-\ngen/top-ten-challenges/challenge3/pdfs/Accenture-2016-Top-10-Challenges-03-\nReference-Data.pdf.\n6    See: https://permid.org.\n7 Thomson Reuters (2017), ‘KYC onboarding still a pain point for financial institutions’, \nhttps://blogs.thomsonreuters.com/financial-risk/know-your-customer/kyc-onboarding-\nstill-a-pain-point-for-financial-institutions.\n\nOpen Data Institute 2017 /     Using data to take an open approach to investment banking 8\n1) The Markets in Financial Instruments Directive (MiFiD \nII), comes into effect in Europe in January 2018. The \ndirective aims to enhance market efficiency and \nresilience and will impact the entire trade lifecycle and all \nasset classes. It also increases requirements for real-time \ndata and effectively mandates institutions to develop \nmore open data infrastructure internally. If banks agree \nstandards for sending data to Data Reporting Services \nProviders (DRSPs), over time those standards could be \nused to communicate directly with each other, speeding \nup execution and settlement processes, improving \ncounterparty risk management capabilities, and possibly \nleading to new services.\nMany institutions manage their data in silos, with \nunnecessary duplication and poor integration across different \nbusiness lines and functions. An internal reorganisation of \ndata is a major challenge, but could also reveal ways these \nnewly aggregated datasets could be appropriately \nrepurposed and shared to advance the sector’s core services. \nIncreasing\nFocus on\nreputation\nFocus on\nrelationships\nHigh touch\nIncreasing\nCommoditisation\nFocus on the machine\nLow touch\nTransaction\nvolume\nTransaction\ncomplexity\nInvestment bank services range from complex & bespoke to commoditised & high volume\nCorporate\nfinance \nFreight\nbrokerage\nOTC\nderi vatives\nPri me \nbrokerage\nCommodities\nExch  ange\ntraded\nderi vatives\nBond sa  le s\nand trading\nEquities and \nsales trading\nFX and \nmoney \nmark et \ntrading\nFigure 2: Investment bank services range from complex & bespoke to commoditised & high-volume.\n\nOpen Data Institute 2017 / Whitepaper   Using data to take an open approach to investment banking 9\ncategories: contracts, identities and securities, which are \ntypically more static (i.e. do not change once created); and \nledgers and transactions, which are typically more dynamic \n(i.e. change as further information becomes available). \nEach of these categories of data can be mapped to the Data \nSpectrum.\n[10]\n Client contracts would represent ‘closed’ data \nand be kept private, while identities are ‘shared’ within or \nbetween contracting organisations. Ledgers are ‘shared’ with \nregulators and shareholders, and transactions reported by \nexchanges and securities information are made public, \nalthough not necessarily ‘open’, for anyone to access, use \nand share.\nThere are many opportunities to address challenges and \ncreate business value by moving data towards the more \nopen end of the spectrum. Simply including a maintenance \nAPI in an individual bank’s securities system could extend the \ncommunity of data contributors within the organisation \nbeyond a central team. This captures benefits of open \nnetworks, such as getting more perspectives scrutinising \ndata to improve its quality and empowering a more diverse \ngroup of users to fix it. \nEach sector is underpinned by \ndata infrastructure – datasets, \ntechnologies and processes, \nalong with the organisations\n \nthat maintain and govern them. \nData sits on a spectrum, falling between closed data \n(typically used internally within institutions), shared data \n(accessible to groups across institutions and sometimes paid \nfor), and open data (available for anyone to access, use and \nshare).\n[8]\n The more open and accessible an industry’s data \ninfrastructure, the more trust and value it tends to create.\n[9]\n \nWhat data assets are produced in \ninvestment banking? \nThe highly transactional nature of investment banking creates \nvast quantities of data daily that constantly need to be stored, \naccessed and updated. There are many ways to categorise \nthis data, but it can be broken down into five broad \nDefining data \ninfrastructure for \ninvestment \nbanking \nData categoryExample/s from the investment banking sector\nContracts\nCounterparty agreements for derivatives transactions\nIdentities\nClient identities, Know Your Client (KYC), risk profiles\nLedgers\nAccounts (exposures, positions, custody records)\nTransactions\nOrders, executions, confirmations, settlements (MiFID)\nSecurities\nInstrument identifiers (Sedol, Ticker), Pricing, Initial Public Offering (IPOs), Bonds\n8 The Open Data Institute (2017), ‘The Data Spectrum’, theodi.org/data-spectrum.\n9 The Open Data Institute (2017), ‘Principles for strengthening our data infrastructure’ \ntheodi.org/guides/principles-for-strengthening-our-data-infrastructure.\n10   The Open Data Institute (2017), ‘The Data Spectrum’, theodi.org/data-spectrum.\n\nOpen Data Institute 2017 /     Using data to take an open approach to investment banking 10\nWhat technologies and processes are  \nused in investment banking?\nAfter the ‘Big Bang’ in 1986, when financial markets were \nderegulated and the London Stock Exchange was reformed, \nthe sector saw a move from traditional face-to-face share \ndealing to electronic markets. This brought a drive towards \n‘straight through processing’ (STP) to optimise transaction \nprocessing speeds, using tools and standards that were new \nat the time such as Extensible Markup Language (XML) and \nlarge-scale messaging infrastructure. Benefits included \nridding the process of paper-based trading and creating \nelectronic markets. \nInvestment banking has become increasingly commoditised \nwith a greater focus on centralised data services and a \nplatform approach. Underpinning banking technology are \ndata standards and shared vocabularies, such as data \nnaming and definition, interfaces including real-time and \nintermittent interactions, and technical data infrastructure, \nsuch as databases, cloud and SaaS. Banks have become \nincreasingly ‘joined up’ with core investment activities; \nfinance, risk and compliance functions, serviced by \ncentralised technology teams, for example.\nWhat does ‘open’ mean for investment banking? \nOpen data is data that anyone can access, use or share. \nAn ‘open’ application programming interface (API) does \nnot automatically make the data it is delivering open, \nrather its technology and the standard itself. The data \ncould be made accessible by being ‘shared’ or made \n‘open’. Shared data would only be accessed with \nappropriate permission (whether from an individual or \nbusiness), and subject to the API’s approved security \nand technical standards.\n \n \nHowever, it is not appropriate to make all data open: data \nshould be kept closed or shared where is it necessary to \nprotect personal or commercial privacy. That said, where \ndata is kept closed or shared, it should not be because of \nhabit, or a lack of knowledge about the possibilities created \nby open and accessible data. It is important to make \ndeliberate decisions about how accessible data should be or \nwhere it should be on the spectrum.\nTransactionsIdentitiesLedgersContracts\nVia authenticationLicence that \nlimits use\nExplicitly\nassigned\nEmployment\ncontract \n+ policies\nOpen licence\nOpen\nSmall  /  Medium  /  Big data\nPersonal  /  Commercial  /  Government data\nSharedClosed\nSecurities\nGroup-based\naccess\nPublic\naccess\nNamed \naccess\nInternal \naccess\nAnyone\nThe Data Spectrum helps you understand the language of data.theodi.org/data-spectrum\nThe Data Spectrum: Investment banking sector\nFigure 3: The Data Spectrum that the ODI proposes for the investment banking sector.\n\nOpen Data Institute 2017 / Whitepaper   Using data to take an open approach to investment banking 11\nWhat organisations are involved in \ninvestment banking?\nAs intermediaries, investment banks sit at the centre of a \ncomplex network of institutions and data flows. Market \nparticipants, exchanges and clearing houses collectively \ndeliver a robust infrastructure of capital markets, overseen by \nregulators and supported by technology and data services. \nOnly through engagement with all stakeholders can banking \ninfrastructure become more open, transparent and robust, \nor deliver a lasting trust. While regulators such as the \nPrudential Regulation Authority (PRA)\n[11]\n protect the public \nfrom systemic risk, understanding the network of \ntransactions and connected entities is essential. When a \nregulator stress-tests the market for the failure of a bank, \nthey need to understand: \n the transactions that bank is engaged in, such as the \nexchange of financial instruments between parties \n(or ‘swaps’), which occur on a daily basis\n who holds debt that may default\n which hedge funds hold collateral that could be lost in \nan insolvency\nTwo trends worth noting here are the innovative regulatory \nsandboxes being championed in the UK\n[12]\n and Australia,\n[13]\n \nand the industry’s increasing commitments to accelerators \nand collaborative partnerships with new fintech\n[14]\n entrants. \nBoth these developments are indicative of a more \ncollaborative and innovative culture and bode well for the \ndevelopment of an open data infrastructure in \ninvestment banking.\n11 Bank of England (2017), ‘Prudential Regulation Authority’,  \nhttp://www.bankofengland.co.uk/pra/Pages/default.aspx.\n12 Financial Conduct Authority (2015), ‘Regulatory Sandbox’,  \nhttps://www.fca.org.uk/firms/regulatory-sandbox.\n13 Australian Securities & Investment Commission (2017), ‘Innovation Hub’,  \nhttp://asic.gov.au/for-business/your-business/innovation-hub/.\n14 BCG Perspectives (2016), ‘Fintech in Capital Markets: A Land of Opportunity’, \nhttps://www.bcgperspectives.com/content/articles/financial-institutions-technology-\ndigital-fintech-in-capital-markets/#chapter1.\n\nOpen Data Institute 2017 / Whitepaper   Using data to take an open approach to investment banking 12\nshared and used by its owners and those who access it.\n[16]\n This \nis being carried out by an Open Banking Implementation Entity. \nWhile PSD2 undoubtedly increases costs and competition \nfor incumbent banks in the short-term, those who have \nembraced the open standard in the UK are starting to \ndemonstrate its value – banks are giving developers access \nto    their APIs, and their Open Up Challenge has been designed \nto drive innovation for their customers and themselves.\n[17 ]\nThe Open Protocol\nThe Open Protocol is an open standard created for the hedge \nfund industry.\n[18]\n It standardises how hedge funds collect, \ncollate and convey risk data, making aggregated risk \nreporting (ledgers) more accessible and accurate for clients \nand regulators. The data is not centrally held, and hedge fund \nmanagers have complete control over the data and how it \nshould be distributed.\n[19]\nThe implementation process from inception to launch and \nadoption took nine months. This speed and impact was \nachieved due to:\n a common need and purpose shared by hedge funds, \ninvestors and regulators\n the absence of a commercial agenda for the initiative itself \n(with a clear path to value-generation for all participants) \n the leadership of an independent working group using an \nopen and federated approach \n a collaborative and iterative process, with input from \nindustry bodies and regulators observing the collaboration, \nand refinement by public consultation\nThe solution is simple and pragmatic: templates give \ninvestors access to standardised Value at Risk (VAR) \nnumbers by asset class, sector and region, and shows \nexplicit properties of the risk methodology being applied. By \nusing standard templates to collect information, the industry \ngets a flexible and transferable framework for risk \naggregation and information exchange. An accompanying \nmanual sets out the processes to populate the templates to \nproduce a standard output.\nThe Hedge Fund Standards Board (HFSB) has become the \nco-chair of the Open Protocol Working Group and has been \nadded to the Standards Body for Alternative Instruments (SBAI) \ntoolbox.\n[20]\n The Open Protocol template is currently used by \nfunds with over $1 trillion in assets under management.\n[21]\nStrengthening data infrastructure \nand making it as open as \npossible presents opportunities \nfor investment banking.\nThe Open Banking Standard\nIn the UK, the CMA-endorsed Open Banking Standard for \nretail and corporate banking offers an example of an open \napproach being applied to improve efficiency and \nstimulate innovation.\n[15]\n \nThe Open Banking Standard was developed by the Open \nBanking Working Group (OBWG) to guide how open banking \ndata should be created, shared and used. \nNew legislation – the Revised Payment Service Directive – \nwill come into effect in January 2018, mandating banks within \nthe EU to offer open application programming interfaces \n(APIs) to licensed third-parties, who can provide account or \npayment services to customers. The directive is intended to \nimprove innovation and give customers more choice. \nThis prompted the OBWG to be set up, at the request of \nHM Treasury, to explore how data could be used to help \npeople to transact, save, borrow, lend and invest their money. \nMaking it possible to share data that banks have historically \nheld can improve people’s banking experience. For example, \nwhen data is securely shared or published openly using \nopen APIs, it can be used to build useful applications and \nresources to help people find what they need. Customers \ncan look for a mortgage more easily, banks can find \ncustomers matched to a new product, and businesses can \nshare data with their accountants. This, in turn, will improve \nefficiency and stimulate innovation. \nThe OBWG collaboratively developed an Open Banking \nStandard to guide how open banking data should be created, \nBuilding a more \nopen data \ninfrastructure\n15 The Open Data Institute (2015), ‘The Open Banking Standard’,  \nhttp://theodi.org/open-banking-standard.\n16 Open Banking (2017) ‘About Open Banking’,  \nhttps://www.openbanking.org.uk/about.\n17 NESTA (2017), ‘Open Up Challenge’,  \nhttp://www.nesta.org.uk/project/open-challenge.\n18 The Open Protocol (2017), ‘Open Protocol’, http://www.theopenprotocol.org.\n19 Ibid.\n20   Standards Board for Alternative Investments (2017), ‘Toolbox’,  \nhttp://www.sbai.org/toolbox.\n21 The Open Protocol (2017), ‘Open Protocol’, http://www.theopenprotocol.org.\n\nOpen Data Institute 2017 / Whitepaper   Using data to take an open approach to investment banking 13\nAssess opportunities for a more open approach \nthat creates long‑term value\nAn open solution that serves the needs of all key \nstakeholders ensures committed and aligned participation \nfrom across the industry. Some organisations committing \ntime or capital may not experience an immediate return on \ninvestment from a more open data infrastructure, but \nsustainable data initiatives will ultimately benefit all \nindustry participants. \nThe Open Protocol demonstrates how fast and effective \nimplementation can be when key industry stakeholders all \nhave a clear rationale for collaborating – hedge fund \nmanagers, institutional investors and regulators all benefit \nfrom its structured risk framework. \nOne area where there may be a clear and immediate need is \nregulation. Another area where there is a clear rationale for an \nopen approach, but perhaps less impetus for change, is the \noverall trade life cycle.\nBy using these three techniques, the investment banking \nsector would be able to understand the value of collaborating \non a more open data infrastructure, which could lead to \nspecific datasets and processes to be developed and \nopened up. \nThe ODI’s principles for data infrastructure provide a \nframework against which to apply these three techniques. \nSee the Annex for more. \nWe recommend three ways to \nmake data infrastructure for \ninvestment banking stronger \nand more open.\nDraw out industry expertise via  \nworking groups \nWorking groups can help bring industry expertise into an \nagile decision-making framework. For the investment \nbanking sector, working groups could harness collective \ninsights from banks into where the greatest data \nchallenges lie.\nSetting up these groups can be difficult, with coordinating \norganisations needing to engage many market participants. \nHaving one or two organisations in a trusted, independent \nposition to convene and facilitate is key. \nFor example, the Open Protocol began as a joint effort \nbetween regulators and the online hedge fund community \nThe Albourne Village,\n[22]\n both well-aligned with the hedge \nfund industry. The Open Banking Standard was a joint effort \nbetween the UK government and the retail banking sector, \nfacilitated by the ODI. \nManage control and access of data \nOrganisations can be protective of the data they control, \nbecause of the competitive advantages they think it affords \nthem. However many groups have a stake in banking data \n– clients, competitors, regulators and wider ecosystems. \nOpen solutions can provide more flexible ways to manage \nhow data is controlled and accessed. We encourage \ninvestment banks to review our proposed Data Spectrum for \ninvestment banking to see how it aligns with their existing \ndata asset registers and flows.\nThe Open Protocol’s methodology for describing risk allows \nasset managers and investors to retain a level of control over \ndata storage and distribution. The Open Banking Standard \ngives retail bank customers more control over data about \nthem, and the ability to decide who they share data with.\nRecommendations\n22 Albourne Village (2017), ‘The Albourne Village’, https://village-eu.albourne.com.\n\nOpen Data Institute 2017 / Whitepaper   Using data to take an open approach to investment banking 14\nCase study: OpenStreetMap\nOpenStreetMap has demonstrated how collaborative \nmaintenance is an extremely efficient way of managing \nrapidly evolving data.\n[25]\n Following the 2010 Haiti \nearthquake, emergency services lacked an up-to-date map \nof roads and the newly established resources and camps \nthat supported relief efforts. With the help of satellite \nimagery and volunteers, NGOs were equipped with digital \nmaps within days.\n[26]\n OpenStreetMap empowered users to \ntake control of data about them, improving quality and \nmaking content more reactive to change. \nIn investment banking, testing and implementing this \napproach could begin with technically simple models such \nas registers\n[27]\n (explained further in the ‘Open registers and \nAPIs’ section) and focus on necessary but non-\ncompetitive datasets. \nFor this, the investment banking sector should seek to explore:\n how sector registers might work with a more open model \n if register members could take a more direct role in \nmaintaining data about themselves\n what data governance processes would be needed to \nmake that work\n what value a more open model would create\nUsing open data to map beneficial ownership\nThe securities lending market has become a particular focus \nin regulators’ efforts to promote market stability and enhance \ncorporate transparency. Open data can better track the true \nbeneficial owners of securities to prevent fraud, money \nlaundering and corruption.\n[28]\n They can also help ensure \nproxy votes contributing to decisions on management pay \nawards, and ensure other topics are more transparent \nand accountable. \nPatterns are emerging in how \npolicies and technologies are \nbeing used to solve data \nproblems across sectors.\nWith the investment banking sector prime to explore better \nways to maximise data’s value and potential, it can be useful \nto consider policies and technologies for collecting, sharing \nand using data that have been developed to achieve the \nsame aim across different sectors. \nCollaborative maintenance models \nCollaborative maintenance models help mitigate the cost of \nmanaging and updating data across a community of users, \nwhile improving data discoverability and quality, improving \naudit and control capabilities, and facilitating engagement \nand innovation. The legislation.gov.uk and OpenStreetMap \ncase studies below show how such a model can work.\nCase study: Legislation.gov.uk\nHistorically, it has been hard to maintain legislation in \naccessible and up-to-date formats. The National Archives’ \nLegislation.gov.uk overcame this challenge by using an \nopen API and a collaborative maintenance model.\n[23]\n Their \ninnovative ‘expert participation programme’ includes \nparticipants from public and private sector groups who all \nsaw the value that open, up-to-date legislation would bring \nthem. As a result, in the last few years over half of the \nupdates to legislation have been made by these experts, \nfive times faster than before and bringing 80% of all \nlegislation\n[24]\n on the website up to date. \nOpen approaches to \ndata problems: existing \npolicies and technologies\n23 See: http://www.legislation.gov.uk.\n24 The Open Data Institute (2017), ‘Case study: Legislation.gov.uk’,  \nhttps://theodi.org/case-studies/case-study-legislationgovuk. \n25 See: https://www.openstreetmap.org/about. \n26 Wikipedia (2017), ‘OpenStreetMap’,  \nhttps://en.wikipedia.org/wiki/OpenStreetMap#Humanitarian_aid. \n27 Government Digital Service (2015), ‘Registers: authoritative lists you can trust’, \nhttps://gds.blog.gov.uk/2015/09/01/registers-authoritative-lists-you-can-trust/.\n28 Open Ownership (2017), ‘About the project’, http://openownership.org/about.\n\nOpen Data Institute 2017 / Whitepaper   Using data to take an open approach to investment banking 15\nIn private markets, such as OTC derivatives, friction is \nusually caused by discoverability and accessibility of data, \nparticularly around contracts and identifiers. It is hard to find \nor transfer the data attached to a new derivatives transaction. \nIf banks collectively solved data discoverability issues in \nprivate markets, it would create opportunities to transfer \nthese learnings into a new model for public markets.\nOpen registers and APIs\nA register is an authoritative list of data that can be trusted. \nAn open register can move beyond relying on datasets that \nare updated periodically and may have errors, to operating \non data that is trustworthy, standardised and open for \nscrutiny and improvement. An open API is an application \nprogramming interface that provides access for all to a web \nservice or software application. It does not necessarily make \nthe data it is delivering open, but makes the technology and \nthe standard itself open. \nOpen registers and APIs for data that is not commercially \nsensitive (but is required to execute transactions) could \nprovide significant opportunities for investment banking. \nA simplified and coordinated standard for country, bank and \naccount codes could be accessed by open registers and/or \nopen APIs and reduce the number of steps required to \nexecute an international transfer, thereby reducing the \nnumber of transfer failures caused by data issues. \nOpen source code and shared vocabularies \nOpen source code can be inspected, modified and enhanced \nby anyone.\n[31]\n Projects that use open source code include the \nOpen Artificial Pancreas System (APS) project, which is an \nopen and transparent effort to make safe and effective basic \nAPS technology widely available to reduce the burden of \nType 1 diabetes.\n[32]\n Open source code is also adopted by \nGnuCash, which provides free accounting solutions for \npersonal and small business accounts.\n[33]\nShared (or standardised) vocabularies help facilitate inclusion \nand interoperability, for example, the Data Catalog \nVocabulary (DCAT) is a vocabulary designed to facilitate \ninteroperability between data catalogs published on the web. \nBy using DCAT to describe datasets in data catalogs, \npublishers increase discoverability and enable applications \neasily to consume metadata from multiple catalogs.\n[34]\nInvestment banks have long been users of open source code \nin their back office operations, but embedding it into \ninteractions with clients, regulators and shareholders offers \nopportunities to create value. \nSome investment banks have begun giving clients access \nto open source technology, and open source code and data \nontologies are emerging, particularly in reporting. The open \nbusiness reporting language by extensible business reporting \nlanguage (XBRL) can be used for both regulatory and \nshareholder reporting. OpenGamma helps derivatives \nmarket participants implement new International Swaps and \nDerivatives Association (ISDA) standards to calculate how \nmuch capital must be put aside for certain types of trades.\n[35]\n \nCase study: OpenCorporates\nOpenCorporates is the largest database of companies in \nthe world, with data from 116 million firms in 119 \njurisdictions.\n[29]\n Its founders saw that open company data \nfrom central governments was valuable but hard to search \nfor and lacked structure. Data was available for those with \nthe resources to collect and structure it, but there was no \nproduct fulfilling that need at scale and in an open and \nflexible way. Coinciding with the evolution of graph \ndatabases for modelling social networks, OpenCorporates \nbuilt a fast and flexible data structure to make search and \nvisualisation fast and pain-free. It removed the complexity \nof multiple data sources, delivering easily searchable, open \ncontent and broadening access to this data. This \nsupported entrepreneurs, innovators and those with \nfewer resources.\nOpen standards for data\nOpen standards are created through an open process which \nensures they take into account the requirements of multiple \nstakeholders. Having different organisations adopting the \nsame open standards ensures that data can flow easily \nbetween them, and that they share the same tools. \nIf open standards for data were used in investment banking, \nthey could support processes or products, which would \nreduce friction in how data is exchanged, helping to improve \nclient onboarding, increase transparency and save costs.\n[30]\n \nRegulatory technology (RegTech) solutions seeking to reduce \ncosts and simplify processes have emerged in recent years, \nbut open standards have yet to be tried in investment \nbanking. Open standards could prove most effective for the \nhighest impact and largest-scale challenges. For example, \nKYC could use them to support identity management and \nhelp establish data provenance. \nFrom a process perspective, banks have sought to make \nend-to-end transactions as ‘light touch’ as possible, in order \nto increase returns. The absence of open standards causes \nmost friction when data is sent between banks or even \ninternally between business functions, as data is often \nmissing, inconsistent or hard to transfer. \nIn public markets that use exchanges – such as equity or \nstock markets – the underlying cause of friction is usually \ndata quality (i.e. a company’s stock ticker is freely available, \nbut entered incorrectly at one stage in a process).\n29 See: https://opencorporates.com. \n30   Thomson Reuters (2016), ‘Thomson Reuters 2016 Know Your Customer Surveys \nReveal Escalating Costs and Complexity’, https://www.thomsonreuters.com/en/press-\nreleases/2016/may/thomson-reuters-2016-know-your-customer-surveys.html.\n31 OpenSource.com (2017), ‘What is open source?’,  \nhttps://opensource.com/resources/what-open-source. \n32 See: https://openaps.org.\n33 See: https://www.gnucash.org.\n34 W3C (2014), ‘Best practices for publishing linked data’,  \nhttps://www.w3.org/TR/ld-bp.\n35 International Swaps and Derivatives Association (2016) ‘New Industry Standard for \nCalculating Initial Margin Widely Adopted by Market Participants’,  \nhttp://www2.isda.org/news/isda-simm-deployed-today-new-industry-standard-for-\ncalculating-initial-margin-widely-adopted-by-market-participants.\n\nOpen Data Institute 2017 /     Using data to take an open approach to investment banking 16\nCase study: Provenance\nRecognising increased public awareness of product \norigins and history – such as the sustainability of materials, \nconditions of workers, and carbon footprint – Provenance \nprovided a platform to build a trustworthy supply chain \nledger. It improves transparency by unmasking opaque \nchains of data, helping customers make informed \npurchasing decisions. \nProvenance uses blockchain technology to help build \ntrust in goods and their supply chain, and uses open data \nfrom partners including Sourcemap.com and \nOpenCorporates.\n[39]\nOver 200 retailers and producers in the food and drinks \nindustry use their software service to help prove the \nprovenance of their product.\n[40]\n For example, the Co-op \nfood and digital teams use the software to track produce \nfrom source to shelf in real-time.\n[41]\n Their work with Fair \nFood verifies proof of payment for living wage to 55 \nfarmers while tracking coconuts from South East Asia to \nEurope.\n[42]\n As well as restoring connections between \nmakers, sellers and customers, Provenance brings value \nto smaller makers that cannot become transparent on their \nown due to the cost of opening their data and representing \nit on the web in a meaningful way to customers.\n[43]\nBlockchain technologies could disrupt existing processes in \ninvestment banking by delivering transformative change to \nhow banks store and exchange data. Near instantaneous \nsettlement of trades could become a reality when asset \nownership is entirely digitised in this fashion. As distributed \ndata technologies evolve, we may see more edge-based \ncomputing that facilitates secure and trustworthy open data \nproducts across the banking network. \nOpportunities remain to harden regulation and reduce the \nburden on investment banks by tightening and linking data \nstandards (e.g. MiFiD). Equally, wherever regulation and \nstandards are in question, the debate about how best to \nbalance accuracy and transparency continues.\nBlockchain technology\nBlockchain technologies are distributed ledgers that provide \na   way to store information so that many people can see it, \nkeep a copy of it, and add to it. Once added, it is very difficult \nto remove information, which reinforces trust in blockchain \ncontent.\n[36]\n Essentially a blockchain is a database shared \nacross the web with many people holding a copy of it, which \nshows a single version of the truth. \nEverledger’s work with diamonds demonstrates how fraud \ncan be reduced as physical assets are certified and tracked \ndigitally. Provenance’s work shows how blockchain \ntechnology can help makers tell the stories behind their \nproducts to customers; it is used by over 200 retailers and \nproducers in the food and drinks industry.\nCase study: Everledger \nEverledger use blockchain, smart contracts and other \nemerging technology to support banks and insurers to \nreduce risk and fraud.\n[37]\n They do this by improving supply \nchain transparency and efficiency. Everledger believe \na   reduction in document tampering leads to a reduction \nin    fraud for industries.\n[38]\n \nEverledger started by applying blockchain technology \nto the diamond industry. After creating relationships with \nthe major certificate houses around the world, they added \ndata about diamonds to a blockchain and have now \nuploaded data about 1,000,000 diamonds. \nEverledger are using this secure and transparent record \nto track and protect these valuable assets by recording all \ntransactions throughout the supply chain without relying \non intermediaries. It helps people to understand the \nprovenance of a diamond, who bought it and owns it, \nif   it   has been resold and where it is now. By adding \ntransparency to the diamond supply chain, Everledger \nhope to use blockchain technology to fix a market full of \ncorruption, trafficking and violence. Everledger work with \nEbay to track the resale of diamonds, Interpol to tackle \ncrime, insurance companies to tackle fraud and banks \nto assist in double financing of diamonds. They see their \napproach being applied to other high-value goods, from \nother gemstones through to wine, art and watches. \n36 The Open Data Institute (2016), ‘Applying blockchain technology in global data \ninfrastructure’, https://theodi.org/technical-report-blockchain-technology-in-global-\ndata-infrastructure.\n37 See: http://everledger.io. \n38 YouTube (2016), ‘Everledger & Diamonds: Building a Secure Blockchain’,  \nhttps://www.youtube.com/watch?v=sRVwkzQi5hI. \n39 See: https://www.provenance.org. \n40 lbid.\n41 See: https://www.provenance.org/case-studies/co-op. \n42 See: https://www.provenance.org/case-studies/fairfood. \n43 See: https://theodi.org/case-studies/provenance-case-study. \n\nOpen Data Institute 2017 / Whitepaper   Using data to take an open approach to investment banking 17\nAnnex: The ODI’s design principles for \ndata infrastructure\n1. Design for open\nOpen data, open culture, open standards, open source and \ncollaborative models build trust, reduce cost and create more \nvalue than other approaches. Being open improves quality as \nmore people can contribute to the outcome, and it increases \nthe number of connections that can be made. Data benefits \nfrom network effects: it creates more value as more people \nuse, contribute to and maintain it.\n2. Build with the web\nWe need to learn how to publish, discover, use and link \ntogether data across the web.\n[44]\n Data on and in the web is \ncontinuing to grow with more devices being connected and \ninterconnected every day. The billions of people, sensors and \nservices on the web produce and use data. Data \ninfrastructure must support the web of data.\n3. Respect privacy\nIn the most impactful and valuable data infrastructure \nopenness is maximised, but what is private remains private. \nDifferent countries have their own data protection legislation \nand social contracts, which need to be adhered to. To build \ntrust, organisations using personal data should also be open \nwith people about how they use and share that data.\n4. Benefit everyone\nData infrastructure components should be designed and \nsupported to benefit as many stakeholders as may use it. \nEveryone should benefit from the innovation, services and \ninsights that the whole data infrastructure allows. Sometimes \ndata infrastructure that is as open as possible will benefit \nthe organisations that maintain the data, in other cases it will not.\n[45]\n To benefit everyone, it will be necessary for governments \nto provide support for some components.\n5. Think big but start small\nDon’t start big. Start with the problems that are making it hard \nfor people to make decisions or build new services, be agile \nand learn from experiments. Concrete and tar don’t go out of \ndate as quickly as data technologies do.\n6. Design to adapt\nExpect needs to change, and expect other needs to \nvary between different stakeholders and local contexts. \nBe prepared to experiment with new technologies and ideas, \nlook for desire paths, measure impact, learn from what works \nand what doesn’t. Any part of data infrastructure might start \nas a small experiment but turn out to create significant \nimpact and have high demand. If it is designed to adapt \nusing approaches like human-centred design, by \nencouraging innovation and by using flexible modular \napproaches, this is most likely to happen.\n7. Encourage open innovation\nThe best ideas can come from anywhere: individual citizens, \nlarge or small organisations and from the public, private or \nthird sectors. Strong data infrastructure and open innovation \nwill encourage and stimulate fair and equitable markets and \ninnovative ways to both maintain data and use it to create \nnew services.\nA more open data infrastructure \npresents opportunities for \ninvestment banking across the \nvalue chain. \nIn the last decade, the significant increase in financial \nregulation has in part been a reaction to the financial crisis \nbut also a recognition of longer-term trends: the exponential \ngrowth of capital markets, the vast amounts of structured \nand unstructured data created by it, and changes in the \ninfrastructure to support it. \nTaking a more open approach would help regulations to be \nimplemented in ways that drive interoperability and innovation, \nfor example making it easier to collect and verify data. Open \nsolutions and open approaches to data for the sector are \nmost likely to emerge where they benefit three key stakeholder \ngroups: investment banks, their clients and regulators. \nRegulation is a good place to start, so long as participants \ncan see a clear path from protocol enhancements to creating \nvalue. The most significant opportunities often lie in the \nlargest but least transparent areas, such as unstructured data \nand derivatives markets.\nPerhaps the most critical factor in introducing a more open \ndata infrastructure will be the process used to implement it. \nAs the Open Banking Standard and the Open Protocol show, \nusing an independent facilitator to harness industry expertise \ncan be a fast and simple way of producing results. Equally, \ndesigning a process with no commercial agenda itself, but \nthat delivers long-term value for participants, removes \npotential barriers to cooperation amongst competitors. \nIn    building a more open data infrastructure, the biggest shift \nfor investment banks will be to agree where collaboration \ncreates more value than competition. \nAt a systemic level, a more open infrastructure for investment \nbanking will support distribution of capital globally and more \neffective risk management. From the ambitious entrepreneur \nto the individual seeking affordable health insurance, such a \nsystem has the potential to benefit many.\nConclusion\n44 The Open Data Institute (2016), ‘We need to learn how to search the web of data’, \nhttp://theodi.org/blog/we-need-to-learn-how-to-search-the-web-of-data. \n45 Lateral Economics (2016), ‘Permission granted: The economic value of data assets \nunder alternative policy regimes’, http://theodi.org/research-economic-value-open-\npaid-data.\n\nOpen Data Institute 2017 / Whitepaper   Using data to take an open approach to investment banking 18\nBibliography\nAccenture (2016), ‘Reference Data Management: \nUnderstanding True Cost’, https://www.accenture.com/\nt20151202T165846__w__/us-en/_acnmedia/Accenture/\nnext-gen/top-ten-challenges/challenge3/pdfs/Accenture-\n2016-Top-10-Challenges-03-Reference-Data.pdf \nAustralian Securities & Investment Commission (2017), \n‘Innovation Hub’, http://asic.gov.au/for-business/your-\nbusiness/innovation-hub \nBank for International Settlements (2012), ‘Principles for \nfinancial market infrastructures’, \n \nhttp://www.bis.org/cpmi/publ/d101.htm\nBank of England (2017), ‘Prudential Regulation Authority’, \nhttp://www.bankofengland.co.uk/pra/Pages/default.aspx\nBCG Perspectives (2016), ‘Fintech in Capital Markets: \n \nA Land of Opportunity’,  \nhttps://www.bcg.com/en-gb/publications/2016/\nfinancial-institutions-technology-digital-fintech-capital-\nmarkets.aspx\nFinancial Conduct Authority (2015), ‘Regulatory Sandbox’, \nhttps://www.fca.org.uk/firms/regulatory-sandbox \nGovernment Digital Service (2015), ‘Registers: authoritative \nlists you can trust’, https://gds.blog.gov.uk/2015/09/01/\nregisters-authoritative-lists-you-can-trust\nL Michael Meyer (2016), ‘Regtech 123’, https://www.linkedin.\ncom/pulse/regtech-1-2-3-l-michael-meyer-cfa?trk=hp-feed-\narticle-title-like\nLateral Economics (2016), ‘Permission granted: The \neconomic value of data assets under alternative policy \nregimes’, \n \nhttp://theodi.org/research-economic-value-open-paid-data\nInternational Swaps and Derivatives Association (2016), \n‘New Industry Standard for Calculating Initial Margin Widely \nAdopted by Market Participants’, http://www2.isda.org/\nnews/isda-simm-deployed-today-new-industry-standard-\nfor-calculating-initial-margin-widely-adopted-by-market-\nparticipants\nNESTA (2017), ‘Open Up Challenge’, \n \nhttp://www.nesta.org.uk/project/open-challenge \nOpen Banking (2017), ‘About Open Banking’, \n \nhttps://www.openbanking.org.uk/about\nOpenSource.com (2017), ‘What is open source?’, \n \nhttps://opensource.com/resources/what-open-source\nStandards Board for Alternative Investments (2017), \n‘Toolbox’, http://www.sbai.org/toolbox\nThe Open Data Institute (2016), ‘Applying blockchain \ntechnology in global data infrastructure’, \n \nhttps://theodi.org/technical-report-blockchain-technology-\nin-global-data-infrastructure\nThe Open Data Institute (2017), ‘Case study: Legislation.gov.\nuk’, https://theodi.org/case-studies/case-study-\nlegislationgovuk\nThe Open Data Institute (2017), ‘The Data Spectrum’, \n \nhttp://theodi.org/data-spectrum\nThe Open Data Institute (2015), ‘The Open Banking Standard’, \nhttp://theodi.org/open-banking-standard\nThe Open Data Institute (2017), ‘Principles for strengthening \nour data infrastructure’, http://theodi.org/guides/principles-\nfor-strengthening-our-data-infrastructure\nThe Open Data Institute (2016), ‘We need to learn how to \nsearch the web of data’, http://theodi.org/blog/we-need-to-\nlearn-how-to-search-the-web-of-data\nThe Open Protocol (2017), ‘Open Protocol’, \n \nhttp://www.theopenprotocol.org\nThomson Reuters (2017), ‘KYC onboarding still a pain point \nfor financial institutions’, https://blogs.thomsonreuters.com/\nfinancial-risk/know-your-customer/kyc-onboarding-still-a-\npain-point-for-financial-institutions\nThomson Reuters (2016), ‘Thomson Reuters 2016 Know Your \nCustomer Surveys Reveal Escalating Costs and Complexity’, \nhttps://www.thomsonreuters.com/en/press-releases/2016/\nmay/thomson-reuters-2016-know-your-customer-surveys.html\nW3C (2014), ‘Best practices for publishing linked data’, \n \nhttps://www.w3.org/TR/ld-bp\n\nGet in touch\ntheodi.org | @ODIHQ\ninfo\n@\ntheodi.org\nOpen Data Institute, 65 Clifton Street, London EC2A 4JE\n\ntheodi.org | @ODIHQ","version":"1.10.100"}