{"numpages":32,"numrender":32,"info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"Skia/PDF m67"},"metadata":null,"text":"\n\n \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nAbout \nThis report has been researched and produced by the Open Data Institute, and \npublished in April 2018. Its lead authors were Jared Robert Keller, Lucia Chauvet, \nJamie Fawcett and Olivier Thereaux, with contributions from Caley Dewhurst, \nAnna Scott, Peter Wells and Jeni Tennison. \nIf you would like to send us feedback, please get in touch by email \nat ​RandD@theodi.org​. \n \nThis report is published under the Creative Commons Attribution-ShareAlike 4.0 \nInternational licence. See: ​https://creativecommons.org/licenses/by-sa/4.0​. \n \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   2 \n\n \nContents \nAbout2 \nContents3 \nExecutive summary4 \nIntroduction5 \nA brief history of artificial intelligence6 \nThe present day7 \nThe importance of data in AI systems8 \nUnderstanding AI business models10 \nCreating a competitive advantage through access to data and algorithms10 \nAccess to data and algorithms exist on a spectrum11 \nClassifying AI systems by access to data and algorithms13 \nBroad archetypes of AI business models14 \nOutputs and other areas for competitive advantage15 \nThe current state of play16 \nThe trend towards open algorithms and closed data16 \nWhy are businesses taking this approach?17 \nChallenges related to the widespread siloing of data19 \nStifling innovation and creating oligopoly19 \nEncoding unintended bias into AI systems19 \nThe role of regulation, competition and trust23 \nTrust and a shift towards greater personal control of data23 \nAn opportunity rather than a threat24 \nGovernment intervention and regulation25 \nConclusion: opening and sharing data27 \nPublishing open data27 \nSharing data29 \nData trusts and exchanges30 \nRecommendations to businesses31 \nMethodology32 \n \n \n  \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   3 \n\n \nExecutive summary \nThe current wave of interest and investment in artificial intelligence (AI) is characterised \nin part by a preference for business models that prioritise the collection and siloing of \ndata. For companies taking this approach, access to data is seen as the key to \nsecuring a competitive advantage when building, implementing, and operating \nAI systems. Many of these companies therefore choose to restrict access to data \nin an effort to increase their competitive advantage. \n \nThe most frequently cited justifications for this approach are that the data siloed by \ncompanies is personal or proprietary – that by restricting access to data, companies \nare ensuring privacy and increasing profits.  \n \nHowever, this approach – and the business models based on it – arguably undercuts \nthese goals. It undercuts the goal of privacy by allowing large companies to control \ndata about people rather than building a framework that recognises the needs of \npeople, communities, businesses and governments. Along similar lines, the current \napproach undercuts efforts to limit unintended encoded bias in AI systems since it \nmakes it difficult to interrogate the data used to train those systems. Finally, the \nwidespread practice of restricting access to data undercuts the goal of increasing \nprofits, since an AI sector beset by monopolies and the widespread siloing of crucial \ndata stifles innovation within the sector as a whole.  \n \nIn this report we will present a matrix of AI business models to help readers understand \nthe array of models currently used by businesses developing AI systems, and lay out \nthe most commonly expressed reasons for the current trend of restricting access to \ndata. We will then discuss challenges related to the widespread siloing of data, \nfocusing on the dangers of unintended encoded bias and an AI oligopoly. We will close \nby identifying a number of emerging trends that are likely to impact the ways data is \nused in the AI sector over the coming years and explore ways of mitigating against \nthe dangers of oligopoly and unintended encoded bias by opening and sharing data.  \n \nAt the ODI we believe the ideal path forward will involve increasing the amount of \nsharing and opening of data for and by businesses operating AI systems, as well as the \nadoption of a wider variety of business models within the AI community. This will need \nto be done in a way that secures and safeguards the trust of people while promoting \ninnovation across the sector.  \n  \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   4 \n\n \nIntroduction \nArtificial intelligence systems are a combination of clever \nstatistical and mathematical techniques, an understanding \nof​ ​the​ ​world, and lots of data. \nArtificial intelligence (AI) has lately garnered a lot of attention and excitement, not only \nfrom private and public sector organisations but the general public as well. National \ngovernments, public sector organisations, large corporations, SMEs and startups have \nall invested significant amounts of money in developing AI technologies such as \nmachine learning, deep learning, natural language processing and image recognition \nwhich, according to the Centre of Public Impact (CPI), can usefully be described as \n“software that enhances and automates the knowledge-based work done by humans”. \n1\nIn this report we have referred to these different approaches as ‘AI systems’. \n \nThe largest technology companies and established firms are particularly interested in \ndeveloping and implementing AI tools and frameworks. In 2011, IBM invested \n$15 billion USD in Watson, its cognitive AI system for answering natural language \nquestions and deriving meaning from photos, videos, text and speech. In addition to \n2\nthe money being spent by individual tech companies, countries such as the USA, \nChina, the UK and France are also investing money in building AI industries. In 2017, \nfor example, the UK government stated its intention to invest at least £75 million into \nthe field of AI in order to “secure the UK’s leading position in the global AI market”.  \n3\n \nSome of this interest in AI is focused on the long-term potential and impact of general \npurpose AI and superintelligence. However, much of it centres on applying AI \ntechnologies to help tackle specific problems. The potential impact of these targeted \napplications has been estimated by PricewaterhouseCoopers (PWC) as adding up to \n$15.7 trillion USD to global GDP by 2030, making AI the “biggest commercial \nopportunity in today’s fast changing economy”. From financial services to digital \n4\nmarketing and healthcare, artificial intelligence has already begun to demonstrate its \npotential in a variety of sectors, saving time, money and lives. In 2016, Frost and \nSullivan, found that the application of AI solutions in the healthcare sector has the \npotential to “improve outcomes by 30 to 40 percent, while cutting treatment costs \nby as much as 50 percent.” \n5\n \nAt the ODI, we are exploring how some or all of this potential might be realised through \nthe application of AI systems to specific challenges. In this report, we focus on the role \n1\n Centre for Public Impact (2017), ‘Destination Unknown: Exploring the impact of \nArtificial Intelligence on Government’, \nhttps://publicimpact.blob.core.windows.net/production/2017/09/Destination-Unknow\nn-AI-and-government.pdf \n2\n Frank Palermo (2016), ‘IBM Watson Points the Way to Our Cognitive Business \nFuture’, \nhttps://www.cmswire.com/information-management/ibm-watson-points-the-way-to-o\nur-cognitive-business-future/ \n3\n Department of HM Treasury (2017), ‘Autumn Budget 2017’, \nhttps://www.gov.uk/government/publications/autumn-budget-2017-documents/autu\nmn-budget-2017  \n4\n PricewaterhouseCoopers (2017), ‘AI to drive GDP gains of $15.7 trillion with \nproductivity, personalisation improvements’,  \nhttps://press.pwc.com/News-releases/ai-to-drive-gdp-gains-of--15.7-trillion-with-produ\nctivity--personalisation-improvements/s/3cc702e4-9cac-4a17-85b9-71769fba82a6 \n5\n Frost & Sullivan (2016), ‘From $600m to $6bn, Artificial Intelligence Systems Poised \nfor Dramatic Market Expansion in Healthcare’, \nhttps://ww2.frost.com/news/press-releases/600-m-6-billion-artificial-intelligence-syste\nms-poised-dramatic-market-expansion-healthcare  \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   5 \n\n \nof data in building such systems, and how access to data, or a lack of access, might \nimpact the creation of value for people, businesses and society. \nA brief history of artificial intelligence  \nDespite all the recent attention and excitement, the idea of ‘artificial intelligence’ is not \nnew – indeed, the creation of artificial intelligence has been the subject of serious \nacademic and industrial research since the emergence of electronic computing in the \nearly post-war period. The intervening decades have seen periodic waves of \nexcitement about the potential of AI systems. \n \n“ \nThere have been at least three or four massive waves of \nenthusiasm for AI since the sixties through to now, and on \neach occasion the headlines have been the same; ‘the \nrobots will take our jobs’ and ‘human expertise is not what \nit was’, and ‘this pinnacle of human intelligence has just \nbeen defeated by a machine so what does that mean \nabout us?’ And associated with each of those peaks have \nbeen the troughs that have followed the kind of classic \nGartner life cycle \n– SIr Nigel Shadbolt \n \n \nIn that time, our understanding of what is meant by ‘artificial intelligence’ has changed \nnumerous times, often leading to confusion about what is and isn’t ‘artificial \nintelligence’. According to Michael Veale, a researcher at UCL focusing on the interplay \nbetween machine learning and data protection, “​AI has always been characterised by \npeople moving the goalposts. People say, ‘Hey, we’ll have an AI system when we can \nbeat this person at chess’, and then of course it does, and people move the goalposts.​” \nThat is why we prefer the CPI’s description of AI as “software that enhances and \nautomates the knowledge-based work done by humans”. In fact, according to \n6\nNigel Shadbolt, Chairman and Co-Founder of the Open Data Institute, \nProfessor of artificial intelligence and Principal of Jesus College, Oxford: \n \n“ \nJohn McCarthy said that “today’s ‘AI’ is tomorrow’s \ncomputer science” – which is to say that what looks like a \nreally unique method today, just becomes one of the many\nmethods in your library of computer science techniques. \n \nThere are also a number of misconceptions about what AI systems are and what they \ncan do. Chiefly, there is a tendency to conflate the potential for superintelligent \ncomputer systems that can perform tasks in a manner equivalent or better than \n6\n Centre for Public Impact (2017), ‘Destination Unknown: Exploring the impact of \nArtificial Intelligence on Government’, \nhttps://publicimpact.blob.core.windows.net/production/2017/09/Destination-Unknow\nn-AI-and-government.pdf \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   6 \n\n \nhumans, with the more conventional programmes that carry out specific tasks based \non some ‘learned’ behaviour. Terming both of these as ‘artificial intelligence’ can be \nconfusing and has led some to suggest the need to rethink the terminology. Indeed, \nYann Lechelle from Snips – which provides localised voice recognition systems \n– stated:  \n \n“ \nAI alone is misleading because it’s a grab bag, it’s loaded \nwith century old literature from Isaac Asimov, it’s loaded \nwith Hollywood’s rendering of AI gone awry, it’s loaded \nwith our collective fantasy. I think we need different words \nfor AI. \n \n \nNaming things is, famously, one of the hardest things in computer science. \n7\nThe term ‘artificial intelligence’ itself gained popularity in the 1950s having won \nout over \"complex information processing\"– a term that arguably comes closer \nto explaining what these systems actually do. \n \nWhat is an AI system? \nAI systems are executable models that take some data input and produce \nspecific recommendations, decisions or actions. They are a combination of \nstatistical and mathematical techniques, an understanding of the world and \ndata. There are many ways of creating these models: expert systems codify \nthe knowledge of experts while machine learning systems are built using \nstatistical techniques trained over data. Individually they are perhaps better \nexplained in terms of tasks they perform – such as automated decision \nmaking, natural language processing and pattern recognition – as opposed to \nthe many methods through which they are created – such as machine learning \nor deep neural networks. \nThe present day  \nWhile AI systems may not be new, our interviewees argued that there are three factors \nthat mark out the current wave of excitement surrounding AI: the increased processing \npower of today’s computers, the availability of open source toolkits and the large \namount of data now available.  \n \nThe recent explosion in AI development has less to do with the development of new \nalgorithms than the availability of high-performance hardware. Most of the techniques \nused today, from neural networks to linear regression, were theorised and developed \ndecades – and in some cases centuries – ago. It was only recently that hardware made \nthose techniques usable at scale: storage technology is now mature enough to store \nand shift vast amounts of training data; the development of GPUs for graphics and \ngaming applications have made massive parallelised computing significantly cheaper \nthan when neural networks were invented. More recently, the development and release \nof AI-specialised hardware such as Google’s Tensor Processing Unit (TPU) or Intel’s \nNervana – which not only increase the performance of AI algorithms, but are often \n7\n David P. Karlton (2017), ‘Naming Things is Hard’, \nhttp://www.meerkat.com/2017/12/naming-things-hard/ \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   7 \n\n \noptimised for a specific AI algorithm – are a sign of the maturity of the \n8\nsoftware-hardware ecosystem. \n \nIn parallel, according to Michael Veale, “there’s more data now than there was before, \nor at least companies have more structured forms of data.” Indeed, a report from IBM \nMarketing Cloud estimated that 90% of the data that exists today was created in the \nlast two years, with around “2.5 quintillion bytes of data” produced each day from \n9\nalmost every sector of the economy. Alongside the increasing amounts of data being \n10\ngenerated is a trend for increasing access to data, either through public availability on \nthe web or explicit data sharing and open data publishing. \n \n“ \nMuch of AI’s recent success has come on the back of \nelectrical engineers building better and faster chips, better \nand bigger memory as well as the network effect of the \nweb and technology to generate torrents of content and \ndata and the human ingenuity to have committed all of \nthat to machine-usable form. \n– SIr Nigel Shadbolt \n \n \nFinally, the increasing availability of and access to open source tools and frameworks \nfor creating AI systems also play a part in the current wave of excitement. \nTensorflow,​ ​Torch and Spark are examples of open source software libraries which, \nalong with powerful cloud computing providers such as AWS and Google Cloud, \nhave​ ​made the creation of AI systems – especially during research and development – \nsignificantly​ ​easier. \nThe importance of data in AI systems \nAI systems are a combination of statistical and mathematical techniques, an \nunderstanding of the world and data – lots of data. Large amounts of quality data are \ncrucial not only as an input during the operation of AI systems, but also to train them \nin the first place. Without access to lots of high quality data, algorithms cannot learn. \nEven the most powerful AI techniques – with top of the line hardware are significantly \nless useful without access to quality data.  \n \nThe more data that companies have access to, and the better the quality, the more \naccurate their AI systems can be. Research carried out for this study showed that \naccess to clean, varied and quality data is required to create effective AI systems. \nPerhaps more importantly, poor quality data or data that is not sufficiently varied, \nresults in misleading or erroneous outputs from AI systems. According to a study by \nthe Boston Consulting Group (BCG) and Massachusetts Institute of Technology (MIT) \nSloan Management Review, a clear discriminator between ‘leaders’ and ‘laggards’ in \n8\n Joel Hruska (2017), ‘Google’s dedicated TensorFlow processor, or TPU, crushes Intel, \nNvidia in inference workloads’, \nhttps://www.extremetech.com/computing/247199-googles-dedicated-tensorflow-proc\nessor-tpu-makes-hash-intel-nvidia-inference-workloads​. \n9\n Jack Loechner (2016), ‘90% Of Today's Data Created In Two Years’, \nhttps://www.mediapost.com/publications/article/291358/90-of-todays-data-created-in\n-two-years.html \n10\n Richard Harris (2016), ‘More data will be created in 2017 than the previous 5,000 \nyears of humanity’, \nhttps://appdevelopermagazine.com/4773/2016/12/23/more-data-will-be-created-in-20\n17-than-the-previous-5,000-years-of-humanity-/ \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   8 \n\n \nthe application of AI systems to business processes is “their understanding of the \nimportance of data, training, and algorithms”. Effective, commercially viable, AI \n11\nsystems require:  \n \ni) an understanding of the importance of data, and in particular an awareness \nof the sensitivity of algorithms to poor​ quality data, and \n \nii) the creation of systems to integrate new data into the model. \n \nAccording to a few of our interviewees, there is a common misconception that the \nmost important part of an AI system is the algorithm, when in fact the data upon which \nthe algorithm is trained and operated is just as important. One interviewee, who did not \nwish to be cited, believed the perpetuation of this misconception is due to the difficulty \nof explaining the role of data in both training and operating AI systems, and that \nfocusing on the algorithm is “just an easier story to tell”.  \n \nMany of our interviewees echoed the importance of access to data. Stephen \nWhitworth, founder of the fraud detection startup, Ravelin, explained that if another \nbusiness set out to develop an AI system that could rival Ravelin’s, they would do so \nnot only by building a “slightly better algorithm”, but by gaining access to “better data”. \nJohn Enevoldsen from Ocean Protocol similarly noted that while having a good \nalgorithm was a necessary and important part of any business developing an AI \nsystem, ​“the amount of relevant data you have behind it” is as important as the \nalgorithm itself. \n \nWhile almost all of our interviewees highlighted the importance of large quantities of \ndata, nearly as many also emphasised that the data being used has to be appropriate – \nit has to fit the problem being tackled.  \n \n“ \nThe value in most data is just in the massive quantity of it \nand how it represents the problem that you’re facing. The \nanswer is in there somewhere. The neural network is \nsimply a tool to go and try to find the answers, it’s not \ngoing to automatically solve anything for you \n– Steve, minds.ai \n \n \nBecause of the significant role of data in making effective AI systems, we will aim to \nexplore the role access to data has in AI business models. This includes examining the \ncurrent trends in access to data, identifying emerging challenges with current \napproaches and considering the potential effects of regulation and trust. Finally, we will \nlook at how data sharing and opening of data might enable the emergence of a greater \nnumber of more effective AI systems. \n \n \n \n11\nPhilipp Gerbert et al. (2017), ‘Is Your Business Ready for Artificial Intelligence?’, \nhttps://www.bcg.com/publications/2017/strategy-technology-digital-is-your-business\n-ready-artificial-intelligence.aspx \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   9 \n\n \nUnderstanding AI \nbusiness models \nThere are many strategies for creating a competitive \nadvantage when building AI systems, but the two most \nprominent are controlling access to data and algorithms. \nAI businesses can be found operating across a wide range of industries and sectors. \nFor this research we spoke to 17 organisations working in industries as diverse as \nonline credit fraud prevention, child protection, and transport, as well as companies \nwho work across a number of commercial contexts simultaneously. We also spoke to \ncompanies that provide services to businesses deploying AI systems, including \nproviding access to data, and venture capitalists who fund AI startups. \n \nAcross these sectors, there is a wide range of different products and services based \non AI systems trying to meet a wide variety of different user needs. As a result there are \nmany potential business models and techniques for creating competitive advantages \nin use, such as building relationships with customers and better meeting their needs. \nHowever, there are a set of similar characteristics that all business models around \nAI systems have. By focusing on these, we aim to understand how businesses are \nattempting to create a competitive advantage for their products and services through \nAI systems.  \n \nTo create effective AI systems that can be deployed within various products and \nservices, businesses need access to ​algorithms, data, skills and hardware​. \nTo create a competitive advantage in providing these products and services, \ncompanies often choose to restrict access to some or all of these resources. \nBecause of the ubiquity and commodification of hardware, access to sufficient \nhardware is relatively uncompetitive, though it may have an impact on initial \ndevelopment done by startups. Any business attempting to create a competitive \n12\nadvantage through the development of bespoke hardware would encounter large \nupfront costs, and in many applications this would be unlikely to provide a sufficient \ncompetitive advantage to justify that cost. However it is a strategy that can be \nemployed by large corporations running cutting-edge AI systems.  \n \nWhile there is a well-documented scarcity of advanced AI skills and therefore extensive \ncompetition for AI expertise, investment in recruiting top AI talent to create a \n13\ncompetitive advantage is one potential strategy. In many cases, however, it might be \nprohibitively expensive for businesses developing AI systems, given the need for \nsignificant capital and potentially limited returns if the AI systems being developed are \nnot cutting edge.  \n \n \nCreating a competitive advantage through access \nto data and algorithms \nBecause of the difficulty with building a competitive advantage through access to \nhardware and skills, access to data and access to algorithms are the primary means of \ncreating a competitive advantage for most businesses creating AI systems. \n12\n Digital Catapult Centre (2018), ‘Machines for Machine Learning’, \nhttps://www.digitalcatapultcentre.org.uk/wp-content/uploads/2018/01/MIG_Machinesf\norMachineIntelligence_Report_DigitalCatapult-1.pdf  \n13\n Rita C. Waite (2017), ‘This Is Why All Companies Need An AI Strategy Today’, \nhttps://www.cbinsights.com/research/artificial-intelligence-strategy \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   10 \n\n \nIn traditional business best practice, businesses lock down access to their resources – \nhowever with access to data and algorithms this is not necessarily the desired \napproach. This is because both data and algorithms are digital assets – in economic \nterms they are ‘non-rivalrous goods’, meaning they can be used by many people \nwithout being used up. Providing access to data or algorithms does not hinder a \n14\ncompany’s ability to use it themselves, so the perceived cost of sharing these assets \nis primarily attributed to a loss of advantage over competitors. \n \nThere are potential business benefits of sharing access to both data and algorithms – \noften centred on the potential for AI systems that are faster and of higher quality, as \nwell as spurring greater innovation within the AI sector as a whole. Businesses may \nchoose to enable access to data or algorithms in order to realise some of these \nbenefits, however they also have to consider the impact this may have on their ability \nto retain a competitive advantage. In order to realise the potential benefits of wider \naccess while retaining some form of competitive advantage, every business must make \ninformed decisions about whether – and how widely – to share access to both the data \nthey use and algorithms they create.  \n \nThis challenge was echoed by one of our interviewees, Roemer Claasen of Frosha (a \nDutch company using AI to clean and combine data) who said he and his colleagues \noften feel a tension between needing to protect their competitive advantage while at \nthe same time wanting to realise the potential benefits of making their algorithms \navailable:  \n \n“ \nWe do think about making the algorithm usable, at least \nfor the open data community but we have to be very \ncareful because it’s also our business model... \n– Roemer Claasen, founder of Frosha \n \nAccess to data and algorithms exist on a spectrum \nProviding access to both data and algorithms is not a binary choice. Businesses need \nto decide what to share, with whom and how. \n \nFor data, access can be described by the ODI Data Spectrum – where access to data \nexists on a spectrum based on the terms of a data licence, sharing agreement or \npermissions. This spectrum spans from not sharing access with any external \norganisations to publishing as open data – with a licence that allows anyone to access, \nuse and share. In between, there is a wide range of possible types of sharing – \nincluding directly with selected partners, with groups of partners or publicly with \na restrictive licence.  \n \nWithin an individual AI system, different data might be treated differently and therefore \nexist at different points on the spectrum – for example data used to train an algorithm \nmight be closed because it contains personal data, but a subset of suitably \nanonymised data may be published openly. Examples of where data is being closed, \nshared or opened include: \n \n●Frosha, which deals with highly sensitive data about people and keeps that \ndata closed \n15\n14\n University of Pittsburgh, ‘Public Goods’, \nhttp://www2.pitt.edu/~upjecon/MCG/MICRO/GOVT/Pubgood.html \n15\n Frosha (2017), ​https://frosha.io \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   11 \n\n \n●Ravelin, which, as a service for clients, shares data which has been \nanonymised by its AI system  \n16\n●Mozilla, a not-for-profit technology company, that publishes its voice data \nset openly \n17\n \n \n \nFigure 1. The Data Spectrum. \n \n \nFrom our research, we concluded that access to algorithms follows a similar pattern as \naccess to data. Algorithms can therefore be understood to exist on a spectrum from \nclosed to shared to fully open. However, this spectrum is more complicated because \nthe term ‘AI algorithm’ can be used to describe a range of different facets of an AI \nsystem, including the type of AI system (e.g. recurrent neural network, linear regression \nor decision trees, to name only a few popular examples), the software toolkit used to \nimplement the system, the model created, the features selected, or indeed any \ncombination of these.  An individual ‘AI algorithm’ might, therefore, cover an area of the \nspectrum – for example, a business might publish the open source software framework \nused to create a specific AI model, but keep details of the feature definition or \noptimisation techniques closed.  \n \nWhile the complexity makes it more difficult to classify AI algorithms as existing at \nparticular points on a spectrum of access, understanding the broad area where they \nexist enables comparisons between AI systems in terms of their business model and \napproach to competitive advantage.  \n \nFor example, Snips keeps their algorithms closed because their commercial advantage \nrelies on controlling access to their algorithms. A number of large technology providers \nshare their algorithms by offering paid or restricted access to their AI systems, \nincluding Amazon Web Services which provides access to Lex, a service that allows \nusers to build conversational interfaces using the algorithm that powers Amazon’s own \nvirtual assistant, Alexa. Finally, many of the larger technology companies contribute to \n18\n16\n Ravelin (2018), ​https://www.ravelin.com/ravelinlookup \n17\n Sean White (2017), ‘Announcing the Initial Release of Mozilla’s Open Source Speech \nRecognition Model and Voice Dataset’, \nhttps://blog.mozilla.org/blog/2017/11/29/announcing-the-initial-release-of-mozillas-ope\nn-source-speech-recognition-model-and-voice-dataset \n18\n Amazon Web Services (2018), ‘What is Amazon Lex?’, \nhttps://docs.aws.amazon.com/lex/latest/dg/what-is.html  \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   12 \n\n \nopen source AI toolkits, for example Microsoft’s Computational Network Toolkit \n19\nor Google’s TensorFlow.  \n20\nClassifying AI systems by access to data and algorithms \nBy considering products and services built on AI systems in terms of their position on \nspectrums of access to data and algorithms, we can start to understand how these \nplay into their business model. If we overlay these spectrums in a matrix, we can, at \nleast theoretically, place each product or service at a point on that matrix – or at least \nacross an area of the matrix. Using this conceptual model, we can start to identify \nbroad archetypes and trends in how businesses are approaching access to data and \nalgorithms as a means of forming a competitive advantage. \n \nBelow, we lay out what this approach might look like and conceptualise the broad \nstrategies that are characterised by areas on the matrix. While we have used our \nresearch and interviews to help infer these potential strategies, we have deliberately \navoided classifying existing products and services. We hope, however, that this \nframing helps people understand some of the strategies being employed by \nbusinesses to create a competitive advantage through access to data and algorithms. \n \n \nFigure 2. The AI Business Model Matrix. \n \n19\n Allison Linn (2016), ‘Microsoft releases CNTK, its open source deep learning toolkit, \non GitHub’, \nhttps://blogs.microsoft.com/ai/microsoft-releases-cntk-its-open-source-deep-learnin\ng-toolkit-on-github \n20\n TensorFlow (2018), ​https://www.tensorflow.org \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   13 \n\n \nBroad archetypes of AI business models \n \nProprietary data model: open algorithm + closed data \n \nThe archetypal business model near the top left of the matrix can be described as \nthe proprietary data model. This approach is characterised by restricting access \nto data while providing wider access to AI algorithms.  \n \nBusinesses employing this type of approach may aim to gain a commercial \nadvantage by restricting access to data used to develop AI systems to prevent \nothers from developing competing systems. At the same time, by using open \nsource AI toolkits – or enabling access to their own algorithms and toolkits – \ncompanies are able to benefit from the latest advances in AI modelling, receive \nfeedback from others in the AI community and encourage the development of \ncomplimentary services through open innovation. \n \n \nClosed model: closed algorithm + closed data \n \nThe archetype positioned near the bottom left of the matrix can be described as \nthe closed model. Businesses applying this approach restrict access to both the \ndata and the algorithms under their control.  \n \nThe benefit of this type of approach is that companies leverage their internal \nresources and develop their own skills and products, where the access to both \ndata and algorithms constitutes their intellectual property. The downside is that it \ncan be comparatively more difficult to have meaningful interactions with the wider \nAI community. Businesses that adopt a closed model tend to not only make fewer, \nless impactful contributions to the broader AI community, but also reap fewer of \nthe benefits that engagement with the community can provide. \n \n \nProprietary algorithm model: closed algorithm + open data  \n \nThe archetypal business model situated near the bottom right of the matrix can be \ndescribed as the proprietary algorithm model – or what Maria Axente, a Digital \nStrategy Consultant at PwC UK, has called the ‘intellectual property (IP) model’. \n21\nThis type of approach is defined by greater access to data coupled with \ncomparatively limited access to algorithms.  \n \nCompanies that adopt this model tend to want to use their skills and expertise to \ndevelop proprietary algorithms that are more effective than their competitors and \nthen allow outside companies with large amounts of untapped data to use their \nmodel, and access the outputs of that model, at a cost. \n \nThe advantage of this approach, especially for many startups and smaller \nbusinesses, is that it does not require them to control their own large data set – \nsuccess is not predicated on the aggregation of vast amounts of data. In addition, \nthere are benefits for the wider AI community, since greater sharing and opening \nof data encourages innovation. \n \n \n \n \n \nOpen model: open algorithm + open data \n21\n This interview was conducted by Future Advocacy on behalf of the ODI. \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   14 \n\n \n \nThe archetype close to the top right corner of the matrix can be described as the \nopen model, where data and algorithms are both openly available. \n \nCompanies that employ this type of approach tend to want both elements openly \naccessible by the general public. This approach offers the most benefits in terms \nof innovation and speed of AI improvements, contributing to making society and \nthe AI community better. However, choosing this strategy might require businesses \nto generate a competitive advantage through other means beyond restricting \naccess to data or algorithms, such as skills or hardware. \n \n \nShared model: shared algorithm + shared data \n \nIn the centre of the matrix exist a range of shared models where access to data \nand algorithms are shared with select parties. Businesses employing these types of \nstrategies tend to aim to derive competitive advantage from other facets of their \nbusiness model, such as their skills and expertise. This might take the form of \nconsultancies building bespoke AI systems for clients or licensing particular \nAI systems and associated services.  \n \nOutputs and other areas for competitive advantage \nAs previously stated, there are many areas in which products and services built on \nAI systems can compete. Beyond those that are common to all services, such as price \nor functionality, one remaining common facet for those built on AI systems is access \nto the outputs of AI systems. Access to these outputs can also be described on \na spectrum, and this might impact how businesses attempt to create competitive \nadvantage. For example, an organisation might provide access to both data and \nalgorithms but limit access to the outputs, allowing them to sell the insights or \nfunctionality as a service. This may enable them to compete on the basis of access \nto hardware or skills, for example by running their system more responsively or by \ntailoring specific insights for clients. \n \nOn the whole there are many ways in which businesses attempt to create advantage \nover their competition by restricting access to some of their resources. However, there \nare many ways in which sharing and opening access to facets can provide tangible \nbusiness benefits. This particularly applies in the case of digital assets such as \nalgorithms and data. Businesses need to identify the approach that best works for \nthem, depending on the context in which they are building an AI system. \n  \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   15 \n\n \nThe current state of play \nAt present, algorithms are shared or made open much \nmore frequently than data due to concerns around \npersonal data and commercial sensitivity. \nThe trend towards open algorithms and \nclosed​ ​data \nIn general, companies see access to data as the key to gaining a competitive \nadvantage when building AI systems and are choosing to restrict access in order \nto create a competitive advantage. \n \nMany larger companies have started to set their sights on what Daniel Faggella of \nTechEmergence referred to as a ‘self-​feeding data ecosystem’. Businesses with large \n22\nsiloes of high quality data are able to train the best AI systems; the best systems find \nthe widest usage; the wide usage of these systems contributes yet more data to the \nsiloes of the largest companies with the best AI systems. That data can then be used \nto improve existing models and create entirely new ones, creating a reinforcing cycle. \n \nIn addition, by collecting vast quantities of data as rapidly and as extensively as \npossible, organisations come to control what Gary Swart of Polaris Partners has called \na ‘proprietary data plume’. Once enough data is collected – and the processes for data \n23\ncollection in real​-time are efficient and well ​established – new companies attempting to \nmove into the field have little option but to rely on the existing ‘data plume’ controlled \nby the early movers in the sector. This has been termed the ‘winner​-takes-​all’ model: \naccess to an extensive ​enough dataset means that new efforts at collecting data – \nessentially, reinventing the wheel – are doomed to be uneconomical and therefore \ncommercially disadvantageous. Indeed, according to Faggella, it is access to – or \ncredible means for developing – a proprietary data plume that investors in AI companies \nvalue above all else when making investment decisions.  \n24\n \nThis attitude to data is in contrast with how some algorithms and AI technologies are \nviewed by many businesses currently developing AI systems. Many AI technologies \nsuch as Keras, Apache Spark and Tensorflow are provided freely and openly, allowing \nthem to be easily reused by other businesses.  \n \nThe ‘Open Algorithm + Closed Data’ setup has led to great disparities in access to data \nacross the AI sector. According to John Enevoldsen of Ocean Protocol – a company \nbuilding a decentralised data exchange to help unlock data for AI systems – there is \n“a huge gap between the data haves and the data have nots” in the AI sector. It is the \n“big corporations and companies that have a lot of data”, he explained, and not many \nof them are sure how to use it to build effective AI systems. On the other hand, AI \nstartups “lack the relevant and high-quality data sets to actually train their models.” \n \nDougal Featherstone from Frosha noted from experience that even in instances where \npeople have expressed a desire to share their data with startups and SMEs, it is often \nnot possible to access that data due to its being “ring fenced” inside major technology \ncompanies. For Featherstone, the key question to ask going forward is therefore, “How \ndo you get that data out to companies like ours who would love to have it?” \n22\n This interview was conducted by Future Advocacy on behalf of the ODI. \n23\n Daniel Fagella (2017), ‘Gary Swart on Defensibility and Scale for AI Companies’, \nhttps://www.techemergence.com/gary​swart​defensibility​and​scale​ai​companies/ \n24\n This interview was conducted by Future Advocacy on behalf of the ODI. \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   16 \n\n \n \nWhy are businesses taking this approach? \nBusinesses are increasingly choosing to provide access to their AI tools and \nalgorithms, providing them under open source licences so that anyone can reuse them. \nIt is increasingly the norm for businesses to publish code openly as a means of getting \nothers to use it and help identify potential or existing issues, alongside other potential \nbenefits. In addition, developing AI systems in the open can have significant benefits \n25\nfor the development of AI systems in general, speeding up the adoption of new \nmethods and ways of operating. This desire to drive progress in AI systems has been \ncited by many businesses as a reason for why they have made their AI toolkits open \nsource. A final reason for increasing access to algorithms is emerging around the idea \n26\nof ‘algorithmic accountability’ – being able to understand how certain algorithms come \nto decisions. Whether or not opening up models to interrogation can actually help \n27\nhold algorithms to account remains in question, however – especially for certain types \nof neural networks. For this reason, it is not currently a big driver behind opening up \nalgorithms but looks set to play an increasing role. \n \nWhen asked why businesses are hesitant to share or open data, our interviewees \ntended to give two responses. First, they said the data in question is often sensitive, \npersonal data that can be difficult to share for privacy reasons. Second, that it is often \nproprietary data that forms the basis of a company’s competitive edge. \n \nRoemer Claasen from Frosha expressed the first point quite succinctly. When asked \nwhether having access to data that is currently siloed might encourage innovation in \ntheir sector, Claasen responded: “Of course we would be able to develop more \nbusiness models out of that, of course, but as a citizen I would probably object to that. \nIt’s with good right there are some silos”. This is a common approach to data about \npeople within businesses: access to some data should be restricted unless the person \nit is about has given explicit consent. Besides the privacy issue, there are strong \nbusiness reasons for controlling access to sensitive data about people – namely \nretaining the trust of customers and avoiding potential regulatory issues. This second \nreason makes many businesses risk-averse when it comes to sharing personal data. \nWhile it can be an admirable and justifiable approach, it can also be used by \ncompanies as an excuse to justify restricting access to what they perceive as \nproprietary data. \n \nWith regards to proprietary data, David Zomerdijk from Frosha followed his colleague’s \npoint about the valid reasons for siloing some personal data by explaining that while \nthe sharing or opening of non-personal, commercial data would “cause innovation – \na lot of it”, companies resist because they “get some market advantage” of that data.  \n \nThere are valid reasons for closing or limiting access to commercial data – for example \nwhen the data reveals something about the inner workings of a business, such as a \nprofit and loss register. However, often businesses default to restricting access to data, \neven if there is potential value in sharing or opening that data. Businesses may keep \nsome data closed, even if they are not using the data themselves – potentially losing \nout on capitalising on the value that it might have to others.  \n \n25\n Ibrahim Haddad (2018), ‘Using Open Source Code’, \nhttps://www.linuxfoundation.org/using-open-source-code \n26\n Allison Linn (2016), ‘Microsoft releases CNTK, its open source deep learning toolkit, \non GitHub’, \nhttps://blogs.microsoft.com/ai/microsoft-releases-cntk-its-open-source-deep-learning-\ntoolkit-on-github \n27\n Megan Rose Dickey (2017), ‘Algorithmic accountability’, \nhttps://techcrunch.com/2017/04/30/algorithmic-accountability  \nWorld Wide Web (2017), ‘A Smart Web for a More Equal Future’ \nhttp://webfoundation.org/docs/2017/07/Algorithms_Report_WF.pdf \nOpenAI (2018), ​https://openai.com \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   17 \n\n \nAccording to our interviewees, businesses developing AI systems often do not see the \nvalue of opening the data they collect. Daniel Vila Suero from RECOGNAI, a startup \nbuilding knowledge-powered predictive models, explained that in his experience, many \n– though not all – AI companies remain unconvinced that they will benefit from sharing \nor opening their data to others. He added, however, that while they resist opening or \nsharing their own data, many of those same companies do see advantages in the open \ndata model in general, as they likely already benefit from other businesses and \norganisations opening up their own data. \n \nSimilarly, according to a number of our interviewees, some AI businesses do not see \nthe value in using open data to train their models. Anne-Valérie Bach from Serena \nCapital – a top tier investment partner – explained that many companies feel that the \ntypes of data published openly by public sector organisations is often of poor quality, \nand would need to be extensively cleaned and combined with other proprietary data \nsets in order to prove useful.  \n \n“ \nMost of the time it’s a combination. Large companies or \nlarge organisations, they sit on a lot of data that they don’t \neven know what to do with, so usually it’s those people \nwho need help in figuring out what to do but on the other \nhand, the start-up, if they only use open data they might \nnot have the relevance and the quality they really need to \ntrain the algorithm, so usually it’s a combination. \n– Anne-Valérie Bach, Serena Capital \n \n \nWhile it is true that some businesses developing AI systems do not see the value of \nopening their data or using open data, many AI systems are actually trained primarily \nor exclusively on open or publicly accessible data. For instance, it is possible to train \nnatural language processing systems on text from open sources like Wikipedia or \n28\npublicly accessible sources like Twitter. A few of our interviewees developed their AI \nsystems using primarily open or publicly available data. Frosha, for instance, combine \ndata from several open sources to train the algorithms and are looking at using Twitter \nas a source of training data. Similarly, AI Poli – a company that combines natural \nlanguage processing and machine learning to help business and governments assess \nthe validity and relevance of news publications – regularly train their models on a \ncombination of data made available by partners and publicly accessible data “scraped \nfrom the internet”.  \n \nIt may be that people in the AI community do not perceive these publicly accessible \ncorpora as ‘open data’, since some of them are not openly licensed, but the wide \n29\nusage of such data within the AI community demonstrates the value in making that \ndata accessible. \n \nAnne-Valérie​ Bach explained that since the business model of many companies \ndeveloping AI systems is built around gaining exclusive access to better data than \ntheir competitors, open data sets – which by definition can be accessed by anyone, \nincluding competitors – do not give AI businesses a competitive advantage. \nBoth factors – the perceived lack of quality and the perceived lack of competitive \nadvantage – likely contribute to the trend towards restricting access to data used \nto develop AI systems.  \n28\nLingatools, ‘Wikipedia Comparable Corpora’, \nhttp://linguatools.org/tools/corpora/wikipedia-comparable-corpora \n29\n Anna Scott (2017), ‘What is ‘open data’ and why should we care?’, \nhttps://theodi.org/article/what-is-open-data-and-why-should-we-care \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   18 \n\n \nChallenges related to the \nwidespread siloing of data  \nRestricting access to data for building AI systems is stifling \ninnovation and creating more biased AI systems  \nWhile many of the people we interviewed were sympathetic to arguments against \nsharing or opening data, they recognised some of the issues arising from this approach \n– not only for businesses, but for the economy and society as well. In particular, they \nfocused on two major challenges related to the current treatment of data and \nalgorithms within AI business models. \nStifling innovation and creating oligopoly \nFirst, restricting access to data to retain a commercial advantage brings with it the risk \nthat the development of AI systems will be dominated by a handful of large companies. \nSince access to large amounts of quality data is of paramount importance for \ndeveloping AI systems, the monopolisation of data by a small cadre of businesses will \nmean that fewer startups, SMEs, and other businesses can turn their innovative ideas \ninto new AI systems.  \n \nMichaele Veale commented that while it is unclear how the sector will develop over the \nnext few years, there is a “natural tendency to monopolisation with machine learning \nsystems.” This is due in part to the realities of the ‘self-​feeding data ecosystem’, identified \nin the previous section. Those with the most data are often able to train the best AI \nsystems and those with the best AI systems are often able to collect the most data.  \n \nVeale cautioned, however, that such a setup was likely not sustainable. Speaking \nspecifically about the role of deep learning in APIs, he explained: “Because deep \nlearning just needs so much data it’s very difficult to make a competitive market \nwithout legislation that would allow that data to be open”.  \n \nThe lack of a competitive market would hinder innovation and stall what is currently \na thriving AI sector. It would stifle the energy and creativity that startups and SMEs \ncontribute and lead, in effect, to a data oligopoly where access to data is concentrated \nin the hands of a few large businesses. This would not only hurt startups and SMEs, \nbut large companies as well, since it would lead to a reduction in the diversity of \nproblems to which AI systems are applied. Ultimately, it would lead to a reduction in \nthe size of the AI market. Businesses should look to address these challenges head on \nrather than exclusively relying on government to tackle them through regulation.  \n \nIf businesses fail to overcome these challenge, it will severely limit the ability of all \nbusinesses to build new innovative products and services based on AI systems. This \nincludes those businesses that have built data oligopolies in certain areas, as they will \nbe unlikely to gain access to certain types of data collected by their direct competitors. \nEncoding unintended bias into AI systems \nAccording to our interviewees, the second major problem with the current restrictions \non access to data is that they will likely to lead to AI systems – in particular those \nbased on machine learning – that contain more unintended bias in their models.  \n \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   19 \n\n \nAlthough AI systems can often feel like black boxes that upon being fed with data \n(photos, preferences, interactions, etc.) magically return decisions, recommendations \nor pattern recognition, they are not magic – they are the creations of scientists, \nengineers, and programmers, and are subsequently trained to maturity on large \namounts of data. The decisions and recommendations provided by an AI system are \ntherefore a product of data and decisions made during the creation and training of that \nAI system. \n \nConsidering the crucial role data plays in training and operating AI systems, the \ndatasets used to train those systems must be of sufficient quality and variety. An AI \nsystem trained on data gathered from an incomplete or unrepresentative section of the \npublic, for instance, might develop racial, gender, or economic biases. For example, an \nimage classification algorithm might do poorly at classifying images of minority ethnic \ngroups compared with majority ethnic groups. Along these same lines, biases present \n30\nin the sampling or collection of data will likely become biases in the actual operation of \nany AI system trained on that data.  \n \n“ \nIf you talk to machine learning people they will tell you, \nif​ ​you don’t have a rich data set you actually start \ndiscriminating people because there is bias in the data set.\n– Sandra Wachter \n \n \nThis type of bias may not have a huge impact on the efficacy of some systems – \nfor instance, unintended bias in an AI system in charge of a home thermostat might \nonly result in minor nuisances. But it might have a huge impact on people in other \ncases – for example bias in an AI system that screens job candidate CVs might affect \nthe career prospects of underrepresented minorities. The impact of unintended bias \nmay also vary by context, and might not be predictable by those building the system. \nIn the thermostat example, imagine if the thermostat was used for regulating the \ntemperature of a hospital room in winter, where the difference of a couple degrees \ncould mean life or death. Bias in AI systems is not only potentially bad for people and \nsociety, but for businesses too, since a poorly functioning product can lead to a decline \nin consumer confidence. \n \nAccess to data from many different sources can help to achieve a more representative \nsample and can also help safeguard against AI systems reflecting any existing or \nhistorical biases related to the collection of data. In contrast, the current practice of \nlimiting access to data could increase the likelihood that AI models will be trained on \nunrepresentative data. \n \nSandra Wachter, a research fellow at the Oxford Internet Institute (focusing on the legal \nand ethical implications of big data and AI), expressed this concern in her interview.  \n \n“ \nIf you don’t know where the data comes from, you don’t \nknow if the data is accurate, you don’t know if it’s actually \ncomplete. So having enough access to broad datasets \ncould actually help to get rid of those biases. \n– Sandra Wachter \n30\n Tom Simonite (2018), ‘When It Comes to Gorillas, Google Photos Remains Blind’, \nhttps://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind​.  \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   20 \n\n \n \n \n \nShe closed by expressing her belief that despite the importance of addressing this \nissue, it is something that “hasn’t really been communicated yet.” \n \nFrom a business perspective, ​Daniel Vila Suero​ from RECOGNAI explained that in his \nestimation combining multiple datasets presents businesses with an opportunity to \nlearn from more structured data. “It wouldn’t be a threat for AI companies,” he stated, \n“I think it’s more of a benefit.” \n \nPart of the reasoning here is that combining data sets helps to make your data more \nrepresentative and therefore better. Better data means better AI systems; better AI \nsystems means better services; and better services means more customers. On the \nother hand, as Gil Arditi, head of machine learning at the ridesharing company Lyft, put \nit: “Bad data can lead to suboptimal decisions that actually kill competitive advantage.” \n31\n \nOn a related note, polling data suggests that a not insignificant proportion of people \nare concerned about the role such systems are likely to play in people’s lives in the \nfuture. In such an environment, businesses developing AI systems will need to work \n32\nespecially hard with users to build trust in their AI systems.  \n \nWhile some advocate opening and sharing algorithms as a way of examining \nalgorithms for inbuilt biases, many of those same people can overlook the opportunity \nto guard against encoded biases by opening and sharing data. At present, there is still \na debate around whether it is possible to meaningfully understand certain AI systems – \nnamely those dependent on deep learning – or the recommendations they offer, merely \nby interrogating the AI algorithm. \n \nHowever, even in instances where it is not possible to fully interrogate an AI system, \ndisclosing source-code and algorithms is an important step. The recent report on \npublic scrutiny of automated decision-making by the Omidyar Network noted that \n33\nwhile opening and sharing algorithms may not always be enough to serve the needs \nof the public, \n \n“ \n... transparency at different layers of a system can help \nexternal scrutinizers understand a system well enough to \nraise concrete concerns, guide further investigation, and \npropose potential remedies \n \n \nAt the ODI we believe that a complimentary step in the right direction would be to open \nup and share data in the same way algorithms currently are. This would provide greater \ntransparency at a different ‘layer of the system’ and would make it possible to examine \nthe training data that may be equally – if not more – responsible for much of the inbuilt \nbias in AI systems. However, this approach is also likely to be contested in terms of its \n31\n John Koetsier (2017), ‘Artificial Intelligence and Commerce: 4 Steps To Bringing AI \nTo Market’, \nhttps://www.forbes.com/sites/johnkoetsier/2017/10/24/4-steps-to-bringing-ai-powered\n-products-to-market-how-lyft-builds-intelligence-into-product/#698155421b66 \n32\n The Royal Society (2017), ‘Public Views of Machine Learning’, \nhttps://royalsociety.org/~/media/policy/projects/machine-learning/publications/public-v\niews-of-machine-learning-ipsos-mori.pdf \n33\n Omidyard Network (2018), ‘Public Scrutiny of Automated Decisions: Early Lessons \nand Emerging Methods’, \nhttp://omidyar.com/insights/public-scrutiny-automated-decisions-early-lessons-and-e\nmerging-methods \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   21 \n\n \nability to fully reveal unintended encoded bias, especially as it is currently relatively \nuntested compared to other methods.  \n \nSharing and opening data could not only help safeguard against the dangers of \nunintentional encoded biases, but encourage innovation and benefit businesses. \nFailing to do so would be bad for society, bad for people, and bad for business.  \n  \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   22 \n\n \nThe role of regulation, \ncompetition and trust \n \nAs people gain more rights to exercise control over \ndata about them, businesses need to think about the \npotential opportunities and impact these rights might \nhave on the design of AI systems \nWhen asked what the future might hold, the people we spoke to identified a number \nof trends they believe have the potential to significantly impact current AI business \nmodels and practices around data. These trends have the potential to both positively \nand negatively impact the development of future AI systems.  \nTrust and a shift towards greater personal control \nof data \nOne trend identified by our interviewees was a general move towards greater emphasis \non transparency and trust. Matthew Sheret of Projects by IF referred to his experience \nof working with clients who were not predominantly concerned with the acquisition of \nnew data, but rather with developing AI systems that are more open and transparent.  \n \n“ \nWhat is important is trust ​– this is what a long term \nrelationship between services and users is built on. \n– Matthew Sheret \n \nHis comment suggests there is an increasing commercial imperative in being \ntrustworthy in interactions with potential and existing clients. Sheret defines \ntrustworthiness as “building services in a way that makes it clear what’s going on \nto users and that can be unpicked by regulators and independent groups”. \n \nBuilding trust will likely become increasingly important for businesses over the coming \nyears as people are given greater control over data about them. Indeed, quite a few \nof our interviewees mentioned the imminent arrival of the General Data Protection \nRegulation (GDPR) in May, and what they saw as a general shift towards a data \n34\neconomy where people are given greater control over the sharing and usage of data \nabout them.  \n \n34\n EUGDPR (2018), ​https://www.eugdpr.org \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   23 \n\n \nGeneral Data Protection Regulation (GDPR) \n35\n \nGDPR impacts how companies collect, use and share data about their users \nby giving people rights over data about them. It applies to all businesses \nprocessing data about citizens of the European Union, even if the business \nis headquartered outside of the EU. Though GDPR creates a few new rights \naround data, it is only the latest iteration of data protection regulation affecting \ncitizens of the EU. Under GDPR, people have specific rights over data about \n36\nthemselves, including over how or whether it is collected, managed, shared, \nand deleted. Of particular interest to businesses building AI systems is the set \nof rights given to people regarding automated decision-making. \n37\n \n \nIt is unlikely that everyone will exercise these new rights immediately – recent research \nin the retail sector, carried out by the ODI, found that only 25% of shoppers were likely \nto exercise their right to portability. However, there is potential that more people \n38\nmight choose to exercise these rights in response to a loss of trust in AI systems or the \nbusinesses using them. More importantly, new products and services, or features for \nexisting services, might make use of these rights and these may enable people to \nexercise these rights easily. For example, an application might ask for permission to \naccess data about your spending habits to recommend some other service, and if \ngranted, exercises your right to access data for you. \n \nIf businesses and organisations lose the trust of their users, they may find that their \nusers are more reluctant to share their data or allow companies to use their data to \ntrain new models. Less access to data could result in less functional AI systems – \nthis would not only hurt the individual business, but could hurt the wider AI business \ncommunity by leading to a drastic reduction in relevant, accessible training data. \nAn opportunity rather than a threat \nSeen from a different perspective, businesses that help their customers balance their \ndesire for improved services with the desire for privacy, will preserve trust. Thus, \nbusinesses and organisations developing AI systems need not see this trend toward \ngreater personal control of data as a bad thing. Indeed, it could be a big opportunity \nfor innovation.  \n \nMany of our interviewees argued that businesses should see this trend toward greater \npersonal control of data as a business opportunity to be approached proactively and \npositively. Michael Veale, for instance, felt that GDPR should serve as a wake up call to \nbusinesses. Rather than seeking to avoid or fight against these realities, Veale advised \nbusinesses to say, “Okay, we need to think about the business model for this – \nwe can’t pretend we’re all closed all the time”.  \n \nIf a business designs a service that builds trust between them and their users by \nsimplifying the process of exercising rights over data and making it easier for users to \nunderstand how their data is being used, they may attract more users. That business \nwill have created a market and gained a commercial advantage over businesses that \n35\n Information Commissioner’s Office, ‘Guide to the General Data Protection Regulation \n(GDPR)’, \nhttps://ico.org.uk/for-organisations/guide-to-the-general-data-protection-regulation-gdpr​.  \n36\n ICO (September 2017), ‘Overview of the  General Data Protection Regulation’, \nhttps://ico.org.uk/for-organisations/data-protection-reform/overview-of-the-gdpr​. \n37\n Information Commissioner’s Office. Rights Related to Automated Decision Making \nIncluding Profiling’, \nhttps://ico.org.uk/for-organisations/guide-to-the-general-data-protection-regulation-gdpr\n/individual-rights/rights-related-to-automated-decision-making-including-profiling \n38\n The Open Data Institute (2017), ‘The EU GDPR Opportunities for Grocery Retail’, \nhttps://drive.google.com/file/d/1A_5gL2504AaXWEvig7HZSWIex13oMIzs/view​. \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   24 \n\n \nare slow to respond to the new realities of a future where people are given more control \nover data about them. \n \nThe importance of this trend in driving future business practice was also highlighted by \nMaria Axente. While many AI businesses currently see the collection and aggregation \nof data as the key to gaining a competitive edge, Axente postulated that the prospect \nof shifting control of data towards consumers and away from companies will increase \nthe attractiveness of the ‘closed algorithm + open data’ model. If companies find that \n39\nthey are no longer able to restrict access to data they have collected about people, \nthen they may decide that the best way to add value is to sell access to algorithms that \nallow analysis of customers’ datasets – i.e. the ‘proprietary algorithm’ model. \n \nSandra Wachter felt that a shift towards giving people greater control over data about \nthem would be a boon for businesses developing AI systems. “I actually think it will \nenable innovation”, she stated during our interview: “it redirects markets and refocuses \nresearch on something new”. She was confident that by applying themselves to the \nnew realities around privacy, transparency and accountability, AI researchers would be \nable to come up with “tools that will address the market”. Michael Veale felt similarly \nand added that this shift was “quite an important move to break down some of the \nmonopolies” that might otherwise form.  \n \nWachter warned that refraining from collecting any data that might be deemed \npersonal or sensitive out of fear of running afoul of data protection regulations, would \nbe the wrong approach. \n \n“ \nIt is counter-intuitive because you might want to say, \n‘because of data privacy considerations you want to \ncollect as little data as possible’, but if you do that you \nactually end up with more discrimination than you \nwould​ ​otherwise. \n– Sandra Wachter \n \n \n \nHer reasoning was that by restricting the collection of data, businesses will almost \nguarantee that AI systems will have ingrained biases because those systems will be \ntrained on limited data sets. She closed by noting: “I think there is some tension here \nthat needs to be resolved in the future.” To build effective, unbiased (and therefore \nmore profitable) AI systems, businesses will need to have access to as much data as \nis legally and ethically possible.  \nGovernment intervention and regulation \nOver the coming years, businesses developing AI systems will need to decide how \nto respond to the trend towards people having greater control over data about them. \nBy responding proactively and positively, businesses developing AI systems can turn \na potential threat to their business model into an opportunity for innovation – both on \nan individual basis and as a sector. \nOn a practical level, businesses that adopt good practices around GDPR or transparent \nalgorithmic decision-making will lessen the likelihood of legal challenges and potentially \nhefty fines.  \n40\n39\n This interview was conducted by Future Advocacy on behalf of the ODI. \n40\n Matthew Sheret (2017), ‘Designing for Trust’, \nhttps://projectsbyif.com/blog/designing-for-trust \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   25 \n\n \n \nOn another level, by moving to grant wider access to data they use, businesses \ndeveloping AI systems may be able to avoid potential anti-monopolistic government \nintervention. If, over the coming years, governments and regulatory agencies find that a \ndata oligopoly is hindering innovation in the AI community, they may move to challenge \nthose monopolies, especially if governments themselves find that the efficacy of their \nown services is being hindered by a lack of access to data caused by companies \nchoosing to restrict access to data.  \n  \nExamples of similar moves in the past include ‘United States v. Microsoft Corporation \n253 F.3d 34 (D.C. Cir. 2001)’, a U.S. antitrust law case wherein Microsoft’s market \ndominance was judged to constitute a monopoly, as well as the European \nCommission’s recent €2.42 billion fine of Google, alleging that the company “abused \nits market dominance as a search engine by giving an illegal advantage to another \nGoogle product, its comparison shopping service.” \n41\n \nThe landscape for businesses developing AI systems is changing. By responding \npositively and proactively, businesses can capitalise on these changing circumstances. \n  \n41\n Joel Brinkley (2000), ‘U.S. VS. Microsoft: the Overview; U.S. Judge says Microsoft \nViolated Antitrust Laws with Predatory Behavior’, \nhttp://www.nytimes.com/2000/04/04/business/us-vs-microsoft-overview-us-judge-say\ns-microsoft-violated-antitrust-laws-with.html \nEuropean Commission (2017), ‘Antitrust: Commission fines Google €2.42 billion for \nabusing dominance as search engine by giving illegal advantage to own comparison \nshopping service’, ​http://europa.eu/rapid/press-release_IP-17-1784_en.htm​. \n \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   26 \n\n \nConclusion: opening and \nsharing data \nTo overcome the challenges arising from restricting access \nto data and capitalise on the opportunities as people \nexercise more control over data about them, more data \nmust be shared with more businesses, in a way that \nretains​ ​the trust of people while promoting innovation  \nTo grow the AI sector in a way that benefits businesses, governments, and people, we \nwill need to ensure that the system respects commercial interests while actively giving \nusers control over data about them and enabling users to make decisions about how \ndata about them is used and shared. Businesses should seek explicit permission from \ntheir customers and others the data might be about when opening or sharing data \nabout them. Giving users granular control about how their data might be shared and \nexplaining the risks around it will enable them to make informed decisions. \n \nSharing and opening data can help support business objectives as well as benefiting \nsociety – for example it can be used to build up a platform for engaging new and \nexisting customers, enable the production of complimentary services, and encourage \nopen innovation around strategic challenges.  \n42\n \nBusinesses need to consider how they will provide greater access to data in a way \nthat people will trust. In all cases, this will rely on clear communication of not only \nthe methods being used but also the benefits this might have.  \nPublishing open data \nNot all data that is useful for building AI systems is personal data or commercially \nsensitive. In many cases, there are few limitations on providing wider access to this \ndata. To maximise the potential value – to the business, the AI sector as a whole, and \nsociety – businesses should publish this data under an open licence as open data. \nThere is clearly a desire for more publicly available datasets within the AI sector – \n72% of respondents to a recent Digital Catapult survey of machine learning companies \nwanted the catapult to provide access to public datasets. \n43\n \n“ \nUnsurprisingly, data was the most in-demand item, \nspecifically access to new public (or private, sandboxed) \ndatasets for training machine learning models. \n42\n The Open Data (2016), ‘Open enterprise: how three big businesses create value with \nopen innovation’, \nhttps://theodi.org/article/open-enterprise-how-three-big-businesses-create-value-with-\nopen-innovation  \n43\n Digital Catapult (2018), ‘Machines for Machine Intelligence’, \nhttps://www.digitalcatapultcentre.org.uk/machines-machine-intelligence-report \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   27 \n\n \n \nAs highlighted earlier, the majority of existing open data sources come from public \nsector organisations, and there have been questions about the quality of that data. \nHowever, increasingly, the private sector is making data available openly and this trend \nlooks set to continue. As Michael Veale argued, “the tide is going towards data being \nmore open” and businesses will therefore have to become “more open with their data” \ngoing forward.  \n \nPublishing open data can be relatively easy for businesses. All they need to do is make \na dataset or expose an API endpoint in a way that is accessible on the web and make \nit clear that it is published under an open licence. The licence is key, enabling users of \nthat data to easily understand what they can do with the data. The licence should meet \nthe requirements of Open Knowledge’s Open Definition. Best practice recommends \n44\nthe use of unedited standard open licences, such as those provided by Creative \nCommons. By applying these licences to existing public sources, data users can \n45\nbe more confident in using the data to develop innovative products and services.  \n \nBusinesses should also include detailed metadata about the data as part of best \npractice, enabling users to understand what the data is, its source and potential \nlimitations. The ODI’s Open Data Certificates and guides provide significant guidance \n46\non open data publishing, as well as helping to make data discoverable and usable. \n47\nBusinesses could also choose to use existing open source or third party tools to \npublish data, including the ODI’s Octopub tool or a platform like data.world, which \n4849\nmake the process easier. For high-volume data, businesses looking to recover some of \nthe costs of publishing can consider freemium models for data publishing such as \nthose offered by OpenCorporates. \n50\n \nFor data that does contain content about people, there are potential strategies that \nbusinesses can use to publish this data. Anonymisation and aggregation techniques \ncan be used to lower the risk of individuals being identified. Explicit consent to share \n51\ndetails about people can also be sought for certain types of data, for example people \ndonating money to particular organisations might give permission for their contribution \nto be published openly. Creating a system where explicit individual permissions can be \nobtained and combined with clear licensing terms for the use of that data by other \norganisations could help companies developing AI systems avoid breaching the trust \nof people when using publicly available data sets to train their AI systems. In some rare \ncases, it might be possible to publish data about people without consent if its already \nwidely available, for example data about public figures or people that have been \ndeceased for a long period of time.  \n \nOf course, not all data can be opened – especially where people choose not to share \ndata about them. However there are emerging techniques for sharing granular data \nwithout revealing details about individuals or commercially sensitive data, especially \naround machine learning. Synthetic data is one of many techniques for de-identification \n44\n Open Definition, Open Definition 2.1, ​http://opendefinition.org/od/2.1/en  \n45\n Creative Commons, ‘About the licenses’, ​https://creativecommons.org/licenses \n46\n The Open Data Institute, ‘The mark of quality and trust for open data’, \nhttps://certificates.theodi.org/en \n47\n The Open Data Institute, ‘Data publishing and use’, \nhttps://theodi.org/topic/data-publishing-and-use  \n48\n Octopub: ​https://octopub.io  \n49\n Data World: ​https://data.world  \n50\n For more information about OpenCorporates, see: \nhttps://opencorporates.com/api_accounts/new​.  \nFor more information on potential business models around open data see: The ODI \n(2017), ‘Data entrepreneurship: exploring successful business models with open data’, \nhttps://theodi.org/article/data-entrepreneurship-exploring-successful-business-models\n-with-open-data  \n51\n We write ‘lower the risk’ since arguably it may not always be possible to fully \nanonymise data. For more information, see: \nhttps://ico.org.uk/for-organisations/guide-to-data-protection/anonymisation \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   28 \n\n \nof data. Synthetic data is created artificially from real data to maintain the overall \n52\nstatistical understanding while changing the individual records. The ability to train \nAI systems with this kind of  data would substantially alleviate concerns about \nsharing potentially identifiable or commercially sensitive data. There have been \nsome documented success in academia and the commercial sector is seeing \n5354\nthe emergence of startups trying to commoditise the practice. \n55\nSharing data \nOur interviewees commented frequently on the potential for businesses to share data \nwithin mutually beneficial partnerships and collaborations. The key, according to \nDaniel Staff of Digital Catapult, would be to match businesses without access to data \nwith data rich businesses in ways that ensure both parties receive something of value \nfrom the partnership. On one side, Staff explained, “you have a company that’s sitting \non a lot of data but not necessarily leveraging it because they’re not aware of new \ntechniques and new research”, while on the other you have “a small startup that has \nthe knowledge but not necessarily the data”. In such a collaboration, the company \nwith a large data set would receive the technical expertise needed to unlock valuable \ninsights from their data, contributing to that company’s competitive advantage. \nConversely, the startup would receive access to large datasets that are crucial for \ntraining and developing innovative AI systems. ​Digital Catapult is one organisation \nhelping to create this type of collaboration through open innovation activities and other \nprogrammes such as the Machine Intelligence Garage.  \n56\n \nThere is great potential for partnerships and collaborations that involve not only private \nsector companies, but government bodies, universities, non-profits, and public sector \norganisations as well. \n \n“ \nWe need to explore how to encourage better data equity \nso that we have some stronger sharing protocols between \ncompanies like Facebook and all the social science labs \nin​ ​the universities around the world. A lot of this is very \nobscure to us because we don’t have access because \ntheir data is extraordinarily valuable but there ought to be \nsome way of managing large scale data sharing efforts \nthat are in everybody’s interest. \n– Sir Nigel Shadbolt \n \n \n \nThere are a number of difficulties in realising these types of mutually beneficial \ncollaborations, not least of which is identifying suitable partners. One approach being \n52\n Personal Data Protection Commission (2018), ‘Guide to Anonymisation Techniques’, \nhttps://www.pdpc.gov.sg/-/media/Files/PDPC/PDF-Files/Other-Guides/Guide-to-Anon\nymisation_v1-(250118).pdf \n53\n Adam Kortylewski et al (2018), ‘Training Deep Face Recognition Systems with \nSynthetic Data’, ​http://search.arxiv.org:8081/paper.jsp?r=1802.05891  \n54\n Stefanie Koperniak (2017), ‘Artificial data give the same results as real data — \nwithout compromising privacy’, \nhttp://news.mit.edu/2017/artificial-data-give-same-results-as-real-data-0303 \n55\n Neuromation: ​https://neuromation.io/en  \n56\n Machine Intelligence Garage: ​https://www.migarage.ai  \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   29 \n\n \ntaken for finding innovative partners is adopting open innovation approaches. In some \ncases this is defined as a challenge, where a company with a large data set and, in \nsome cases, a well-defined problem puts out an open call for startups and SMEs to \ndevelop innovative solutions to that problem. This can be done by releasing the data \nup front – for example the Kaggle competition platform enables big businesses to host \nopen data science competitions around specific data and specific problems, and \nanyone can enter.  \n57\n \nAlternatively, businesses can put out open calls for partners and then enter ongoing \ndata sharing arrangements. For example, the EU-funded Data Pitch project pairs \ncorporate and public-sector organisations that have data with startups and SMEs \nthat work with data, as well as providing lots of support for these collaborations. \nBusinesses could take either approach or a mix of the two depending on the \noutcomes they are looking for. \n \nWhether partners are identified directly or through open innovation approaches, the \nnext step for these businesses will be to build trust between the various parties, and \nfinding adequate ethical, legal and technical means of sharing data between them. \nThis is particularly challenging when personal data such as journey or health data \nis involved, but even non-personal commercial data can be difficult to share.  \n \nDougal Featherstone of Frosha explained that in his experience it is often not possible for \nSMEs like Frosha to gain access to data even when people and companies are willing to \nshare it with them. With an eye to the future he asked, “How do we build that bridge?” \n \n \nData trusts and exchanges \n \nOne potential way of bridging the gap between parties that want to share data but \ncurrently find it difficult to do so, is through data exchanges, marketplaces or trusts. \nEach of these types of arrangement aim to provide the technical and legal \ninfrastructure to allow businesses and other organisations to share data in a secure \nmanner. The aim is to provide mechanisms that facilitate sharing between a number \nof different parties in a more frictionless way than lots of individual data sharing \nagreements. \n \nIn our interview, Nick Allott of nquiringminds – a data analytics company that hosts a \ndata sharing platform – noted that there is “massive potential value in being able to \nshare raw data and analyse streams of data between parties.” Value, he clarified, for \nlarge companies, SMEs, startups, public sector organisations, and universities alike.  \n \nSimilarly, John Enevoldsen explained that one of the reasons why Ocean Protocol was \nstarted was to help AI businesses collaborate more freely by bridging the gap between \nthe data haves and data have nots \n \nAccording to Allott, one of the main reasons data is currently not shared between \nbusinesses and organisations is that it is difficult to trust other organisations with \npersonal or commercial data. The goal of the data exchange operated by \nnquiringminds is to “afford certain controls, checks and balances and assurances that \nlubricate that data flow”. “The key to AI is access to data,” he explained, “the key to \nunlocking that data is having a secure platform that allows your customers to have \nconfidence in it and share data between different people”. \n \nEach of these types of arrangement have the potential to facilitate wider data sharing – \nwhich one is most appropriate will depend on the situation. Data trusts which are \ngoverned by collaboration rather than through financial incentives may offer a means \nfor businesses to create significant, ongoing collaborations.  \n \n  \n57\n Kaggle (2018), ​https://www.kaggle.com/competitions \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   30 \n\n \nRecommendations to businesses \nBusinesses need to identify the costs and benefits of making more data available \nas part of the AI systems they are building. They need to understand the potential \nimplications of failing to increase access to data around stifling innovation and \nencoding unintended bias. In light of the current trend towards people having greater \ncontrol over data about them, businesses need to design AI systems that create trust. \nIf they do not, companies risk losing access to data, either from individuals \nwithdrawing consent, competitors siphoning users, or through government \ninterventions in the market. This being the case, businesses should: \n \n \ni) Examine their current approach to data as part of their business model \n \nBusinesses should aim to understand how they are currently creating \na competitive advantage in terms of access to data and algorithms. \nThey may choose to adapt their current approach to data, exploring \nhow they can improve access to data and realise the associated benefits. \n \nii) Consider what data might be made open \n \nBusinesses should identify where, if at all, they can publish data openly. \nThis is subject to obtaining explicit consent if that data is about people, \nand understanding what de-identification techniques could be used to \navoid the identification of individuals.  \n \niii) Explore the options around creating data trusts \n \nBusinesses should examine the potential for using data trusts to share data \nsecurely between partners. If this is personal data, this is subject to obtaining \nexplicit, informed consent from the people who the data is about. \n \n \nIn addition, there is still much more research to be done on how businesses can share \nand open data to support the development of the AI sector. This might include work by \ngovernment and other organisations on how to encourage, facilitate and possibly \nincentivise greater collaboration and sharing of data within the AI sector.  \n \nAt the ODI we will begin to explore some of these issues over the next year, specifically \nemerging methods of de-identification of data about people and the potential for data \ntrusts to encourage collaboration within the AI sector. \n \n“ \nIt isn’t a perfect world in terms of data and there’s plenty \nmore still to do. And right at the heart of that are questions \nof: What data should be open? What should be shared? \nWhat should stay closed? What’s personal and what’s \nnot? That whole data spectrum discussion is so important \nstill. The slight worry is that people may think: ‘Data has \nbeen solved – there’s just loads of it about, so we can \nworrying about that’. \n– Sir Nigel Shadbolt \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   31 \n\n \n \nMethodology \n \nFor this research, we commissioned Future Advocacy to produce an overview of the \nrole of artificial intelligence and machine learning in business models and policy \nframeworks.  \n \nThey conducted interviews and consulted academic publications, public policy reports, \nand news publications in order to explore the role of AI, machine learning and data in \nemerging business ​models. We then conducted a landscape review which involved \nextensive research of the current use of AI in the commercial sector.  \n \nWe identified a list of startups and large firms using AI in their business, which we \nanalysed and categorised according to the way that AI was deployed within each \nbusiness. A number of businesses were selected for targeted, in-depth interviews \nbased on how they turned AI into a commercial advantage. \n \nWe conducted 17 interviews with participants from a range of backgrounds, striving for \na balance between people from academia, research institutions, startups, SMEs and \nventure capital. Our interviewees were mainly from the UK (13), though we also \ninterviewed one person each from France, the Netherlands, Spain and the United \nStates of America. \n \n \n \n \n \n \n \nOpen Data Institute 2018 / ReportThe role of data in AI business models   32 ","version":"1.10.100"}