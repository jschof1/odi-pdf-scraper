{"numpages":13,"numrender":13,"info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"Skia/PDF m87"},"metadata":null,"text":"\n\n \n\n \nContents \n \nIntroduction3 \nInitial findings4 \nTrust and trustworthiness are highly context-dependent4 \nThird-party certifications are useful, but only to a degree and in certain \ncontexts6 \nThe most appropriate method will depend on the context7 \nPlans for the development phase10 \nNext steps10 \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nAbout \n \nThis report has been researched and produced by the Open Data Institute, and \nwas published in September 2020. The lead authors are Jared Robert Keller, \nSonia Duarte, Fionntán O'Donnell, Elea Himmelsbach, Renate Samson and Olivier \nThereaux. \n \nIf you would like to send us feedback, please get in contact with us at \nresearch@theodi.org​. \n \n \nHow can it be improved? We welcome suggestions from \nthe community in the comments. \n \nOpen Data Institute | September 2020                    Demonstrating and assessing trustworthiness when sharing data    2 \n\n \nIntroduction \nWhen sharing or accessing data, organisations need to be able to trust those they \nare interacting with and feel comfortable doing so. Since data ecosystems are \nmade up of a range of organisations with different roles and responsibilities, an \norganisation accessing or using data often needs to be able to trust more than the \norganisation holding or providing that data. To some degree they need to be able \nto trust any other organisations involved in the collection, storage, management, \nanalysis, sharing or use of that data along the way. \n \nAt the Open Data Institute (ODI) we have been conducting a research and \ndevelopment project that aims to develop tools and resources to build trust \nbetween organisations when sharing and accessing data, with the goal of helping \ndata ecosystems operate more effectively while reducing the risk of causing harm.  \n \nThe scope of the project presents an interesting challenge, as it involves concepts \nthat can be difficult to pin down. Our previous ​research into designing trustworthy \ndata institutions​ has shown, for instance, that ‘trust’ and ‘trustworthiness’ are \noften perceived as nebulous topics. Trust is inherently about relationships and \n1\ncommunication between people and organisations, but it can be difficult for \nmultiple parties to align around a shared understanding of what trust and \ntrustworthiness mean. Similarly, sharing and increasing access to data can take \nmany forms. Our research into the ​wide world of data sharing​ demonstrated that \nthere is a range of approaches to sharing data, each of which involves different \ntrust relationships and carries different benefits and limitations. Lastly, ​research \n2\nby the ODI​ and others found that although there is broad agreement that data \nsharing is beneficial, it is often difficult to quantify the actual ‘value’ or ‘impact’ of \nsharing data. The goal of this project – to ​positively impact​ data ecosystems by \n3\nbuilding​ ​trust​ between organisations when ​sharing data​ – is multidimensional and \nchallenging, but worthwhile. \n \nThis interim report summarises the research conducted over the first phase of the \nproject and looks ahead to the coming development phase. In particular, it lays \nout why third-party certifications and audits are useful, but only to an extent and in \ncertain contexts. In other cases, alternative approaches to building trust may be \nmore appropriate. \n  \n1\n Open Data Institute (2020), ‘​Designing trustworthy data institutions​’. \n2\n Open Data Institute (2020), ‘​Mapping the wide world of data sharing​’.  \n3\n Open Data Institute (2020), ‘​The Value of Data​’. \n \nOpen Data Institute | September 2020                    Demonstrating and assessing trustworthiness when sharing data    3 \n\n \nInitial findings \nGiven the necessarily broad terrain covered by this project, the research phase \naimed to narrow the scope. We cannot address every challenge related to trust \nand data that organisations might have, so we have focused on defining what is \nin/out of bounds and setting achievable goals. We have outlined a few of our initial \nfindings below.  \n \nAn important learning to come out of our early research (backed up by ​previous \nresearch at the ODI​) is that there is a difference between ‘being trustworthy’ and \n‘being trusted’. The main difference is that being trusted is relational and involves \n4\nan assessment by another party. An organisation might deem themselves \ntrustworthy​, but they can only consider themselves ​trusted​ once another \norganisation has placed its trust in them in some way – for instance trusting them \nto perform a service or deliver a product.  \n \nStressing the relational aspect of trust is important, as it highlights that \norganisations need to demonstrate their trustworthiness to specific audiences \nrather than to the world in general. Indeed, our early research for this project has \nconfirmed that some organisations think of trust and trustworthiness in general \nterms and do not think deeply enough about how to demonstrate specific aspects \nof their trustworthiness to specific audiences in specific ways.  \n \nIn light of this, when we speak to organisations we ask them not about trust in \ngeneral, but about how, specifically, they go about ​improving​ and ​demonstrating \ntheir trustworthiness to other organisations when accessing, using and sharing \ndata – and vice versa, how they go about ​assessing​ the trustworthiness of others. \nFor instance:  \n \n●An organisation might strive to ​improve​ its internal trustworthiness by \nundergoing a training scheme or through conducting ethical reviews.  \n●This is often not enough to garner the trust of other organisations, \nhowever. In order to be trusted, they must ​demonstrate​ their \ntrustworthiness to other organisations, perhaps by displaying kitemarks or \npublishing the results of ethical reviews. \n●And since ‘being trusted’ is relational, those other organisations must be \nable to ​assess​ the trustworthiness of that organisation, possibly by \nconfirming that it has undergone a relevant training scheme or by locating \nopenly-published results of ethical reviews. \n4\n Open Data Institute (2020), ‘​Designing trustworthy data institutions​’. \n \nOpen Data Institute | September 2020                    Demonstrating and assessing trustworthiness when sharing data    4 \n\n \nTrust and trustworthiness are highly \ncontext-dependent \nOur research has confirmed that ‘being trustworthy’ means very different things to \ndifferent people – and therefore the methods that people and organisations use to \nimprove, demonstrate and assess trustworthiness vary widely depending on the \ncontext.  \n \nFor instance, ‘trustworthiness’ means different things to different people and \norganisations. \n●Organisations working in different sectors​. What an organisation does \nto demonstrate trustworthiness in the health sector is different to what \norganisations do in the engineering or finance sectors. This is because \ndifferent sectors have different rules governing ethics and trustworthiness, \ndifferent governing bodies and different forms of sanction, redress and \nliability. In addition, different sectors value and use data in different ways, \nwhich can produce different business models and priorities within \norganisations. \n●Organisations performing different roles within a sector. ​Even within \nthe same sector, what defines a trustworthy ‘data contributor’ is often not \nthe same as what defines a trustworthy ‘data intermediary’ or ‘data user’. \nSimilarly, people and communities impacted by the sharing of data are \nlikely to view trustworthiness differently than regulators, funders or \npolicymakers working within that sector.  \n●People working in different parts of an organisation.​ Within a single \norganisation, a member of the legal department will have a different view \nof trustworthiness compared to someone working in data management, \nsales or communications, for example. One respondent to our survey, in \nfact, noted they were answering from only one perspective among many \nwithin their organisation: “This is in my role working with data, I am sure \nthat if a different member of our organisation, for example, finance, \ncompleted this they would respond differently.”  \n \nResearch and methodologies \nSince May 2020, we have been conducting desk research on this topic, interviewing \nexperts and surveying people from organisations involved in sharing or increasing \naccess to data.  \n●Expert interviews ​–​ ​Between June and August we conducted 10 expert \ninterviews with people from organisations performing different roles within data \necosystems – for example data contributors, data intermediaries and data users \n– across the health and finance sectors.  \n●Qualitative and quantitative survey ​–​ ​In August we launched a survey to \nidentify how organisations demonstrate and assess trustworthiness when \nsharing data. The questions were aimed primarily at people working in \norganisations that collect, store, use, access or share data in some way, but we \n \nOpen Data Institute | September 2020                    Demonstrating and assessing trustworthiness when sharing data    5 \n\n \nwelcomed responses from regulators, funders, policymakers and certifying \nbodies as well. To date, the survey has received 59 responses from \norganisations across a dozen sectors. \n●Working in the open​ – Throughout this project we have strived to work in the \nopen and have provided regular updates of our progress, including through the \npublication of an ​introductory launch blog post​, a ​work note on the various \nresearch streams​ of this project and a ​work note detailing the research that \ninformed the survey​. \n5\n \nThe variables outlined above impact how trust and trustworthiness are defined, \nimproved, demonstrated and assessed – but they are only a start. We have also \nidentified other variables that impact trust and trustworthiness, such as: \n●The maturity of the use case or ecosystem​, for example an established \necosystem versus a new or evolving ecosystem.  \n●The sensitivity of the data involved​, for example an agreement to share \nnon-sensitive data versus an agreement to share highly sensitive or \npersonal data.  \n●The type of technologies in use,​ especially newer technologies or \ntechnologies that develop or change quickly. \n●The type of service, product or transaction​, for example a \nbusiness-to-business service versus a business-to-consumer service. \n●The role or importance of data within the organisation involved​, for \nexample an organisation whose business model revolves around data in \nsome way versus an organisation for whom data is a smaller part of their \nbusiness. \nThird-party certifications are useful, but only to \na degree and in certain contexts  \nOne consistent theme that emerged from our desk research, expert interviews and \nsurvey responses is that there is no single method, approach or mechanism that \ncan build trust between organisations in every circumstance and every context. \nThere is a wide range of different methods for improving, demonstrating and \nassessing trustworthiness, and different methods are better suited to different \ncircumstances, challenges or contexts. What works to build trust between \norganisations in the health sector might not work in finance; and what works to \nbuild trust between two organisations when sharing data directly might not work \nfor an ecosystem of organisations sharing data via an intermediary.  \n \nOur research has found that, in particular, while third-party certifications and \naudits are useful for improving, demonstrating and assessing trustworthiness, in \nsome cases alternative approaches may be more appropriate.  \n5\n The Open Data Institute (2020), ‘​Help us understand how certification can help build trust \nin data ecosystems​’; The Open Data Institute (2020), ‘​R&D: Building trust through audit and \ncertification. Worknote #1​’. The Open Data Institute (2020), ‘​R&D: Building trust through \naudit and certification – Worknote #2​’. \n \nOpen Data Institute | September 2020                    Demonstrating and assessing trustworthiness when sharing data    6 \n\n \n \nFor instance, when we asked respondents to rate the usefulness of things like \nthird-party assessments, audits and certifications in helping them demonstrate \ntheir trustworthiness to others, the average rating was 7.8 out of 10 (10 being ‘very \nuseful’). Similarly, 71% of respondents said they were either satisfied or very \nsatisfied with the certification schemes that existed in their sectors. This was \nborne out in many of our interviews, with one interviewee noting that third-party \nassessments are often needed to “reduce the risk” of “bad things happening”.   \n \nHowever, certifications and audits are often seen as only one approach to \nimproving, demonstrating and assessing trustworthiness. Indeed, one respondent \nto our survey wrote that while third-party assessments were “of some use”, they \nwere ultimately “only an indicator not a guarantee”. This came out in our \ninterviews as well, with some experts noting that in order to build trust between \norganisations, a range of different approaches often need to be deployed in \ntandem. Certifications and audits were seen as offering a useful starting point or \nfoundation, but because trust and trustworthiness are highly context-dependent, \nother methods are often necessary, depending on the situation. As one \ninterviewee put it: “Certification could provide a very baseline level of assurance \nabout a data source, but it would just be the baseline because the data that you \nneed is very situational, specific.”  \n \nIn some circumstances or contexts, certifications and audits are seen as \nunproductive or unsuitable, for a range of reasons, including: \n●A belief that certification or audit processes often cannot keep up with the \npace of change in the domain, especially the pace of technological \nchange. \n●A concern that some assessment schemes can become ‘tick-box \nexercises’ that lack robustness.  \n●A concern that some certification and auditing schemes are easily gamed \nor become ‘certification theatre’, where both parties know the certification \nor audit is inadequate but have no incentive to improve it. \n●A feeling that some complex technologies or data flows, for instance \nmachine learning algorithms or a system with millions of new data points \ndaily, may be hard, if not impossible, to adequately assess.  \n \nFinally, some of our interviewees and respondents noted that third-party \nassessments can, in certain cases, actually be harmful. In particular they noted \nthat certification and auditing schemes can hinder innovation if they are costly and \ntime consuming. This was seen to lock some smaller organisations out of the \nmarket, especially if the schemes are mandatory. One of the respondents to our \nsurvey, for instance, noted: “As a startup, I am concerned about losing access \ndue to higher ‘costs of doing business’, or worse, a ‘pay-to-play’ culture.”  \n \nOpen Data Institute | September 2020                    Demonstrating and assessing trustworthiness when sharing data    7 \n\n \nThe most appropriate method will depend on \nthe context \nBecause third-party assessments, certifications and audits are only useful in some \ncontexts, and because there is a wide range of different methods for improving, \ndemonstrating and assessing trustworthiness, we surveyed a range of \norganisations in different sectors to gather their views on the value of third-party \nassessments and to understand how they demonstrate and assess \ntrustworthiness when sharing data.  \n \nThe first section of the survey focused on identifying which aspects of an \norganisation are the most important when it comes to demonstrating \ntrustworthiness. Organisations are multifaceted, after all, so demonstrating \ntrustworthiness is multifaceted as well. By drawing on our desk research, expert \ninterviews and other research at the ODI we have been able to put together a list \nof different aspects of an organisation that organisations might feel the need to \nshow are trustworthy. In the survey we posed the question, ‘what about your \norganisation do you try to demonstrate is trustworthy?’ and asked respondents to \nrank the list in terms of priority for their organisation.  \n \nThe list currently includes things like: \n1.Your legal structure and compliance with relevant laws or regulations \n2.Your software and technical infrastructure \n3.Your information governance framework (eg data management and data \nprotection procedures) \n4.Your commercial practices and how ‘value’ is created or shared \n5.Your decision-making processes for how data is collected, managed, \nused and shared \n6.Your ethical review procedures and how you work to minimise bias or \nharms \n7.Your oversight, accountability and redress procedures \n8.Your transparency or engagement procedures \n9.The capabilities and expertise of the individuals working within your \norganisation (for example demonstrating that they are good practitioners) \n10.The datasets you supply (for example quality, safety, value) \n11.The services you deliver (for example quality, safety, value) \n12.The products you provide (for example quality, safety, value) \n13.Your commitment to ‘public good’ or having a ‘positive impact’ \n14.Your diversity and inclusion practices \n15.Your financial sustainability \n16.Your environmental sustainability \n \nWe asked the same question for ​assessing​ the trustworthiness of other \norganisations. The list is a work in progress, so if there is anything that you believe \nis missing from our list, please ​get in touch​ to let us know. \n \n \nOpen Data Institute | September 2020                    Demonstrating and assessing trustworthiness when sharing data    8 \n\n \nA few noteworthy initial findings \n●Respondents to our survey stressed the importance of being able to \ndemonstrate their commitment to ‘public good’.​ When asked ‘what about \nyour organisation do you try to prove is trustworthy?’, a commitment to ‘public \ngood’ or ‘social impact’ was ranked the second most important aspect of an \norganisation. However, when asked ‘which aspects of other organisations are \nimportant to assess?’, a commitment to ‘public good’ or ‘social impact’ was \nranked eighth. More work will need to be done to identify how representative \nthe results of our survey are, but they suggest that while organisations are often \nconcerned with ​demonstrating​ their commitment to public good, many appear \nto be less concerned with ​assessing​ whether others share that same \ncommitment.  \n●Efforts to build trust have frequently been reactive rather than proactive. \nThroughout our research we have come across instances where methods have \nbeen developed for improving, demonstrating or assessing trustworthiness as a \nreaction to an event, such as a reputational issue, a legal challenge or a system \nsecurity concern. We also found that unless there is a clear incentive, \ndeveloping methods for building trust can be drawn out, complex or difficult to \nagree. However, a starting point for organisations can be first engaging in \nlow-effort or low-risk situations, where trust is much more easily built. In these \ncases, it is less about demonstrating trustworthiness and more about having no \nreason to distrust. From these situations, trust can be built for more complex or \nhigher-risk situations. \n \nIn addition to asking people ​what​ about their organisation they strive to \ndemonstrate is trustworthy, the survey also asked people ​how​ they go about \ndoing so. We wanted to identify to what extent organisations use other methods \nor approaches to demonstrate and assess trustworthiness outside of third-party \nassessments, certifications and audits. Through our desk research, interviews and \nsurvey we have assembled a list of almost 20 ways that organisations \ndemonstrate trustworthiness, including:  \n \n1.Committing to specific legal agreements – for example contracts, terms \nand conditions or licenses \n2.Abiding by relevant laws and regulations \n3.Abiding by relevant standards (technical or data or quality) \n4.Committing to relevant principles or values  \n5.Committing to relevant best practice or codes of conduct \n6.Committing to relevant organisational or industry norms \n7.Attaining relevant certifications (at an organisational level) \n8.Attaining relevant certifications (at an individual level – that is, for \npractitioners within the organisation) \n9.Displaying relevant kitemarks, stamps or labels \n10.Undergoing tests or exams (either of your organisation, your people, or \nyour products) \n11.Undergoing or undertaking auditing schemes \n12.Answering queries or sitting for interviews \n13.Agreeing to performance monitoring or oversight \n \nOpen Data Institute | September 2020                    Demonstrating and assessing trustworthiness when sharing data    9 \n\n \n14.Agreeing to penalties or redress mechanisms \n15.Embedding regular internal review processes \n16.Embedding independent advisory processes – for example citizen juries, \nethics panels or data access boards \n17.Committing to proactive transparency – for example the publication of \nearnings reports, decision logs or the minutes of meetings \n18.Engaging and communicating with users, stakeholders or community \nmembers  \n19.Through implementing technologies designed to underpin or improve trust \n \nAs above, if there is anything that you believe is missing from our list, please \ncontact us​ to let us know. \n  \n \nOpen Data Institute | September 2020                    Demonstrating and assessing trustworthiness when sharing data    10 \n\n \nPlans for the \ndevelopment phase \nProviding an organisation with an approach to how they can build trust depends \non a wide range of variables. Therefore the development phase of this project will \nfocus on working with people and organisations in a range of contexts to identify \ntheir specific trust-related challenges and potentially co-create guidance, tools or \nresources that can help them address their specific needs.  \n \nFocusing on addressing concrete, trust-related needs will enable us to take an \nin-depth look at real data ecosystems, the trust relationships between different \nactors and how trustworthiness is improved, demonstrated and assessed within \nthose ecosystems. Furthermore, by creating, testing and iterating potential tools \nor resources with the actors and stakeholders involved in those contexts, we can \nhelp ensure that what we produce will be fit-for-purpose, useful and therefore \nmore likely to be adopted. A useful approach is unlikely to be developed unless \nwe are led by the people who understand the domain; our research has shown \nthat creating a certification or audit that is inadequate can actually be harmful \nsince, among other things, it can give organisations a false sense of security and \nleave them unaware of potential risks. Our research has also shown that there \nmust be transparency around what is being certified, who is doing the certifying \nand why. As one of the respondents to our survey put it: “If I have no real say in \nwhat the standards are, I'm much less likely to buy into them.” One of the best \nways of helping to ensure this is to develop them with input from the relevant \ncommunities.  \n \nIn some cases, we may find that people and organisations in a specific context \nwould benefit from an auditing scheme or agreed standards that could eventually \nform the basis of a certification scheme. But in other cases we may find that \nthings like guidance, training tools or a checklist of resources would help \norganisations improve, demonstrate and assess trustworthiness more effectively \nthan standards and certifications. \n \nThe insights and lessons we draw from this development work will be applicable \nbeyond the specific ecosystems and use cases we looked into. We therefore see \nthe development phase as ultimately contributing to our ability to offer overarching \nguidance and lessons to organisations in disparate contexts.  \n \nBecause of the nature of this work, we see it as contributing to a necessarily \nlonger term research endeavour. Further work from ourselves or other interested \norganisations will undoubtedly be needed. \n \nOpen Data Institute | September 2020                    Demonstrating and assessing trustworthiness when sharing data    11 \n\n \nNext steps \nOver the next six months, this project will progress through discovery, to alpha \nand then beta. During the discovery phase we will identify pressing challenges or \nopportunities related to trust and data, test some of our initial findings with \norganisations in those areas, identify their specific trust-related challenges and \ndevelop initial ideas for tools or resources that could address those challenges. As \nwe move into the alpha phase, we will develop basic prototypes that we can put in \nfront of potential users. The beta phase will involve taking the best idea(s) from the \nalpha phase and creating a refined version, ready to test on users. \n \nBased on our research, one of the areas where we believe we can have the \ngreatest impact in improving trust between organisations is in ‘less mature’ \ncontexts. Our research has shown that in mature, traditional or static contexts, \norganisations tend to have well-established mechanisms for improving, \ndemonstrating and assessing trustworthiness; in less mature contexts, previous \nunderstandings of trust and trustworthiness may need to be renegotiated and \nredefined and previously satisfactory methods for building trust may need to be \nrecontextualised, updated or replaced. In these types of areas, building trust is \nparticularly important, but particularly difficult. \n \nWithin the development phase, we are therefore interested in exploring a range of \ndifferent ‘emerging’ contexts, such as: \n●‘New’ use cases ​– for example, new uses of data or the repurposing of \ndata in novel ways. For instance, the mobility and transport sector where \nlocation data is increasingly being repurposed for novel uses; or the health \nsector where data not traditionally viewed as health data (eg fitness data) \nis being used to make health decisions. These novel uses often outpace \nthe development and adaptation of methods previously used to build trust \nwhen sharing data, so it can be difficult for organisations to improve, \ndemonstrate or assess trustworthiness around these new uses of data. \n●‘Evolving’ data ecosystems​, for example, ecosystems where new \nintermediaries are being installed or organisations are taking on new roles \nas data stewards or data institutions. For instance, the health or mobility \nsectors where organisations are seeking to play the role of independent, \nthird-party stewards of data. The introduction of these ‘new actors’ into \nexisting ecosystems requires the existing actors in those ecosystems to \nreassess their roles and to potentially adapt existing mechanisms (or \nintroduce new mechanisms) for improving, demonstrating or assessing \ntrustworthiness. \n●‘Emerging’ sectors​, for example, less-established sectors where roles \nand responsibilities have yet to be settled and methods of building trust \nhave yet to be agreed. For instance, the new sector that is consolidating \naround ‘alternative’ forms of investment data, or ‘alt data’. Within this new \nsector, data is being used in new ways, new data contributors are \nproliferating and organisations are unsure who they can trust. These \nemerging sectors often have ad hoc ways of improving, demonstrating or \n \nOpen Data Institute | September 2020                    Demonstrating and assessing trustworthiness when sharing data    12 \n\n \nassessing trustworthiness, but few established, scalable ways of doing so \nand little shared understanding of best practice or standards. \n \nWe will also be working with Frontier Economics, an economics research firm, to \nquantify the economic impact of increased trust between organisations in data \necosystems. At the ODI we have conducted research into the ways that trust can \nbe established and built when sharing and accessing data. There is also a large \namount of research into the relationship between data sharing and economic \nimpact. The research with Frontier Economics will seek to address the evidence \ngap between these two areas and attempt to quantify the economic impact of \nincreased trust between organisations when sharing and accessing data. \n \nIf you are an organisation that collects, manages, shares, accesses or uses data, \nwe would love to speak with you​ about how you improve and demonstrate your \ntrustworthiness and assess the trustworthiness of others. \n \nDuring the development phase of this project we are likely to convene stakeholder \nworkshops to test initial designs and gather feedback. If you would like to take \npart in these workshops or provide feedback as a ‘critical friend’ during this \nphase, please ​get in touch​.  \n \nWe believe, after all, that only by collaborating with stakeholders and members of \ndata ecosystems will we be able to help organisations build trust when sharing \nand accessing data, thereby helping to increase the sustainability and \neffectiveness of data ecosystems while reducing the risk of causing harm. \n \nOpen Data Institute | September 2020                    Demonstrating and assessing trustworthiness when sharing data    13 ","version":"1.10.100"}