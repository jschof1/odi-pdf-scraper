{"numpages":36,"numrender":36,"info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Adobe InDesign CC 2015 (Macintosh)","Producer":"Adobe PDF Library 15.0","CreationDate":"D:20170124234453+11'00'","ModDate":"D:20170124234459+11'00'","Trapped":{"name":"False"}},"metadata":{"_metadata":{"xmp:createdate":"2017-01-24T23:44:53+11:00","xmp:metadatadate":"2017-01-24T23:44:59+11:00","xmp:modifydate":"2017-01-24T23:44:59+11:00","xmp:creatortool":"Adobe InDesign CC 2015 (Macintosh)","xmpmm:instanceid":"uuid:23ec733f-ab45-a349-9c4d-70a333055cfd","xmpmm:originaldocumentid":"xmp.did:C25894B30B206811822A9858DD7B9C3F","xmpmm:documentid":"xmp.id:65fb0eaa-c821-47f2-95d0-d2fbf6caad58","xmpmm:renditionclass":"proof:pdf","xmpmm:derivedfrom":"xmp.iid:959cf2c3-4832-4932-bfdc-92e2baa83255xmp.did:40f9b89b-5cf3-48ba-b02d-696bbcc70278xmp.did:C25894B30B206811822A9858DD7B9C3Fdefault","xmpmm:history":"convertedfrom application/x-indesign to application/pdfAdobe InDesign CC 2015 (Macintosh)/2017-01-24T23:44:53+11:00","dc:format":"application/pdf","pdf:producer":"Adobe PDF Library 15.0","pdf:trapped":"False"}},"text":"\n\nWhat works\nin open data\nchallenges\nMethod report\nODI-WP-2017-001\nJanuary 2017\n\n2 What works in open data challenges | Open Data Institute 2016\nTable of contents \nExecutive summary 3\nIntroduction: Challenge prizes and open data in a global context 6\nWhy run an open data challenge? 11\nWhat benefits can you expect? 12\nRisks and issues to consider 14\nFour foundations for delivering effective open data challenges 16\n1. The principles of leading a challenge 16\nPrinciple 1: Invest in relationships 16\nPrinciple 2: Work openly and collaboratively  17\nPrinciple 3: Respect intellectual property and investment 17\nPrinciple 4: Minimise barriers to participation 18\n2. Designing your programme and activities 18\n3. Providing resources and inputs 21\n4. Creating incentives for participants 22\nConclusion and recommendations 25\nAbout this report 28\nAppendix                                                                                                             29\nGlossary                                                                                                          29\nExamples of open data challenges 30\nBibliography                                                                                                        33\nAuthor: Briony Phillips\nEditors: Anna Scott and Amanda Smith\nDesigner: Christie Brewster\nWith thanks to Eun A Jo for conducting the literature review,  \nand Marta Tondera for research support.\n\n3 What works in open data challenges | Open Data Institute 2016\nExecutive summary\nThis report reviews current theory and practice behind open data challenges as a mechanism \nfor driving open data improvement, engagement and innovation. Its main purpose is to equip \nand  enable  organisations,  governments  and  community  organisers  to  deliver  high-quality  \nopen data challenges while helping them to recognise nuances within their local contexts.\n \nOpen data challenges are a derivation of challenge prizes or inducement prizes, which have a \nlong history reaching back to the Longitude Prize in the 1700s.\n1\n While the theory and history of \nchallenge prizes is well documented by Nesta’s Centre for Challenge Prizes amongst others,\n2\n \nopen data challenges were not widely recognised until the 2000s.  \nOpen data challenges offer a mechanism that demonstrates the potential of open data, drives \nits  improvement  and  enables  entrepreneurs  to  innovate  with  it.  They  have  typically  been  \nimplemented  in  contexts  where  open  data  publication  and  use  are  already  advanced,  but  \nare  now  also  contributing  to  innovation  and  economic  development  in  developing  country  \ncontexts (as an alternative to hackathons).\n  \nThe number of countries, governments and organisations releasing data openly has increased \nsignificantly in the past few years. However, their motivations remain mixed. While some may \nsee  releasing  data  as  an  opportunity  to  increase  accountability  and  transparency,  others  \nhave realised its potential to support new business growth and innovation. For those with the \nambition  to  support  and  strengthen  a  sustainable  data  infrastructure,  open  data  challenges  \nprovide a framework through which to expedite this.\n  \nThis report draws on an extensive review of literature on the economics and management of \ninnovation contests, which was used to map over 25 open data challenges. Further qualitative \ninsights were drawn from nine interviews that were conducted with organisers of open data \nchallenges, representing seven geographic regions and five scales of operation. \nThe  report  explores  the  case  for  implementation,  explains  the  key  attributes  of  a  challenge  \nprize  and  provides  seven  recommendations  for  prize  delivery  to  help  others  design,  deliver  \nand evaluate open data challenge prizes effectively. \n1     See     http://longitudeprize.org/history.\n2     See     http://www.nesta.org.uk/sites/default/files/challenge-prizes-design-practice-guide.pdf.\n\n4 What works in open data challenges | Open Data Institute 2016\n1. Set clear objectives that reflect the primary interests of all core stakeholders. \nOrganisers should only conduct an open data challenge where it is appropriate \nand will contribute to their overarching goals. While open data challenges often \nhelp demonstrate the power of data that has already been released, the timelines \nthey work to are often  insufficient to drive the release of new open data. Effective, \ncollaborative, open design and marketing of challenge objectives will ensure that \nthey reflect goals that all key stakeholders subscribe to.\n2. Design a bespoke challenge structure that reflects these primary objectives \nthroughout. As this report illustrates, subtle and significant changes to challenge \ndesign will determine whether or not and to what degree its core objectives are \nachieved. While keeping resource, infrastructure and organisational constraints in \nmind, organisers should take time, utilise expertise and employ creative license to \ndesign a challenge that best reflects what they are trying to achieve in their unique \ncontext.  Every  challenge  should  start  with  a  call  to  action  focused  on  a  clear  \nchallenge question and culminate in the award of one prize to an overall winner \nwho is committed to sustaining their product or service. \n3. Commit to open design principles and be prepared to iterate or adjust plans as \nyou go. To deliver a successful challenge, organisers will need to:\n operate with uncertainty and unknowns as a core element of design\n invest in relationship building (with partners, participants and volunteers)\n work as collaboratively and openly as they would expect others to \n engage stakeholders in design and delivery\n respect participants’ intellectual property and level of investment\n minimise barriers to participation and have clear incentives\n4. Sustain focus on open data from launch to completion. Support participants \nto understand, access and use open data. A challenge cannot succeed unless \nsufficient, high-quality and relevant data are available. Challenges are much more \nlikely  to  succeed  when  data  infrastructure,  access  and  resources  are  carefully  \nprepared  and  maintained.  Organisers  should  recognise  that  many  of  their  \nparticipants  will  not  be  open  data  experts  and  will  need  support  in  accessing  \nand using it. Understanding what data is available and how it can be used can \nbe a significant barrier in creating ideas. Further, if every opportunity is taken to \nsupport data’s improvement and that of the surrounding ecosystem, a challenge \nprize can add significant value for the open data community, including publishers \nand users. This must be actively built into challenge design.\n\n5 What works in open data challenges | Open Data Institute 2016\n5. Take time to plan, deliver and review each stage of the challenge process. \nChallenges   often   look   straightforward   when   observed   from   an   outsider’s   \nperspective. However, a challenge is only simple when sufficient thought and \nexpertise is invested in its design and execution. Assembling a team with suitable \nexpertise is no easy task, but experts in business modelling, facilitation, judging \nand impact assessment will be essential to the success of the challenge.\n6. Do not stop at one challenge. To optimise their return on investment, challenge \nprize  organisers  should  consider  running  multiple  challenges  over  an  extended  \nperiod.  This  additional  upfront  commitment  will  create  an  opportunity  to  build  \nmomentum  with  participants  and  supporters,  and  ensure  lessons  are  recorded  \nand iterated quickly. The investment needed to launch and deliver a successful \nchallenge is significant, but once initial design, launch and awareness building \nis complete, much of the hard work is done and the reward will be greater from \ndelivering  multiple  challenges.  A  community  of  innovators,  policy  experts  and  \nentrepreneurs is easier to sustain than to create for a single open data challenge.\n7. Undertake an impact and process evaluation and share it.  As  a  community  \ncommitted  to  working  collaboratively  and  openly,  we  owe  it  to  one  another  to  \nshare the lessons and experiences that lead to both the successes and failures in \nour work. Too few process and impact evaluations exist in relation to open data \nchallenges. Together, we have the opportunity to change this.\n\n6 What works in open data challenges | Open Data Institute 2016\nIntroduction:  \nChallenge prizes and open data in a global context\nThe history of challenge prizes\nChallenge  prizes  in  some  form  have  been  recorded  throughout  history,  dating  back  as  far  \nas 1714, and are defined by Wikipedia as “a competition that awards a cash prize for the \naccomplishment  of  a  feat,  usually  of  engineering.  Inducement  prize  challenges  are  typically  \ndesigned to extend the limits of human ability” (Wikipedia, (2016b).\nNesta’s  Centre  for  Challenge  Prizes  further  explains  that  “challenge  prizes  (also  called \n‘inducement’ prizes) offer a reward to whoever can first or most effectively meet a defined \nchallenge. They act as an incentive for meeting a specific challenge, rather than as a reward \nfor past achievements” (Nesta, 2014).\nThe difference between hackathons and pure challenge prizes\nAll open innovation techniques, such as hackathons and challenge prizes, all share common \nobjectives. Specifically, they will all raise the profile of a given brand, topic, issue or resource, \nand engage a community of participants or specialists. However, hackathons and challenges \nare often conflated, leading to creative interpretations of both and a poor understanding of the \ndesign principles for a successful challenge. \nThe table below shows the differences between the two event types, when they should be \nused and what outcomes can be expected.\n3\nHackathonChallenge Prize\nDefinitionAn event in which programmers/\nsoftware development \nspecialists (e.g. graphic \ndesigners and project managers) \ncollaborate intensively on \nsoftware projects (Wikipedia, \n2016a).\nA series of activities leading to a \nreward for whoever can first or \nmost effectively meet a defined \nchallenge. The incentive is \nawarded for meeting a specific \nchallenge, not to reward past \nachievements.\n\n7 What works in open data challenges | Open Data Institute 2016\nGoals and objectives\nDevelop prototypes to test an \ninput or platform.\n• Quickly develop new software \ntechnologies\n• Locate new areas for \ninnovation and funding\n• Test resources such as data \nintegrity/functionality of API\n• Attendees learn new skills and \nbuild professional networks\nCreate sustainable products or \nservices that solve a specific \nissue.\n \n• Raise awareness about and \ngive momentum to the open \ndata movement\n• Teach participants specific \nskills\n• Prioritise the development of \nproducts/services \n• Support participants to \nexpedite product development\n• Seek to generate socially, \neconomically and \nenvironmentally responsible \nsolutions\nParticipantsPrimarily those with technical \nskills (computer programmers, \nsoftware developers, graphic \ndesigners etc)\nEntrepreneurs, startups, big \nbusiness, academic institutions \nand SMEs\nOutputs• Working prototypes/minimum \nviable product\n• Demonstration of potential\n• Minimal commitment required \nby participants\n• Innovative and sustainable \nproducts and services\n• Tested business model\n• Committed, engaged teams\nOutcomes• Refined and tested inputs \n(data, API etc)\n• Offers of employment/new \njobs\n• Improved awareness of a \nspecific issue\n• Personal and professional \nnetworks and development\n• Increased engagement \nbetween data publishers and \nusers\n• Network of knowledgeable \npeople engaged with the \nbrand/issue and data source\n• Increased profile for/\nawareness of challenge issue\n• Connect with talented \npotential future employees\nTime investmentPrep: 3 months (often less)\nDelivery: 1–2 days\nPrep: 2-3 months per stage\nDelivery: 3 months to 5 years\nCost (£-£££)£££££\nPotential impactPrimary impact on organisation \nand data users\nBroader impact including social \nand environmental\n\n8 What works in open data challenges | Open Data Institute 2016\nThe underlying research that informs this report assessed 25 selected open data challenges, \nsome  of  which  might  be  strictly  defined  as  hackathons,  particularly  those  that  prioritise \n“learning” as their primary objective. \nOpen data and challenge prizes\nOpen data is data that anyone can access, use and share. Open data lends itself to challenge \nprizes  particularly  well  because  it  shares  central  principles  with  a  well-run  challenge  prize,  \nsince both rely equally on collaboration, openness and building symbiotic relationships.\nPutting open data at the centre of a challenge prize has a number of key benefits. It brings \na  challenge  prize  concept  to  a  new  audience  (open  data  specialists),  increasing  the  pool  \nof  potential  participants  who  are  passionate  and  knowledgeable.  Including  open  data  in  a  \nchallenge prize also exposes this core resource to a new audience, increasing awareness and \nunderstanding for those sector specialists who are knowledgeable about the challenge topic \nbut not yet aware of relevant data that is publicly available.\nStipulating  the  use  of  open  data  within  products  and  services  in  this  way  helps  to  create  \ndemonstrable examples of the power of open data in a business context. When done well, this \nencourages greater interaction between users and publishers, thereby increasing the quality \nand availability of data, and helping countries and organisations to create a mature open data \necosystem.\nHistory of open data challenge prizes\nIn recent history, since the advent of the X Prize\n4\n in 1996 and the establishment of the Centre \nfor Challenge Prizes at Nesta in 2012, challenge prize methodology has blossomed beyond \nthe realms of engineering to encompass the open data sector. In particular, significant steps \nforward have been observed since the launch of the Open Data Challenge Series by Nesta and \nthe Open Data Institute in 2013.\n5\n \n4     See     https://www.xprize.org.\n5     See     http://opendatachallenges.org.\n\n9 What works in open data challenges | Open Data Institute 2016\nThe application of challenge prize methodology to the open data sector can be traced \nback to two main points of origin:\n The  growing  expectation  that  hackathons  should  deliver  more  sustainable,  \nquantifiable  outputs:   Event   commissioners   often   seek   a   simpler,   more   \ncost-effective  mechanism  through  which  to  deliver  sustainable  innovation \nand  settle  on  a  hackathon-challenge  hybrid.  In  2008,  the  UK  Government  \ninvited citizens to find innovative ways to use the masses of data that it has \ncollected  in  health,  criminal  justice  and  education.  At  the  time,  the  activity  was  \ndescribed as a ‘data mash-up’ competition, offering an example of challenge \nprize   and   open   innovation   theory   working   in   combination   (BBC,   2008). \n The design and delivery of the Open Data Challenge Series (ODCS) by Nesta and \nthe Open Data Institute: This series of seven challenges was conducted largely \nin  the  open  and  heralded  as  a  success,  thanks  to  an  independent  assessment  \nby  PWC,  which  projected  its  return  on  investment  to  be  5–10-fold  (Nesta  and  \nthe ODI, 2015. The ODCS released process and impact evaluations along with a \nhandbook (including a summary of its methodology) openly to support others to \nadopt and adapt the model (Nesta and the ODI, 2015b). ODCS is frequently cited \nby organisations as the inspiration and/or basis for their own model and approach. \nOne such example is Ukraine’s EGAP challenge.\n6\n EGAP is designed to drive the \ncreation and implementation of new electronic democracy tools to help citizens \nreceive new high-quality services, interact with the government effectively, have a \ndirect impact on it and help it to reach a new level of transparency and efficiency.\n \nCore features of open data challenge methodology\nOpen  data  challenges  have  evolved  in  a  variety  of  ways.  Challenge  structure  has  generally  \nmorphed to reflect more the priorities of the organiser than the core features of a challenge \nmethod. A project that delivers against the following core questions is technically classified as \nan open data challenge prize:\n Does the challenge address a specific and ambitious question that will require \nsignificant innovation?\n Is  a  timeline  clearly  communicated  in  which  the  number  of  qualifying  entries  \ngradually reduces to a small number of winners? Does the process culminate in \na significant cash incentive (or equivalent)? \n Are  participants  expected  to  deliver  a  product/service/prototype  that  they  are  \n6     See     http://egap.in.ua/komponent-3-e-demokratiya/egap-challenge-framework.\n\n10 What works in open data challenges | Open Data Institute 2016\ncommitted to in the medium to long term, in order to deliver sustainability? \n Are all participants required to use open data in their proposition?\nGlobal context for challenge prizes\nTo  date,  challenge  prizes  have  been  used  most  in  well-resourced  contexts.  More  recently,  \nopen data challenge prizes have been increasingly considered and implemented to contribute \nto innovation and economic development in capacity-constrained contexts (as an alternative \nto hackathons), such as India and South Africa.\nIn capacity-constrained contexts, our research highlighted the need to build collaboration into \nthe programme design to overcome capability gaps frequently experienced by participants. \nAs  these  countries  release  a  greater  volume  of  higher  quality  open  data,  there  is  a  growing  \nexpectation that it should be used. Effective challenge prizes enable organisers and government \nofficials to have greater visibility about who is using their data and how, while fostering open \nchannels of communication to improve the usability of the data. \n\n11 What works in open data challenges | Open Data Institute 2016\nWhy run an open data challenge?\nOrganisations  that  design  and  run  open  data  challenge  prizes  range  from  governments  to  \ncommercial  organisations,  data  publishers  to  activists.  Each  will  of  course  have  their  own  \nmotivations.  However,  the  first  indication  of  success  for  a  challenge  will  come  from  how \neffectively they distil these motivations into clear, measurable objectives. \nBoth the secondary evidence that was considered and the challenges that were assessed to \ninform this work suggest that challenges are generally organised to achieve a primary objective. \nThese objectives are broadly organised into three main categories – learning, innovation and \nsustainability (Adamczyk, 2012).\n1. Professional development and learning: Challenges that aim to raise awareness \nabout and give momentum to the open data movement and teach participants \nspecific skills. Literature widely focuses on the benefits of challenges to develop \nteamwork,  time  management,  budgeting  and  communication  skills\n \n(Adamczyk, \n2012). These challenges provide an opportunity for participants to apply scientific \nconcepts to real-life situations, such as using data to address specific problems \n(Kimmel, 1992).\n Used  primarily:  by  academic  institutions  or  organisations  dedicated  to  \neducation.\n Example:  Convergence  Innovation  Competition  (CIC)  at  Georgia  Tech  –  an  \nannual competition in which students are provided category-specific resources \nby industry sponsors to employ towards developing a prototype and business \ncase. It includes a rigorous workshop schedule and support system to drive \nlearning agenda (Piller et al, 2004).\n Prize: Contracts of employment and opportunities to commercialise products. \n2. Innovative  outputs:  Challenges  that  prioritise  the  development  of  products/\nservices  and  support  participants  to  expedite  product  development  (Piller  et  \nal,  2004). These challenges offer a cost-effective method to attract numerous \ndispersed  communities  of  committed  innovators,  often  intended  to  kick-start  a  \nnew market (e.g. private space flight) or adoption of a new resource (open data). \nUser-made ideas are often comparable to those of internal experts and provide \na  compelling  platform  to  integrate  internal  and  external  experts  toward  the  \ninnovation cause thereby driving collaboration and open innovation approaches \n(Poetz et al, 2012).\n Used primarily: within the industry.\n\n12 What works in open data challenges | Open Data Institute 2016\n Example:  NASA  Centennial  Challenge  –  designed  to  engage  a  diverse  \ncommunity  including  the  public  and  particularly  citizen-inventors  in  NASA’s  \nresearch   and   development.   The   Centennial   Challenge   drives   forward   \ninnovation,  opportunity  and  communication  by  finding  innovative  solutions \nthrough  competition  and  cooperation,    enabling  challenge  competitors  to  \ndevelop and expand their business models and business base, and providing \na forum for public outreach.\n Prize: Prize purse from US$25,000–5 million.\n3. Sustainability   and   community:   Challenges   that   seek   to   generate   socially,   \neconomically  and  environmentally  responsible  solutions.  In  the  case  of  open  \ndata, this may apply in two ways. Firstly, a socially motivated challenge question \nwill ensure open data challenges deliver socially beneficial products and services \n(Belz et al, 2007); secondly, effective open innovation techniques and fostering \nengagement  between  participants  and  data  owners  will  facilitate  a  sustainable  \nand mature open data infrastructure.\n Used primarily: by governments, charities and not for profit organisations.\n Example: The Open Data Challenge Series run by Nesta and the Open Data \nInstitute. The seven challenges each prioritised a specific theme and social \nneed  which  was  defined  in  collaboration  with  sector  experts.  Challenge \nparticipants  were  assessed  according  to  how  well  their  product  or  service  \nresponded to the social need, their use of open data, the level of innovation \nand the strength of their business model.\n Prize: Prize purse from £45,000–55,000 per challenge. \nAs we will see later, the selection and articulation of objectives will have direct implications for the \ndesign of the challenge prize and should not be overlooked. The effective, collaborative construction \nof  objectives  is  a  process  that  should  be  invested  in  by  all  stakeholders,  ranging  from  domain  \nexperts to funders and data owners. It provides an opportunity to air and agree primary measures \nof success and to establish core principles which will guide challenge design and delivery. \nWhat benefits can you expect?\nOpen  data  challenges  are  particularly  appealing,  both  to  corporations  and  governments,  \nbecause innovative solutions can emerge at a far lower cost than through traditional research and \ndevelopment practices in closed organisational settings (Lampel et al, 2012). Challenges often \ndeliver a number of benefits to the organising group, ranging from increased engagement with \nspecific datasets and a wide spectrum of specialists, to access to a community of advocates \n\n13 What works in open data challenges | Open Data Institute 2016\nand innovators who are invested in a brand or cause. Rapid shifts in innovation demands and \nthe rising costs of maintaining internal resources make open innovation methods increasingly \nattractive (Hossain and Kauranen, 2015).\nEconomic benefits\n Return on investment for data release or investment is clearer, more significant \nand measurable. It is not always easy to demonstrate the benefits of releasing \nopen  data.  Many  organisations  are  unaware  of  the  degree  of  their  open  data’s  \nuse, which makes estimating the return on their investment difficult. A challenge \nprize  can  require  that  a  participant  should  keep  the  organiser  informed  of  their  \nprogress and success, thereby giving some indication of impact.\n Foster  activity  on  a  broad  topic  and  potentially  invest  in  a  new  market. \nChallenges  are  particularly  useful  where  groups  are  unlikely  to  risk  developing  \nideas themselves because there is not a proven market for them, or the high cost \nof developing products or services puts them off.\nEnvironmental benefits\n Limited environmental impact.  Challenge  prizes  are  largely  delivered  remotely  \nwhich reduces the requirement for travel or the impact of a physical event. Online \nplatforms  such  as  YouNoodle\n7\n and Collabfinder\n8\n  provide  functionality  for  team  \nrecruitment, submission and judging.\n Target  and  overcome  specific  environmental  challenges. Challenge  prize  \nquestions  can  be  specifically  designed  to  target  environmental  needs  and \nimprovements. For example, a challenge question could read “How can we use \nopen data to increase the number of people generating their own energy?”\nSocial benefits\n Discover new, innovative solutions to entrenched social (and other more technical) \nproblems which respond to the challenge definition. For example, solutions to \nfood waste, social mobility, public engagement and housing.\n Improve recruitment and community building by identifying talent in communities \nand building a network of knowledge and expertise.\n Encourage collaboration between participants. There is an option to incentivise \ndeeper collaboration and partnerships through the challenge design by requiring \nacademics to submit in partnership with experienced entrepreneurs, for example.\n Improve awareness of existing innovation, specialists and open data resources, \n7     See     https://www.younoodle.com.\n8     See     http://collabfinder.com.\n\n14 What works in open data challenges | Open Data Institute 2016\nstrengthening open data practice and prompting greater use of open data.\n Develop ongoing symbiotic relationships – data providers, publishers and users \nare encouraged to collaborate more effectively. The quality, availability, use and \nbreadth of data improves as a result.\nWhile open data challenges provide an efficient platform for organisers to seek innovative \nsolutions, participants will also often benefit greatly from their involvement. \nPersonal professional development\n Build  professional  networks  related  to  a  topic  of  interest,  meet  like-minded  \nparticipants and become part of an expert community.\n Test and learn new skills in a stimulating, supportive environment.\n Access wide-ranging resources including data, user insight reports, research and \npublications.\nProduct development\n Get access to expert facilitation, peer support and industry sponsorship.\n Agile and intense process to quickly research and develop in secure environment.\n Bring visibility to themselves, their work and their projects. \n Enter markets that are otherwise difficult to penetrate.\nIn addition to the broad benefits set out above, the challenge process can be designed to \nsupport specific outcomes for the participants in line with the overarching objectives. For \nexample, if learning is a priority, organisers may wish to provide a professional development \npackage  alongside  the  challenge  milestones.  This  package  may  include  training,  in  person  \nor online, or mentoring on topics such as user research, open data, project management or \nbusiness models. This will provide an extra bundle of benefits to participants and will have the \nadditional benefit of improving the quality of submissions. \nRisks and issues to consider \nFor colleagues working in capacity-constrained contexts, our research identified four specific \nchallenges  that  are  vital  to  consider  during  the  programme  design  and  execution  of  the  \nchallenge. First and foremost, data science capacity and capability – the success of open \ndata challenge participants depends on their ability to extract, interpret, analyse and apply data. \nIf an existing community of potential participants with the necessary skills and capacity cannot \nbe found and engaged, investment will need to be made in training and expert mentorship for \nparticipants who lack these skills. \n\n15 What works in open data challenges | Open Data Institute 2016\nSecond, adequate data and legal infrastructure will need to be in place. Not only should \nrelevant,  quality  data  be  available  for  participants  at  the  launch  of  the  challenge,  but  also  \ninvestment should be made to ensure the infrastructure supports participants to access and \ndigitise information and locate and manage datasets. \nOrganisational  fragmentation  and  lack  of  collaboration  were  also  reported  as  issues.  \nOrganisers must identify clear roles and responsibilities for all stakeholders and make sufficient \ninvestment into stakeholder relationships (e.g. work together to set common objectives and \ndesign principles). \nFinally, though it may not seem an obvious priority, it is essential that organisers commit in the \nlong term to their challenge process and prioritise open data. This requires that organisers \ninvest  in  the  full  assessment  of  the  quality  of  submissions  (including  user  accessibility  and  \nimpact of open data use), not just in the number of submissions themselves. Organisers are \nrecommended to monitor participants progress beyond the final winner’s award and evaluate \nthe long-term outcomes and impacts of the challenge process. \n\n16 What works in open data challenges | Open Data Institute 2016\nFour foundations for delivering effective  \nopen data challenges\nThere are four foundations for the design and delivery of an open data challenge:\n1. The principles of leading a challenge \n2. Designing your programme and activities\n3. Providing resources and inputs \n4. Creating incentives for participants\n1. The principles of leading a challenge\nThe  objectives  agreed  between  key  organising  partners  will  greatly  determine  the  nature  of  \nthe  challenge  outputs.  In  order  to  further  increase  the  likelihood  of  success,  organisers  are  \nencouraged to consider to what degree they will adopt the following guiding principles. These \nprinciples are derived from our research and experience in open data challenge delivery.\nPrinciple 1: Invest in relationships \nWhether  between  partner  organisations,  individuals  within  a  team  or  competing  teams,  \nrelationships are a core foundation for the success and sustainability of an open data challenge. \nAn early investment in building open, collaborative relationships with all stakeholders will pay \ndividends.  In  the  short  term,  organisers  can  expect  an  increased  likelihood  of  collaboration  \nor pro bono support, deeper understanding of the challenge question and theme, and more \ncollaboration between participants. \nWhen the foundations are set right, this investment can lead to more significant relationships \nand involvement between parties in the longer term, ranging from permanent employment and \nfreelance support to collaborative product design and delivery.\nCapacity-constrained  contexts.  Investing  in  building  relationships  within  the  open  data  \necosystem is particularly important where the level of open data maturity is nascent, or where \nthe financial rewards for involvement in this specific event are more limited. This enables future \npartnerships to develop over the longer term.\n\n17 What works in open data challenges | Open Data Institute 2016\nPrinciple 2: Work as openly and collaboratively as you  \nexpect others to \nAn open data challenge is one example of an open innovation technique, as such its success \nis dependent on the degree to which it is designed, managed, judged and evaluated openly. \nAn open data challenge invites participants to submit their innovations in the open – the quality \nof these submissions can be improved by clarity of judging criteria and shared insight into the \nuser needs that motivate the challenge question. \nCapacity-constrained  contexts. Aligning   organisations   with   similar   objectives   and   \ncomplimentary  skillsets  may  be  more  challenging  where  there  is  competition  for  limited  \nresources such as donor funding. Working openly can be perceived as a risk to organisational \nintellectual property, however, in this case, the benefits far outweigh the risks. \nPrinciple 3: Respect participants’ intellectual property and \nlevel of investment\nIt  is  imperative  that  participants  have  clarity  regarding  their  intellectual  property  throughout  \nthe challenge process. All challenges will require participants to make a level of investment in \ntheir submissions prior to entry, and teams can incur reputational and other risks as a result. \nTo support their involvement and comfort with the process, clarity should be provided through \nwritten terms and conditions with a clear judging timeline and matrix. \nThe openness of the challenge process requires that participants both compete and collaborate \nwith one another. Creating conditions that support both behaviours, and being clear on the \nexpectations that you hold for participants, will enable them to benefit from the process to the \ngreatest degree possible.\nCapacity-constrained  contexts. Encouraging  collaboration  is  highly  beneficial \nfor the experience and outcomes of the process but this approach may conflict \nwith  cultural  norms.  Finding  a  suitable  balance  that  both  optimises  collaboration  \nwhile  encouraging  competition  should  be  considered  on  a  case-by-case  basis  \nand  reflected  in  the  challenge  design.  For  example,  meetups  will  encourage \ncollaboration while the judging process will drive competition.\n\n18 What works in open data challenges | Open Data Institute 2016\nPrinciple 4: Minimise barriers to participation \nChallenges,  particularly  those  with  a  lower  prize  range,  are  frequently  the  pursuit  of  small  \nbusinesses, entrepreneurs and individuals. These participants are likely to be time-constrained \nand working on tight margins or in their own time so it is vital that they feel their time is suitably \nrewarded through professional development, a comfortable environment and a suitable prize. \nA challenge that will have greatest appeal to a wide and well-suited audience is one which has \nconsidered and attempted to overcome barriers to participation. Organisers may wish to do \nthis through provision of:\n Challenge  question  and  definition.  A  narrative  to  explain  how  and  why  the  \nchallenge  question  has  been  selected  and  what  impact  is  anticipated  from  \nsubmissions.\n User research and insights help participants to understand the challenge question \nmore fully and target their submissions to specific audiences. \n User   centred   design   and   universal   design   principles   or   other   suitable   \nrequirements to guide submissions and put user needs at the centre of innovation \nprocess.\n Data.  A  central  curated  repository  for  relevant  data  to  include  metadata  and  \nguidance thereby supporting efficient idea creation and innovation.\nTips for implementation: The more guidance and research that can be centralised, \nthe  less  burden  on  participants.  Organisers  should  consider  how  to  work  \ncollaboratively with experts in their field to provide these resources.\n2. Designing your programme and activities\nAs  Nesta’s  Centre  for  Challenge  Prizes  has  established,  challenge  prizes  can  be  designed  \nto  achieve  a  number  of  outcomes  –  whether  to  solve  big  problems  and  achieve  major  \nbreakthroughs,  to  make  progress  towards  ambitious  goals  or  to  create  new  markets.  \n9\nIrrespective of the overarching goal, there are some elements of overarching challenge design \nthat  are  consistent  across  best-in-class  open  data  challenge  prizes.  A  standard  challenge  \nprocess can be simplified as follows:\n9     See     http://www.nesta.org.uk/sites/default/files/challenge-prizes-design-practice-guide.pdf.\n\n19 What works in open data challenges | Open Data Institute 2016\nKey:\nBlack text: discovery and challenge definition\nOrange text: significant communications milestones\nPurple text: participant focused activities\nGreen text: assessment and judging\nDefining the challenge: the discovery phase\nThe discovery phase for any challenge will set up participants, key stakeholders and champions \nto  engage  most  effectively  with  the  challenge  process.  Organisers  may  wish  to  consider \nadditional activities such as:\n Roundtable  discussions  and  interviews.  Bring  together  specialists  to  better  \nunderstand  underlying  issues  that  could  present  potential  challenge  questions/\nthemes and specific areas of focus.\n Comprehensive data review. Review available open data and curate a data guide \nto help data novices understand what is available, how frequently it is updated, \nthe quality and completeness of the data, and how the data could relate to the \nchallenge question.\n User research. Undertake or commission user research activities to expose user \nneeds. Both secondary and primary research can be highly valuable and encourage \ndata specialists who may lack thematic or sector expertise to participate.\nSetting communications milestones\nThe impact and degree of engagement with a challenge can be significantly increased through \neffective communication. While the main milestones that should be prioritised are the launch \nof the challenge and the announcement of the winner, there are specific activities that can be \nemployed to increase their hit-rate:\n Share  openly.  Participants  and  observers  will  benefit  greatly  from  access  to \ninformal, anecdotal information as the challenge progresses. Collaborative note-\ntaking tools such as Hackpad, blog posts and social media activity are all useful \nways to share progress, collect input and engage potential participants. \n Commit in the long term. The most sellable stories come long after the culmination \n\n20 What works in open data challenges | Open Data Institute 2016\nof the challenge, once participants have launched, often pivoted, and had some \nsuccesses. By making a commitment to the winner in the medium to long term, \nor running multiple challenge prizes consecutively, an organiser will benefit from \na multiplier effect. \nSetting activities for your participants\nWhile the preparation, communication and assessment of the challenge are all vital logistical \nelements, the participant activities form the main focus of the process. In its simplest form, a \nchallenge will require participants to submit an idea or concept, develop that concept and then \nlaunch it into the market. At each stage, the number of participants will decline and the focus \nof support will increase. Participant activities can be supported through:\n Online submission platform. Organisers may wish to use a submission platform \nsuch as YouNoodle or Collabfinder to manage initial participant submissions. The \nselection of a platform is a difficult process and all options should be considered. \nFor  example  some  platforms  will  support  the  judging  process  as  well  as  \nsubmissions but will not support participants to find teammates. An initial online \nsubmission provides the opportunity to assess and shortlist suitable participants \nto engage in the next phase.\n Meetups.  Physical  interaction  between  participants  can  be  hugely  beneficial, \nparticularly in the early stages when idea generation is the focus, and later when \nteams will benefit from being exposed to specific skills and techniques through \ntraining and support. \n Creation Weekend. Many open data challenge prizes will require all participants \nto attend and pitch at a weekend long event. This is a dedicated time period for \ndevelopment and refinement of the product or service before live pitching in front \nof  a  panel  of  judges.  The  Creation  Weekend  structure  can  itself  be  adjusted  to  \nprioritise primary objectives and outcomes. \n\n21 What works in open data challenges | Open Data Institute 2016\nAssessment and judging\nTransparency in assessment will improve both the volume and quality of submissions. Where \na participant can easily see what they are being judged on, by whom and how, they can more \neasily improve their scores and achieve even greater success.\n Share judging information early. Communicate the judge’s names, judging criteria \nand matrix as early as possible in the process to help participants understand what \nis required of them at each stage and how their submissions will be assessed. \n Communicate scores and feedback openly. To broaden the benefits and impact \nof  a  challenge  process,  organisers  should  share  feedback  with  all  participants  \nat  all  stages  regardless  of  the  degree  of  success  they  achieve.  Supporting  all  \nparticipants to achieve success will ensure the greatest possible impact for the \nchallenge process.\n3. Providing resources and inputs \nThe submissions made in response to a challenge question are primarily a reflection of the \nresources,  experiences  and  knowledge  of  the  participating  team.  Teams  are  often  drawn  \nfrom a range of open data expertise levels, a variety of different sectors and across different \nlevels  of  seniority,  depending  on  the  size  and  draw  of  the  incentive.  To  improve  the  quality  \nof submissions, a number of challenges have found great benefit from crowdsourcing and \nopenly sharing resources to expedite the idea and product development. \nWith  open  data  being  a  relatively  new  and  nuanced  discipline,  expertise  and  knowledge  in  \nthe  entrepreneurial  sphere  is  limited.  Challenge  organisers  have  benefited  from  asking  an \nindependent  data  scientist  to  contribute  to  the  provision  of  two  types  of  open  data-related  \nmaterial. This includes an introduction to open data, including information about the concept, \nrequirements and availability, and also an outline of the main data providers and key datasets \nthat relate to the sector or challenge question. Those who have a basic understanding of open \ndata will also benefit from a second, more thorough, interactive audit and quality assessment. \nThis  document  will  rate  the  openness  of  the  data  and  provide  clear  documentation  to  help  \npotential participants identify the datasets that will best support their idea at a glance, and help \ndata publishers to see where their data sits amongst their peers. \nWith participating teams often resource-constrained and limited to specific areas of expertise, \nuser research and user centred design principles can be overlooked. One simple way to set \nthis expectation is to suggest teams refer in some way to user needs and user feedback in \ntheir pitch. A solution which will offer benefits far beyond the parameters of the challenge is \n\n22 What works in open data challenges | Open Data Institute 2016\nthe preparation of a user insight guide by a researcher. Organisers may wish to commission \nspecialists to create a user insight report to include user profiles of the types of users that \nteams should develop their products for, an exploration of user needs, analysis of secondary \nresearch and interviews with sector specialists.\nThe Creation Weekend and prototype development phases offer an opportunity to provide \nspecialist  support  to  the  teams.  Experts  can  work  with  the  teams  directly  to  challenge,  \ncoach and advise them regarding specific areas of focus stipulated in the judging criteria, such \nas use of open data, brand and concept.     \n4. Creating incentives for participants\nThe nature, volume and enthusiasm of participants is commonly influenced by their commitment \nto the cause and equally by the size and type of the incentive. This is a very important aspect \nof challenge design and the literature is exhaustive on the subject, particularly in relation to the \namount or type of reward (Piller et al, 2010), whether to offer single or multiple prizes (Glazer and \nHassin, 1988), whether to offer fixed or proportional prizes (Cason et al, 2010), and monetary \nprizes versus proprietary rights (Che et al, 2015). All 25 open data challenges involved some \nform of monetary reward. Observably, the size of their cash prizes differed significantly, ranging \nfrom $500 to $1,000,000. Open data challenges with simple context structures, single-stage, \nsingle-award, often employed one-off, larger-sum prizes, while those with complex structures, \nmulti-stage, multi-module, or both, tended to link each stage or module with a smaller-sum \nprize. \nWhile  a  professional  development  programme  of  learning  and/or  recruitment  opportunity  \nmay be more than enough incentive for a university student, it will not encourage seasoned \nentrepreneurs to participate in the challenge. It is therefore essential that the organisers explore \nand test suitable incentives with their intended participant community before committing. \nAccording  to  one  interviewee,  the  prevalence  of  monetary  award  could  be  attributed  to  \nconvention and convenience, because “setting up a monetary prize is the most straightforward \nand  proven  thing  to  do  in  terms  of  reward”.  While  most  interviewees  were  positive  about  \ncash  prizes,  one  noted  their  limitations  in  a  longer-term  challenge:  “We call it a prize as if \nit’s a reward, but you must recognise that in order to win that prize, they probably put far \nmore than £50,000 worth of investment into the product or service in terms of their time, the \ntechnological developments, the user research sessions they’ve run, and so on. Effectively, we \nare not actually even covering their costs for the time they’ve spent.” \n\n23 What works in open data challenges | Open Data Institute 2016\nBesides the size and variety of monetary rewards, many challenges focused on the “honour” \naspect  of  winning  their  open  data  challenges.  For  instance,  the  D4D  Senegal  Challenge  \nhighlighted  that  winners  will  win  the  opportunity  to  present  at  an  international  conference  \nNetMob  2015,  held  at  the  Massachusetts  Institute  of  Technology  in  Boston.  Similarly,  the  \nJakarta Provincial Government announced that winners will meet the Vice Governor of Jakarta, \nwho will also take part in the evaluation process. The Data Innovation Challenge organised by \nthe United States Department of Transportation publicised that the awardees will be honored \nby the Transportation Secretary in a “special session where awardees will present their concept \nfor senior officials from across the US Department of Transportation, Challenge judges and \nother members of the DoT staff”.\n10\nIncentive TypeAudience attracted\nImplications for \nchallenge design\nCash\n£1k–250k\n£250–1m\n£1m+\nStudents, small business \nentrepreneurs\nExperienced business owners\nResearch institutions, big \nbusiness\nA cash prize is best offered \nwhen in combination with seed \nfunding for multiple shortlisted \nfinalists.\nSmaller seed funding should \nbe offered after the Creation \nWeekend. \nGuaranteed contractExisting experienced businesses \nworking in the sector\nThe degree of competition \nincreases and collaboration and \nopenness is often diminished. \nIntellectual property is a major \nconcern particularly where the \ncontract holder is represented \non the judging panel.\nOpportunity to pitch \nfor new clients\nFree exhibition ticket \nfor sector conference\nPersonal introduction \nto potential clients\nSmall/medium/new businesses \nhoping to penetrate new \nmarkets. Entrepreneurs.\nFocus is less on the product or \nservice developed and more on \nthe team skills and experience. \nMuch less traditional challenge \nprize approach.\n10   For more information on the Data Innovation Challenge, see: https://www.transportation.gov/mission/challenges/\ndatachallenge-rules.\n\n24 What works in open data challenges | Open Data Institute 2016\nPress coverage\nBrand association \nwith organisers or \nsponsors\nSmall/medium/new businesses \nhoping to penetrate new \nmarkets. Entrepreneurs.\nSignificant pressure on the \nsuccess of communications \ninitiatives which cannot be \nguaranteed. \nMore effective if led by \ncommunications specialists.\nEngagement with \nusers/user feedback\nSmall/medium/new businesses \nhoping to penetrate new \nmarkets. Entrepreneurs.\nShould be built into the \nchallenge process as it is not a \nreward for delivery so much as a \nbenefit of the process.\nAccess to startup \nincubation \nprogramme\nEarly stage startups with very \nlimited experience\nIncubation programme replaces \nthe prototype development \nphase and so finalists are \nselected early and the whole \nchallenge process is shorter.\n\n25 What works in open data challenges | Open Data Institute 2016\nConclusion and recommendations\nThe  challenge  prize  or  inducement  prize  concept  has  achieved  great  gains  across  a  wide  \nvariety of sectors since its inception in the early 1700s – whether in private spaceflight or \ndetermining  a  ship’s  longitude.\n11\n  So  far,  in  the  few  years  since  its  application  to  the  open  \ndata  sector  in  the  late  2000s  we  have  already  seen  the  growth  of  a  new  market  of  product  \nand service-led businesses that use open data to solve specific social, environmental and \neconomic challenges. \nWhile its definition is still subject to misconceptions, the open data challenge prize approach \nis gaining traction across regions, demographics and communities internationally. Designed \nto  incentivise,  engage  and  support  the  growth  of  a  burgeoning  market  of  products  and  \nservices that use open data, open data challenge prizes are increasingly considered the best \nmechanism with which to:\n demonstrate potential applications for open data,often for social good\n increase the use of open data \n improve the quality and availability of open data \nHowever, in order for an open data challenge prize to deliver positive impact on the open \ndata ecosystem, startup market and open data infrastructure, we must invest fully and deliver \nthem  to  the  best  of  our  ability.  A  challenge  prize  should  only  be  embarked  upon  if  all  core  \nstakeholders  share  the  ambition  to  achieve  long-term  sustainable  products  and  services  \nwhich use open data, and to do so by incentivising participants to solve a specific, ambitious \nchallenge question. \nFor  the  best  chance  at  success,  the  following  recommendations  are  set  out  for  open  data  \nchallenge prize organisers.\n1. Set clear objectives that reflect the primary interests of all core stakeholders. \nOrganisers should only conduct an open data challenge where it is appropriate \nand will contribute to their overarching goals. While open data challenges often \nhelp demonstrate the power of data that has already been released, the timelines \nthey work to are often  insufficient to drive the release of new open data. Effective, \ncollaborative, open design and marketing of challenge objectives will ensure that \nthey reflect goals that all key stakeholders subscribe to.\n11   See   https://en.wikipedia.org/wiki/Inducement_prize_contest.\n\n26 What works in open data challenges | Open Data Institute 2016\n2. Design a bespoke challenge structure that reflects these primary objectives \nthroughout. As this report illustrates, subtle and significant changes to challenge \ndesign will determine whether or not and to what degree its core objectives are \nachieved. While keeping resource, infrastructure and organisational constraints in \nmind, organisers should take time, utilise expertise and employ creative license to \ndesign a challenge that best reflects what they are trying to achieve in their unique \ncontext.  Every  challenge  should  start  with  a  call  to  action  focused  on  a  clear  \nchallenge question and culminate in the award of one prize to an overall winner \nwho is committed to sustaining their product or service. \n3. Commit to open design principles and be prepared to iterate or adjust plans as \nyou go. To deliver a successful challenge, organisers will need to:\n operate with uncertainty and unknowns as a core element of design\n invest in relationship building (with partners, participants and volunteers)\n work as collaboratively and openly as they would expect others to \n engage stakeholders in design and delivery\n respect participants’ intellectual property and level of investment\n minimise barriers to participation and have clear incentives\n4. Sustain focus on open data from launch to completion. Support participants \nto understand, access and use open data. A challenge cannot succeed unless \nsufficient, high-quality and relevant data are available. Challenges are much more \nlikely  to  succeed  when  data  infrastructure,  access  and  resources  are  carefully  \nprepared  and  maintained.  Organisers  should  recognise  that  many  of  their  \nparticipants  will  not  be  open  data  experts  and  will  need  support  in  accessing  \nand using it. Understanding what data is available and how it can be used can \nbe a significant barrier in creating ideas. Further, if every opportunity is taken to \nsupport data’s improvement and that of the surrounding ecosystem, a challenge \nprize can add significant value for the open data community, including publishers \nand users. This must be actively built into challenge design.\n5. Take time to plan, deliver and review each stage of the challenge process. \nChallenges   often   look   straightforward   when   observed   from   an   outsider’s   \nperspective. However, a challenge is only simple when sufficient thought and \nexpertise is invested in its design and execution. Assembling a team with suitable \nexpertise is no easy task, but experts in business modelling, facilitation, judging \nand impact assessment will be essential to the success of the challenge.\n\n27 What works in open data challenges | Open Data Institute 2016\n6. Do not stop at one challenge. To optimise their return on investment, challenge \nprize  organisers  should  consider  running  multiple  challenges  over  an  extended  \nperiod.  This  additional  upfront  commitment  will  create  an  opportunity  to  build  \nmomentum  with  participants  and  supporters,  and  ensure  lessons  are  recorded  \nand iterated quickly. The investment needed to launch and deliver a successful \nchallenge is significant, but once initial design, launch and awareness building \nis complete, much of the hard work is done and the reward will be greater from \ndelivering  multiple  challenges.  A  community  of  innovators,  policy  experts  and  \nentrepreneurs is easier to sustain than to create for a single open data challenge.\n7. Undertake an impact and process evaluation and share it.  As  a  community  \ncommitted  to  working  collaboratively  and  openly,  we  owe  it  to  one  another  to  \nshare the lessons and experiences that lead to both the successes and failures in \nour work. Too few process and impact evaluations exist in relation to open data \nchallenges. Together, we have the opportunity to change this.\nWhat do you think?\nIf you have insights into open data or challenge prizes that you would like to share, we want to \nhear from you. Get in touch with amanda.smith@theodi.org or tweet us at @ODIHQ. \n\n28 What works in open data challenges | Open Data Institute 2016\nAbout this report\nThe  Open  Data  Institute  (ODI)  connects,  equips  and  inspires  people  around  the  world  to  \ninnovate with data. It is independent, nonprofit and nonpartisan, founded in 2012 by Sir Tim \nBerners-Lee and Sir Nigel Shadbolt. From its headquarters in London and via its global\nnetwork  of  startups,  members  and  nodes,  the  ODI  offers  training,  research  and  strategic \nadvice for organisations looking to explore the possibilities of open data.\nThis report was supported by the Open Data for Development (OD4D) programme. OD4D is a \nglobal network of leading organisations that are creating locally-driven and sustainable open \ndata ecosystems in in Latin America, the Caribbean, Africa, and Asia and East Europe. The \nOD4D network builds knowledge and provides support  to governments and policy-makers in \nkey issues such as policies, standards, innovation and skills development.\nOD4D  is  managed  by  Canada’s  International  Development  Research  Centre  (IDRC),  and  it  \nis  a  donor  partnership  with  the  World  Bank,  United  Kingdom’s  Department  for  International  \nDevelopment (DFID) and Global Affairs Canada (GAC). OD4D focuses on building up the supply \nof quality open data, and also on improving the use of that data by leaders in government, civil \nsociety, the media, and business so that it furthers public interest and improves people’s lives.\nA partnership funded by\n\n29 What works in open data challenges | Open Data Institute 2016\nAppendix \nGlossary \nChallenge prize / Inducement prize\nChallenge prizes, also called inducement prizes, offer a reward to whoever can first, or most \neffectively, meet a defined challenge. They act as an incentive for meeting a specific challenge, \nrather than an award for past achievements (prizes that do this are referred to as recognition \nprizes). \nChallenge prizes landscape review (2012). Available at:  \nhttps://www.nesta.org.uk/sites/default/files/challenge_prizes_landscape_review.pdf\nOpen data \nOpen data is data that anyone can access, use and share.\nhttp://theodi.org/what-is-open-data\nUser centred design \nUser-centered design (UCD) or user-driven development (UDD) is a framework of processes \n(not restricted to interfaces or technologies) in which the needs, wants and limitations of end \nusers of a product, service or process are given extensive attention at each stage of the design \nprocess.\nhttps://en.wikipedia.org/wiki/User-centered_design\nUniversal design principles\nThe 7 Principles of Universal Design were developed in 1997 by a working group of architects, \nproduct designers, engineers and environmental design researchers, led by the late Ronald \nMace  in  the  North  Carolina  State  University.  The  purpose  of  the  Principles  is  to  guide  the  \ndesign of environments, products and communications. According to the Center for Universal \nDesign in NCSU, the Principles “may be applied to evaluate existing designs, guide the design \nprocess and educate both designers and consumers about the characteristics of more usable \nproducts and environments”.\n Principle 1: Equitable Use\n Principle 2: Flexibility in Use\n Principle 3: Simple and Intuitive Use\n Principle 4: Perceptible Information\n Principle 5: Tolerance for Error\n Principle 6: Low Physical Effort\n Principle 7: Size and Space for Approach and Use\nhttp://universaldesign.ie/What-is-Universal-Design/The-7-Principles\n\n30 What works in open data challenges | Open Data Institute 2016\nExamples of open data challenges\nOpen Data Challenge Series\n12\n, Nesta and ODI, UK (2013–2015)\nFunded by: Department for Business, Innovation and Skills.\nFormat: Two phase open data challenge. Challenge definition, data sharing, submission, selection \nof semi finalists, creation weekend, selection of finalists, incubation, selection of winner\nTopic: Range of seven social issues ranging from education to heritage and culture.\nIncentive: £5,000 for semi finalists + mentoring, £40-50,000 for final winner\nGoal: To  develop  sustainable,  innovative  products  and  services  using  open  data  for  social  \ngood. To engage entrepreneurs and innovators in open data.\nLearning: It is very valuable of investing in evaluation of impact and process, and to commit \nto multiple challenges in a series to allow for the process to be iterated immediately, and for \nmarketing reach to accumulate over time.\nLongitude Prize\n13\n, Nesta, Global (2014–2019)\nFunded by: InnovateUK.\nFormat: Three phase challenge. Challenge question researched and selected from six options \nby public vote. Registration, application, judging (Prize Advisory Committee), testing, judging \n(Longitude  Committee),  winner  declared.  If  necessary,  this  cycle  will  be  completed  multiple  \ntimes until a winner is identified and verified.\nDiscovery awards available to provide seed funding to develop an idea.\nTopic: How can we prevent the rise of resistance to antibiotics? (On average antibiotics add \n20 years to each person’s life. The development of antibiotics has been vital to our survival, yet \nthe rise of antimicrobial resistance is threatening to make them ineffective in the future.)\nIncentive: £10 Million.\nGoal: To engage a diverse community and solve one of the greatest challenges of our time.\n12   See   http://opendatachallenges.org.\n13   See   https://longitudeprize.org.\n\n31 What works in open data challenges | Open Data Institute 2016\nGODAN Open Data Challenge, Global (2016–2017)\nFunded by: Global Open Data for Agriculture and Nutrition (GODAN).\nSupporting Partners: Thought for Food (TFF), Presidents United for Hunger (PUSH)\nFormat: A  virtual  challenge  process  in  which  participants  were  required  to  submit  a  pitch  \npresentation  for  their  product/service  online  (YouNoodle  platform).  Nearly  40  entries  were  \nmade across the two challenge themes and three finalists per track were selected by volunteer \njudges.\nTopic: Two tracks were identified for this challenge: the policy track and the maker’s track. \nThe  challenges  both  centred  around  availability  and  use  of  data  and  focused  on  GODAN’s  \nambition to achieve world food security.\nIncentive:  Three  seed-funding  prizes  per  theme  for  finalists:  $3,000,  $2,000,  $1,000  plus \naccess, transport and accommodation for the GODAN Summit in New York, and access to \na three month mentoring program. The final winner will receive $5,000 and an opportunity to \npitch their product at the TFF and PUSH Summits in 2017.\nGoal:  To  engage  a  younger  generation  in  the  work  of  GODAN  and  to  identify  and  support  \ninnovation in the sector.\nLearning: Focus  participants  on  one  track  and  prioritise  innovative  products  and  services  \nrather than changes to policy as these are more accessible and can be addressed practically.\nEGAP Challenge\n14\n,  Ukraine (2015–2019)\nFunded by: IBM, Cisco Systems, De Novo, and Intel.\nSupporting  Partners: iHub Vinnytsia, Space Hub Dnipropetrovsk, Impact Hub Odesa and \nLutsk Local Development Foundation.\nFormat: A five stage process (research, stimulation, creative weekends, incubation, selection \nof  winners)  which  will  run  multiple  times  over  the  duration  of  the  challenge.  Each  cycle  will  \nfocus on a specific theme or topic. \nTopic: The challenge targeted submissions that were helping to improve interaction between \nthe government and citizens ranging from “resolving social problems” to “making the activity \nof government agencies more transparent and open”.\nIncentive: UAH 4.5 million split between up to 20 projects.\nGoal:  Ultimately,  the  challenge  aims  to  implement  new  electronic  democracy  tools  to  help  \ncitizens receive new high quality services, interact with the government effectively and have \na direct impact on it, as well as help the government reach a new level of transparency and \nefficiency.\nLearning: A challenge is limited by the availability of open data. For their next challenge the \nteam will focus on topics where there is sufficient, quality open data available.\n14   See   http://egap.in.ua/en/egap-challenge-framework.\n\n32 What works in open data challenges | Open Data Institute 2016\nSouth Africa Open Data Challenge\n15\n, South Africa (2016–2017)\nFunded by: International Development Research Centre\nSupporting Partners: Open Government Partnership South Africa (main organiser), The ODI, \nOpenData for development network, OpeniX, Geekulcha, {code}bridge, Code for South Africa \nand Open data durban.\nFormat: Open, online call for participants to submit their concept. Shortlisted participants will \nbe invited to a local Creation Weekend.\nTopic: Responsive Cities: help residents work better with local government.\nIncentive: First place: R10,000, Second place: R4,000, Third place: R1,000.\nCity winners and finalists will also be awarded top-up awards by local partners depending \non solution potential and available budgets. For example Gauteng-based participants could \nreceive up to R300,000 in seed funding (provided by The Innovation Hub to support piloting of \nprojects selected for implementation by a city partner).\nGoal: To solve the respective challenges in the cities, while driving forward demand and use of \nopen data in order to encourage new data publication.\nLearning: Maintaining consistency over multiple locations while also maximising value from \nthe local expertise, data and resources.\n15   See   http://challenge.responsivecities.org.za.\n\n33 What works in open data challenges | Open Data Institute 2016\nBibliography\nAdamczyk, S. (2012). Managing innovation contests: challenges of attraction and facilitation. \nAvailable  at:  https://opus4.kobv.de/opus4-fau/frontdoor/deliver/index/docId/2270/file/Sabri-\nna_Adamczyk_Dissertation.pdf [Accessed: 2016-10-24].\nAdamczyk,  S.,  Bullinger,  A.  C.  and  Möslein,  K.  M.  (2012).  Innovation  contests:  a  review,  \nclassification and outlook. Creativity and Innovation Management,  21(4),  pp.  335–360.  doi:  \n10.1111/caim.12003.\nBBC  (2008)  Government  launches  data  mash-up.  Available  at:  http://news.bbc.co.uk/1/\nhitechnology/7484131.stm [Accessed 2016-10-20]. \nBelz, F. M., Silvertant, S. and Pobisch, J. (2007). Chapter 10 Consumer Integration in Sustaina-\nble Product Innovation Processes. Available at:  http://score-network.org/files/9594_Proceed-\nings_worshop.07.pdf#page=137 [Accessed: 2016-10-24].\nBrabham, D. C. (2009). Crowdsourcing the public participation process for planning projects. \nPlanning Theory, 8(3), pp. 242–262. doi: 10.1177/1473095209104824.\nCason,  T.  N.,  Masters,  W.  A.  and  Sheremeta,  R.  M.  (2010).  Entry  into  winner-take-all  and  \nproportional-prize contests: an experimental study. Journal of Public Economics, 94(s 9–10), \npp. 604–611. doi: 10.1016/j.jpubeco.2010.05.006.\nChe, Y.-K., Iossa, E. and Patrick, R. (2015). Prizes versus contracts as incentives for innovation: \nSSRN. doi: 10.2139/ssrn.2677626.\nGlazer, A and Hassin, R. (1988). Optimal contests. Economic Inquiry, 26(1), pp. 133–143. doi: \n10.1111/j.1465-7295.1988.tb01674.x.\nHossain, M. and Kauranen, I. (2015). Competition-based innovation: the case of the X prize foun-\ndation:  SSRN.  Available  at:  https://papers.ssrn.com/sol3/Papers.cfm?abstract_id=2549616 \n[Accessed: 2016-10-24].\n\n34 What works in open data challenges | Open Data Institute 2016\nEIT Digital (2016). Ideathon: how to design or improve a business idea? Available at: https://\nwww.eitdigital.eu/news-events/news/article/ideathon-how-to-design-or-improve-a-business-\nidea [Accessed: 2016-10-24].\nKimmel, H. (1992). Beyond bridge building: creative design for secondary school students. \nProceedings of the 22nd ASEE/IEEE Frontiers in Education Conference.\nLampel, J., Jha, P. P. and Bhalla, A. (2012). Test-driving the future: how design competitions \nare changing innovation. The Academy of Management Perspectives, 26(2), pp. 71–85. doi: \n10.5465/amp.2010.0068.\nNesta (2014). A practice guide: challenge prizes. Available at: http://www.nesta.org.uk/sites/\ndefault/files/challenge-prizes-design-practice-guide.pdf [Accessed: 2016-10-24].\nNesta (2012) Challenge prizes landscape review. Available at: https://www.nesta.org.uk/sites/\ndefault/files/challenge_prizes_landscape_review.pdf [Accessed: 2016-10-24].\nNesta  and  the  ODI  (2015a).  Open  Data  Challenge  Series  final  report.  Available  at:  http://\nopendatachallenges.org/wp-content/uploads/2015/10/Nesta-Final-report-26.10.15.pdf \n[Accessed: 2016-10-24].\nNesta  and  the  ODI  (2015b).  Open  Data  Challenge  Series  Handbook.  Available  at:  http://\nopendatachallenges.org/wp-content/uploads/2015/10/Nesta-ODCS-Handbook-Revised-\nEdition-WEB.pdf [Accessed: 2016-10-24].\nPiller, F., Schaller, C. and Walcher, D. (2004). Customers as co-designers: a framework for open \ninnovation. Paper 116. Congress of the International Federation of Scholarly Associations of \nManagement (IFSAM) (Vol. 57).\nPiller, F. T., Ihl, C. and Vossen, A. (2010). A typology of customer co-creation in the innovation \nprocess: SSRN. doi: 10.2139/ssrn.1732127.\nPoetz, M. K. and Schreier, M. (2012). The value of crowdsourcing: can users really compete with \nprofessionals in generating new product ideas? Journal of Product Innovation Management, \n29(2), pp. 245–256. doi: 10.1111/j.1540-5885.2011.00893.x.\nWikipedia    (2016a).    Hackathon.    Available    at:    https://en.wikipedia.org/wiki/Hackathon \n[Accessed: 2016-10-20].\n\n35 What works in open data challenges | Open Data Institute 2016\nWikipedia  (2016b).  Inducement  prize  contest.  Available  at:  https://en.wikipedia.org/wiki/\nInducement_prize_contest [Accessed: 2016-10-24].\n\n","version":"1.10.100"}