{"numpages":26,"numrender":26,"info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"Skia/PDF m81"},"metadata":null,"text":"\n\n \n\n \n \nContents \n \nAbout3 \nExecutive summary4 \nRecommendations6 \nIntroduction8 \nWhat we did10 \nBackground11 \nWhat are protected characteristics?11 \nWhy research protected characteristics?11 \nWhy focus on digital services?12 \nLegislation and guidance13 \nWhat we found15 \nInclusive services need to be accessible15 \nEquality requires more than accessible design16 \nWe lack data on the use of digital services17 \nData protection is no barrier to statutory duty17 \nData about vulnerable people needs to be handled ethically18 \nThere are examples of using and publishing monitoring data19 \nInclusive services need more than numbers20 \nOur recommendations21 \nCollect data to understand service users21 \nCollaborate to develop standards, guidance and training22 \nConduct further research23 \nConclusion25 \n \n \n \n \n \n \n  \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  1 \n\n \n \n \n \n \n \n \nAbout \nThis ‘Monitoring equality in digital public services’ report has been researched and \nproduced by the Open Data Institute, with funding from The Legal Education \nFoundation, and published on 31 January 2020. Its lead author was Edafe ​Onerhime, \nwith additional support from Jeni Tennison, Renate Samson, Ben Snaith, Fionntan \nO’Donnell and Walter Brown​. If you want to share feedback by email, or would like to \nget in touch, contact the project lead, Renate Samson, at ​renate.samson@theodi.org​. \n \nTo share feedback in the comments, highlight the relevant piece of text and click the \n‘Add a comment’ icon on the right-hand side of the page. \n \n \n \n \n \nHow can it be improved? We welcome suggestions \nfrom the community in the comments. \n \n \n \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  2 \n\n \nExecutive summary \n \nMany of the public and private services we use are now digital. ​The move to \ndigital is likely to increase as technology becomes more embedded in our lives. But \nwhat does this mean for how essential public services understand who is using, or \nindeed not using, them and why? Public services are required to adhere to legal \nrequirements around discrimination, but how do these requirements apply in the \n1\ndigital sphere, and how can we monitor adherence to them?  \n \nWith funding from The Legal Education Foundation, we have explored how \n2\ndigital public services adhere to these legal requirements.​ ​We have sought to \nunderstand how the protected characteristics of people using the digital services are \nbeing collected, to make it possible to tell how they might be affecting excluded \ncommunities. \n \nProtected characteristics are a way of describing a part of who we are. ​The \n3\nEquality Act 2010 outlines protected characteristics as being age, disability, gender \nreassignment, marriage and civil partnership, pregnancy and maternity, race, religion \nor belief, sex, and sexual orientation. Article 14 of the Human Rights Act 1998 makes \n4\nit unlawful to discriminate against a person for a wide range of reasons, including \n“​sex, race, colour, language, religion, political or other opinion, national or social \norigin, association with a national minority, property, birth or other status”. \n5\n \nWe have found during this project that those providing digital public services \ndon’t know the demographic make-up of who uses them. ​Data about the \nprotected characteristics of people using these services isn’t currently collected and \nstatistics aren’t published in a consistent or collective way. This means it is harder to \nfind out who is excluded from using these services and why.  \n \nBarriers to access, exclusion or algorithmic biases based on protected \ncharacteristics are problematic.​ ​We know from research by organisations like \nCitizens Advice – a charity offering free, impartial advice – that people with mental \nhealth conditions, for example, have encountered barriers using everyday services. \n6\nThe UK government report, ‘Exploring the UK’s digital divide’, showed that women, \npeople aged over 65 and disabled people are all disproportionately affected by digital \nexclusion, meaning they are less likely to have the skills or access to use the internet \nand are therefore excluded from using online services.  \n7\n \nThere are also reports of exclusion from online services through built-in biases \nin digital services that use face and voice recognition. ​In addition, there is a risk \n8\nthat data-driven systems can operate in a discriminatory fashion,​ ​for example by \nhaving processes that are harder for women than men to successfully navigate. This \nwas highlighted in an open opinion by ​Dee Masters and Robin Allen QC. \n9\n1\n UK Government (2010), ‘Equality Act 2010’, ​https://www.legislation.gov.uk/ukpga/2010/15/contents  \n2\n The Legal Education Foundation (n.d.),​ https://www.thelegaleducationfoundation.org/ \n3\n Equality and Human Rights Commission (n.d.), ‘Protected characteristics’, \nhttps://www.equalityhumanrights.com/en/equality-act/protected-characteristics  \n4\n UK Government (2010), ‘Equality Act 2010’, ​https://www.legislation.gov.uk/ukpga/2010/15/contents​ ​Equality Act 2010  \n5\n Equality and Human Rights Commission (2018), ‘Article 14: Protection from discrimination’, \nhttps://www.equalityhumanrights.com/en/human-rights-act/article-14-protection-discrimination  \n6\n Citizens Advice (2017), ‘Citizens Advice finds people with mental health problems are being failed when trying to engage with \nessential everyday services’, \nhttps://www.citizensadvice.org.uk/about-us/how-citizens-advice-works/media/press-releases/citizens-advice-finds-people-with-m\nental-health-problems-are-being-failed-when-trying-to-engage-with-essential-everyday-services/  \n7\n Office for National Statistics (2019), ‘Exploring the UK’s digital divide’, \nhttps://www.ons.gov.uk/peoplepopulationandcommunity/householdcharacteristics/homeinternetandsocialmediausage/articles/exp\nloringtheuksdigitaldivide/2019-03-04  \n8\n New Scientist (2019), ‘UK launched passport photo checker it knew would fail with dark skin’, \nhttps://www.newscientist.com/article/2219284-uk-launched-passport-photo-checker-it-knew-would-fail-with-dark-skin/  \n9\n Cloisters (2019), ‘In the matter of automated data processing in government decision making’, \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  3 \n\n \n \nResponsible collection and publication of data and statistics on protected \ncharacteristics would enable the monitoring of digital public services​ to \ndetermine whether everyone is being treated equitably by the system. \n \nDuring this short research project, we conducted interviews with:  \n \n●organisations that have, or could develop, good practice \n●organisations that implement digital transformation \n●people and communities who could be helped or harmed by the data \n●regulators. \n \nAlthough we found a gap in specific guidance on how to design and collect data \nabout who uses digital services​,​ our desk research did reveal a range of useful \nguidance on collecting data safely and securely, which is published by regulators, \ngovernment organisations like the Government Statistical Service, and in the \n10\nhumanitarian sector. We also found that the demographic data that is collected by \ndevolved governments and equalities guidance differs for England, Scotland and \nWales. \n \nFurthermore, we found that organisations who already monitor for protected \ncharacteristics do so with privacy and dignity of people in mind​ and in alignment, \nwhere possible, with demographic data sources like the census.  \n \nIn light of our research and conversations with interviewees, we have made \nrecommendations on how we think there could be a move forward to collect \nand publish data about who uses digital services, while respecting people’s \nprivacy.​ ​These recommendations focus on the design and development of public \nservices, but equally could be adopted by private digital services and by \norganisations seeking to understand how their services are working – or not. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nhttps://www.cloisters.com/wp-content/uploads/2019/10/Open-opinion-pdf-version-1.pdf  \n10\n Government Statistical Service (n.d.), ​https://gss.civilservice.gov.uk/ \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  4 \n\n \n \n \n \n \nRecommendations  \n \n1.Collect data to understand services users  \nWe recommend that service designers start to embed, with respect and care, equalities \nmonitoring into the provision of digital public services.  \n \nWe recommend that any collection of protected characteristics data is designed such \nthat: \n \n●people can choose to provide information – or not  \n●privacy is respected  \n●standards and guidance are followed \n●the results are transparent and follow good data practice. \n \n2.Collaborate to develop standards, guidance and training \nWe recommend that regulators, and other bodies supporting and monitoring the \nadoption of digital public services, collaborate to produce robust guidance, standards \nand training on how to collect, use and publish data about the people using those \nservices.  \n \nWe further recommend that the Gov.uk Design System is developed to include styles, \n11\ncomponents and patterns to collect data about who uses the services and that this \nshould be based on rigorous and collaborative user research.  \n \nWe recommend that an open standard for data for monitoring equality requirements be \ndeveloped.  \n \nData at a minimum should include:  \n \n●Protected characteristics.  \n●Where the person is.  \n●Why the service has failed. \n \nWe recommend that training for service designers includes how to:  \n \n●design coherent, multi-channel services  \n●design for opting-out \n●consider inclusive user research.  \n \n3.Conduct further research  \nWe recommend that further research could be undertaken in the following areas:  \n \n●Are there other examples of monitoring equal access to services? \n●What other characteristics could be monitored?  \n●What impact does monitoring have on users of a service? \n●Can monitoring be trusted?  \n●How do citizens feel about the collection of monitoring data? \n \n \n11\n Gov.uk (n.d.), ‘Design your service using GOV.UK styles, components and patterns’, ​https://design-system.service.gov.uk/  \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  5 \n\n \nIntroduction \n \nPublic and private services are being transformed. Traditionally offline services, many \nof which are essential services, are now becoming digital by default. Part of the push \nin the public sector to make services digital stems from the UK Government’s \n‘Government Transformation Strategy 2017–2020’, which encouraged the harnessing \nof digital channels to build and deliver public services. As services go digital, they \n12\nmust still meet legal requirements around discrimination, just as non-digital services \n13\nmust; but we have found there is work to be done.  \n \nIn Great Britain, providers of services have a legal obligation to prevent discrimination \nand exclusion of a service based on a person’s protected characteristics, which \n1415\nincludes a person’s: age, disability, gender reassignment, marriage and civil \npartnership, pregnancy and maternity, race, religion or belief, sex, or sexual \norientation. \n \nIn Northern Ireland, service providers must make reasonable adjustments for people \nwith disabilities to help them to overcome barriers to accessing services. \n16\n \nUnfortunately there is no accepted practice for collecting and publishing data about \nwho uses digital services, which makes it hard to tell whether they have \ndiscriminatory effects or not. The absence of this data means providers of digital \nservices don’t know who is using the service and who is excluded. There is evidence \nthat some aspects of services are discriminatory, such as the algorithms behind visa \napplication processing, but it is unclear how widespread this is. The failure of an \n17\naccepted approach to collecting this data means it is hard for public authorities who \nhave obligations under the Public Sector Equality Duty (PSED) to advance equality \n18\nand demonstrate compliance.  \n \nThe impact of lack of data is also felt outside government bodies. Advocacy \norganisations such as Age UK and regulators like the Equalities and Human Rights \n19\nCommission (EHRC) or the Equality Commission for Northern Ireland (ECNI) are \n2021\nfinding it hard to understand if people are being discriminated against, and with a \nlack of data it is difficult for them to subsequently hold organisations to account.  \n \nIn this project, funded by The Legal Education Foundation (TLEF), we have explored \n22\nhow exclusion can happen and how data can help people understand if these legal \nobligations are being met. We wanted to understand the motivations, needs, wants \nand challenges people faced in collecting and publishing data about who uses digital \nservices.  \n \nWe interviewed people from organisations that have existing good practice in place, \n12\n Cabinet Office and Government Digital Service (2017), ‘Government Transformation Strategy’, \nhttps://www.gov.uk/government/publications/government-transformation-strategy-2017-to-2020/government-transformation-strat\negy  \n13\n UK Government (2010), ‘Equality Act 2010’, ​https://www.legislation.gov.uk/ukpga/2010/15/contents \n14\n Equality and Human Rights Commission (2019), ‘Your rights under the Equality Act 2010’, \nhttps://www.equalityhumanrights.com/en/advice-and-guidance/your-rights-under-equality-act-2010  \n15\n Equality and Human Rights Commission (n.d.), ‘Protected characteristics’, \nhttps://www.equalityhumanrights.com/en/equality-act/protected-characteristics  \n16\n NI Direct (n.d.), ‘Protection against disability discrimination’, \nhttps://www.nidirect.gov.uk/articles/protection-against-disability-discrimination \n17\n The Guardian (2018), ‘Lawyer blames visitor visa refusals on ‘deep underlying racism’, \nhttps://www.theguardian.com/uk-news/2018/jul/06/lawyer-blames-visitor-visa-refusals-on-deep-underlying-racism  \n18\n Equality and Human Rights Commission (2019), ‘Public Sector Equality Duty’, \nhttps://www.equalityhumanrights.com/en/advice-and-guidance/public-sector-equality-duty  \n19\n Age UK (n.d.), ​https://www.ageuk.org.uk/   \n20\n Equality and Human Rights Commission (n.d.), ​https://www.equalityhumanrights.com/en \n21\n Equality Commission for Northern Ireland (n.d.), ​https://www.equalityni.org/Home  \n22\n ​The Legal Education Foundation (n.d.), https://www.thelegaleducationfoundation.org/  \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  6 \n\n \norganisations which could help develop good practice, organisations that implement \ndigital transformation, people and communities who could be helped or harmed by \nthe data or lack of data, and regulators. \n \nWe also researched how organisations collect data on who uses their services, what \ngood practice exists or is used to collect data safely and securely, and other \nregulations to consider when collecting or publishing data on who uses digital \nservices. \n \nWe focused on speaking with organisations in the UK, including representatives from \ngovernment departments and from civil society. However, there are also good \npractices for collecting and publishing this type of data emerging from international \nbodies and much of this practice is applicable globally.  \n \nThis report explains what we discovered from interviews and desk research – from \nthe lack of insight into who uses digital services, to concerns about collecting data \nsafely – and our recommendations on how to move forward with good practice. \n  \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  7 \n\n \nWhat we did \n \nWith funding from the TLEF, we explored how protected characteristics of people \n23\nusing digital public services are collected and published. \n \nDuring research over eight weeks, we interviewed people from different stakeholder \ngroups, including the UK government, digital transformation practitioners and \ncommunity, and regulatory and advocacy bodies. We also engaged with \norganisations interested in our research and researched current practices, guidance \nand data. We produced this report based on our engagement, desk research and \ninterviews. \n \nWith thanks to: \n \n●Emily McCarron, Equality and Human Rights Policy Manager, Age UK \n●Tom MacInnes, Head of Data, Citizens Advice \n●Amy Turton, Project Diamond Manager, Creative Diversity Network \n●Ewan Devine-Kennedy, Principal Researcher, The Equality and Human Rights \nCommission \n●Andrew Goldsby, Community and Relationship Manager, Equality Advisory & \nSupport Service \n●Ali Harris, CEO, Equally Ours \n●Elric Honoré, Development Officer, Fife Center for Equalities \n●Ben Carpenter, Inclusive Services Lead, Government Digital Services  \n●Mhairi McGee, Policy and Campaigns Officer, HEAR Equality Network \n●Ali Shah, Head of Technology, Information Commissioner’s Office  \n●Judith Jones, Head of Regulatory Strategy (Domestic), Information \nCommissioner’s Office  \n●Zoe Leventhal, Public Law and Human Rights Barrister, Matrix Law \n●Clare Pini, Statistician, GSS Best Practice and Impact, Office for National \nStatistics \n●Paola Serafino, Head of the Centre for Equalities and Inclusion, Office for \nNational Statistics  \n●Richard Laux, Deputy Director (Data and Analysis), Race Disparity Unit \n●Samantha Fothergill, Lawyer and Campaigner, Royal National Institute of \nBlind People  \n●Albert King, Deputy Chief Data Officer, Scottish Government \n●Cat Macaulay, Chief Design Officer, Scottish Government \n \n  \n23\n The Legal Education Foundation (n.d.), ​https://www.thelegaleducationfoundation.org/  \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  8 \n\n \nBackground \nWhat are protected characteristics? \nIn Great Britain, it is against the law to treat a person unfairly because of who they \nare. The Equality Act 2010, regulated by the EHRC, makes discrimination against a \n24\nperson due to any of the following nine characteristics unlawful: \n \n1.Age:​ This may be a specific age or a range of ages, for example people over \n60. \n2.Disability:​ A long-term physical or mental impairment that affects a person’s \nability to carry out everyday activities.  \n3.Gender reassignment:​ ​A person reassigning their birth sex to a preferred \nsex and changing their physical or other characteristics. \n4.Marriage and civil partnership:​ Marriage or civil partnership between same \nor different sex couples. \n5.Pregnancy and maternity:​ A person who is pregnant, expecting a baby, on \nmaternity leave or breastfeeding. \n6.Race:​ A person belonging to a group defined by their colour, race, nationality \nor national origins. \n7.Religion and belief:​ A person’s religion or lack of religion, including a \nreligious or philosophical belief that affects the way they live. \n8.Sex:​ A man, woman or group of people like men, boys, women or girls. \n9.Sexual orientation:​ A person’s sexual attraction to same sex, different sex or \nboth. \n \nIn Northern Ireland, the Disability Discrimination Act 1995 applies and is regulated by \nthe ECNI. Providers of services must make reasonable adjustments to prevent \n25\ndiscrimination against people with disabilities. The definition of disability here differs \n26\nfrom the Equality Act 2010 in terms of length and seriousness of conditions – a \nperson must satisfy the particular definition. \n \nOur research focuses on the broader set of protected characteristics that apply in \nGreat Britain (England, Scotland and Wales). \nWhy research protected characteristics? \nEveryone has the right to fair and inclusive access to services and protection from \ndiscrimination. In Great Britain, the Equality Act 2010 defines protected \ncharacteristics as part of a person’s identity; essentially making them who they are. \nThe act replaces various laws that protected people from discrimination, including the \nRace Relations Act 1976 and the Disability Discrimination Act 1995 in England, \n2728\nScotland and Wales.  \n \nDiscrimination can be direct or indirect: a person who is treated worse than other \n29\npeople due to them having a protected characteristic, being thought to have a \nprotected characteristic, or being associated with someone with a protected \ncharacteristic, experiences direct discrimination. A policy can cause indirect \n24\n UK Government (2010), ‘Equality Act 2010’, ​https://www.legislation.gov.uk/ukpga/2010/15/contents  \n25\n Equality Commission for Northern Ireland (n.d.), ​https://www.equalityni.org/Home \n26\n NI Direct (n.d.), ‘Disability discrimination law’, \nhttps://www.nidirect.gov.uk/articles/protection-against-disability-discrimination#toc-1 \n27\n UK Government (1976), ‘Race Relations Act 1976’, ​https://www.legislation.gov.uk/ukpga/1976/74/enacted \n28\n UK Government (1995), ‘Disability Discrimination Act 1995’, ​https://www.legislation.gov.uk/ukpga/1995/50/contents/enacted \n29\n Equality and Human Rights Commission (2019), ‘What is direct and indirect discrimination?’, \nhttps://www.equalityhumanrights.com/en/advice-and-guidance/what-direct-and-indirect-discrimination \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  9 \n\n \ndiscrimination when it is applied in the same way to everyone, but overall \ndisadvantages a group of people with a protected characteristic. \n \nIn 2017, Citizens Advice – a charity offering free, impartial advice – found that people \nwith mental health conditions encountered barriers using everyday services. These \n30\nservices include paying bills, switching energy providers, and contacting local \nauthorities. Their research concluded that more flexibility is needed when \ncommunicating with people who have a mental health diagnosis. Long-term mental \nhealth conditions are a disability under the Equality Act 2010, and by collecting and \npublishing who uses digital services, we can better understand who faces barriers \nusing them. \n \nOur research focuses on all protected characteristics, with the aim of advancing \nequal access to fair and inclusive services. \nWhy focus on digital services? \nIn 2017, the then UK Government set out the ‘Government Transformation Strategy \n2017–2020’. This strategy outlined how the government planned to harness digital \n31\nto build and deliver fast, effective public services. \n \nDigital channels, however, come with their own set of challenges. We know that \ndigital exclusion – when people are unable to, or choose not to, engage with the \ndigital world – presents a real risk of inequality. In 2018, 5.3 million adults, or 10% of \nthe adult UK population, experienced digital exclusion. According to the Office for \n32\nNational Statistics (ONS), women, people aged over 65 and disabled people were \ndisproportionately affected by digital exclusion. This is particularly true of disabled \n33\npeople, as one in five people in the UK are affected by long-term illness, have an \nimpairment or live with a disability. In 2017, 56% of internet non-users were \n34\ndisabled. \n \nThe risks of lack of fairness and equality in relation to digital services do not just arise \nover access to those services, but in how they treat people differently. In 2019, a \nreport in ​New Scientist​ revealed that the new passport photo checking service from \nthe Home Office failed to recognise skin shades of people from ethnic minority \ngroups. The Passport Office’s digital service had also rejected an application from a \n35\nyoung black man when his closed lips failed the facial recognition checks. Even if \n36\nthe final outcome of using such a service is eventually the same, through appeal to \nhuman intervention, inequalities arise in the time, effort and emotional impact on \npeople with protected characteristics. \n \nDigital services, from websites such as Gov.uk and the passport service, are the \npotential future of UK government services. Services such as HM Revenue and \nCustoms (HMRC) Voice ID, which uses biometrics, may also become more prevalent \nin the future. The use of biometrics is currently a sensitive area. In the UK, the use of \n30\n Citizens Advice (2017), ‘Citizens Advice finds people with mental health problems are being failed when trying to engage with \nessential everyday services’, \nhttps://www.citizensadvice.org.uk/about-us/how-citizens-advice-works/media/press-releases/citizens-advice-finds-people-with-m\nental-health-problems-are-being-failed-when-trying-to-engage-with-essential-everyday-services/  \n31\n Cabinet Office and Government Digital Service (2017), ‘Government Transformation Strategy’, \nhttps://www.gov.uk/government/publications/government-transformation-strategy-2017-to-2020/government-transformation-strat\negy  \n32\n Office for National Statistics (2019), ‘The scale of digital exclusion in the UK’, \nhttps://www.ons.gov.uk/peoplepopulationandcommunity/householdcharacteristics/homeinternetandsocialmediausage/articles/exp\nloringtheuksdigitaldivide/2019-03-04#the-scale-of-digital-exclusion-in-the-uk \n33\n Office for National Statistics (2019), ‘How does internet usage and digital exclusion vary for men and women?’, \nhttps://www.ons.gov.uk/peoplepopulationandcommunity/householdcharacteristics/homeinternetandsocialmediausage/articles/exp\nloringtheuksdigitaldivide/2019-03-04#how-does-internet-usage-and-digital-exclusion-vary-for-men-and-women \n34\n Scope (n.d.), ‘Disability facts and figures’, ​https://www.scope.org.uk/media/disability-facts-figures/  \n35\n New Scientist (2019), ‘UK launched passport photo checker it knew would fail with dark skin’, \nhttps://www.newscientist.com/article/2219284-uk-launched-passport-photo-checker-it-knew-would-fail-with-dark-skin  \n36\n BBC News (2019), ‘Passport facial recognition checks fail to work with dark skin’, \nhttps://www.bbc.co.uk/news/technology-49993647  \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  10 \n\n \nfingerprints and DNA are covered by the Protection of Freedoms Act 2012, but \n37\nother forms of biometrics, such as facial biometrics, voice or gait, for example, are \nnot currently subject to legislative or regulatory guidance or oversight. Research into \nissues of bias within the algorithms and technology used in facial biometrics for \nexample, has shown that false positives towards women, the elderly, children, and \nWest and East African and East Asian people are present.  \n38\n \nThe move to digital, and more broadly to automated or biometric-based services, \ntherefore requires a focus on understanding who is using, or not using, these digital \nservices; the outcomes of their interactions with the services; and the experiences of \ndifferent groups when using these services and the alternatives they are offered. \n \n \n \n37\n UK Government (2012), ‘Protection of Freedoms Act 2012’, \nhttps://www.legislation.gov.uk/ukpga/2012/9/contents/enacted?view=plain \n38\n National Institute of Standards and Technology, US Department of Commerce (2019), ‘Face recognition vendor test. Part 3: \nDemographic effects’, ​https://nvlpubs.nist.gov/nistpubs/ir/2019/NIST.IR.8280.pdf \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  11 \n\n \nLegislation and guidance \nIn England, Scotland and Wales, the Equality Act 2010 is the key piece of legislation \nthat protects people from discrimination. In Northern Ireland, the Disability \n39\nDiscrimination Act 1995 applies. \n40\n \nArticle 14 of the Human Rights Act 1998 makes it unlawful to discriminate against a \nperson for a wide range of reasons, including “sex, race, colour, language, religion, \npolitical or other opinion, national or social origin, association with a national \nminority, property, birth or other status”. \n41\n \nPublic authorities must also comply with the Public Sector Equality Duty (PSED) to \n42\neliminate discrimination, advance equality and foster good relations between those \nwho share protected characteristics and those who don’t.  \n \nGuidance on the PSED is devolved for Scotland and Wales. There is also \n4344\nseparate guidance for England and non-devolved public authorities in Wales and \nScotland. To support transparency, public authorities must also publish equality \n45\nobjectives every four years and demonstrate their compliance.  \n \nFor local authorities, the ‘Best value statutory guidance’ outlines how to work with \nvoluntary and community groups and small businesses to deliver effective public \nservices.  \n46\n \nOur research focuses on monitoring the use of digital public services, which means \ncollecting and publishing data about the people using them, to which the General \nData Protection Regulation (GDPR) and the Data Protection Act 2018 apply. Data \n4748\nabout protected characteristics is similar to sensitive personal data, which is \n49\ndefined as a special category of data under the GDPR. \n \nPart 5 of the Digital Economy Act 2017 outlines how the government will make \nbetter use of data, including data sharing, research and statistics, and safeguarding \npeople’s privacy. \n50\n \nFor websites and mobile devices, the UK government has committed to new \naccessibility regulations: The Public Sector Bodies (Websites and Mobile \nApplications) (No. 2) Accessibility Regulations 2018. \n51\n \n39\n UK Government (2010), ‘Equality Act 2010’, ​http://www.legislation.gov.uk/ukpga/2010/15/contents  \n40\n UK Government (1995), ‘Disability Discrimination Act 1995’, ​https://www.legislation.gov.uk/ukpga/1995/50/contents  \n41\n Equality and Human Rights Commission (2018), ‘Article 14: Protection from discrimination’, \nhttps://www.equalityhumanrights.com/en/human-rights-act/article-14-protection-discrimination  \n42\n UK Government (2010), ‘Equality Act 2010. Section 149: Public sector equality duty’, \nhttp://www.legislation.gov.uk/ukpga/2010/15/contents  \n43\n Equality and Human Rights Commission (2019), ‘Guidance for Scottish public authorities’, \nhttps://www.equalityhumanrights.com/en/advice-and-guidance/guidance-scottish-public-authorities  \n44\n Equality and Human Rights Commission (2014), ‘The essential guide to the Public Sector Equality Duty: An overview for listed \npublic authorities in Wales’, \nhttps://www.equalityhumanrights.com/en/publication-download/essential-guide-public-sector-equality-duty-overview-listed-public\n-authorities  \n45\n Equality and Human Rights Commission (2014), ‘The essential guide to the Public Sector Equality Duty’, \nhttps://www.equalityhumanrights.com/en/publication-download/essential-guide-public-sector-equality-duty  \n46\n Communities and Local Government (2011), ‘Best value statutory guidance’, \nhttps://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/5945/1976926.pdf  \n47\n Information Commissioner’s Office (2018), ‘Guide to the General Data Protection Regulation’, \nhttps://www.gov.uk/government/publications/guide-to-the-general-data-protection-regulation  \n48\n UK Government (2018), ‘Data Protection Act 2018’, ​https://www.legislation.gov.uk/ukpga/2018/12/contents/enacted  \n49\n Information Commissioner’s Office (n.d.), ‘What is personal data?’, \nhttps://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/key-definitions/\nwhat-is-personal-data/  \n50\n UK Government (2017), ‘Digital Economy Act 2017’, ​http://www.legislation.gov.uk/ukpga/2017/30/contents/enacted  \n51\n UK Government (2018), ‘The Public Sector Bodies (Websites and Mobile Applications) (No. 2) Accessibility Regulations 2018’, \nhttps://www.legislation.gov.uk/uksi/2018/952/made  \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  12 \n\n \n \nUnfortunately, at present, there is no accepted practice for collecting and publishing \ndata about who uses digital services and their experience. There is little evidence of \npublic digital services collecting this data consistently and transparently. There is also \nno open standard for doing so. However, there are pockets of practice and published \ndata inside and outside local and central governments. \n \nOur research revealed a gap in how to safely and securely collect and publish this \ndata as part of digital services. In the next section, we describe how we carried out \nour research, and outline our findings and recommendations. \n \n \n \n \n  \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  13 \n\n \nWhat we found \nInclusive services need to be accessible \nThe Government Digital Service (GDS) ‘Service manual’ is the guidance for \n52\ngovernment teams building digital services. It provides a quick and easy way to \n53\nunderstand how government services are built, agile ways of working, and provides \nexamples of how government service principles are used. It is used to help​ “teams to \ncreate and run great public services” and​ ​touches on the need to design inclusive \nservices. For example, the guidance on understanding users who don’t use digital \nservices focuses on making design inclusive and providing support for those who \n54\nneed help. The section on making your service more inclusive emphasises the \n55\nbarriers people may face to using government services and the legal duty to be \nadhered to under the Equality Act 2010. The importance of creating inclusive \ngovernment services guidance details the GDS’s work on building inclusive services \n56\nfor everyone.  \n \nTo comply with the Public Sector Bodies (Websites and Mobile Applications) (No. 2) \nAccessibility Regulations 2018, the manual includes guidance on making your \n57\nservice accessible. Accessible services must meet the Web Content Accessibility \n58\nGuidelines (WCAG) 2.1. For example, they must support assistive technologies like \n59\nscreen magnifiers and screen readers, work with people who are disabled as part of \ntheir user research, and explain what it is that has been done to make the service \nmore accessible. \n \nWe found that no single design element makes a service fairer and more inclusive for \nall protected characteristics. People may fit in one group, or they may have multiple \ncharacteristics in a single group, for example, multiple disabilities, or they may be \npart of more than one group. As Cat Macauley, Chief Design Officer at the Scottish \nGovernment, said to us: “I don’t know any people who fit in a [single] protected \ncharacteristic, most people who fit one will also fit another, if multiple.”​ ​Furthermore, \nthere is also the issue that how people choose to define themselves may differ from \nhow others define them.  \n \nWhile it is important to meet the accessibility requirements, it must be understood \n60\nthat accessibility alone will not provide support to all people with protected \ncharacteristics who may use a digital service.  \n \nFully inclusive services that take into account the intersection between protected \ncharacteristics are needed. It is important to understand that people’s needs and \ncircumstances can change. Disability, for example, may be as temporary as a broken \nfoot, or as permanent as the ongoing need to use a wheelchair. People’s engagement \nwith technology, therefore, can also change. For example, while a screen reader may \nbe beneficial for a period of time, if a person’s sight deteriorates, a screen reader may \n52\n Gov.uk (n.d.), ‘Service manual’, ​https://www.gov.uk/service-manual  \n53\n Government Digital Service (2018), ‘How we write guidance for the service manual’, \nhttps://gds.blog.gov.uk/2018/05/17/how-we-write-guidance-for-the-service-manual/  \n54\n Gov.uk (2016), ‘Service manual: Understanding users who don’t use digital services’, \nhttps://www.gov.uk/service-manual/user-research/understanding-users-who-dont-use-digital-services  \n55\n Gov.uk (2018), ‘Service manual: Making your service more inclusive’, \nhttps://www.gov.uk/service-manual/design/making-your-service-more-inclusive  \n56\n Government Digital Service (2018), ‘The importance of creating inclusive government services’, \nhttps://gds.blog.gov.uk/2018/06/29/building-inclusive-government-services/  \n57\n UK Government (2018), ‘The Public Sector Bodies (Websites and Mobile Applications) Accessibility Regulations 2018’, \nhttp://www.legislation.gov.uk/uksi/2018/852/contents/made  \n58\n Gov.uk (2019), ‘Service manual: Making your service accessible: An introduction’, \nhttps://www.gov.uk/service-manual/helping-people-to-use-your-service/making-your-service-accessible-an-introduction  \n59\n World Wide Web Consortium (2018), ‘Web Content Accessibility Guidelines (WCAG) 2.1’, ​https://www.w3.org/TR/WCAG21/  \n60\n HM Government (n.d.), ‘Making online public services accessible’, ​https://accessibility.campaign.gov.uk/  \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  14 \n\n \nnot be the solution they need to enable them to access a service.  \n \nThese concepts are explored in ‘Inclusive design principles’, which encourages \n“putting people first”​ ​by “designing for the needs of people with permanent, \ntemporary, situational, or changing disabilities”,​ ​with people being defined as “all of \nus”.   \n61\n \nInternationally, the Ontario government’s inclusive design toolkit similarly \n62\nencourages the design of services for people with ​“​temporary or situational \ndisabilities”​, ​while in the UK, the GDS guidance on ‘the importance of creating \ninclusive government services’ stresses that: ​“​fully inclusive service is one that can \nbe accessed and successfully completed by all its users. They will be able to interact \nhowever they need to, regardless of their personal characteristics, situations, \ncapabilities or access needs.” \n63\n \nExpanding on these helpful toolkits and service manuals, well-researched guidance \nand inclusive design patterns​ ​will help make it easier to design fairer, more inclusive \nservices.  \nEquality requires more than accessible design \nServices tend to exclude people with disabilities. Citizens Advice found that people \nwith mental health conditions encountered barriers using everyday services, while \n64\nthe United Nations Special Rapporteur has raised concerns about the digital welfare \nstate.  \n65\n \nDigital exclusion presents a real risk of inequality, and disabled people are \n6667\ndisproportionately affected, as one in five people in the UK are affected by long-term \nillness, have an impairment or live with a disability.  \n68\n \nWe welcome making digital services easier to use for people with disabilities. The \nGDS has committed to meeting accessibility requirements, including level AA of the \nWCAG 2.1 as a minimum. \n69\n \nWe found that work towards equality currently focuses heavily on disability, but less \nso on other protected characteristics.  \n \nOrganisations we interviewed were less likely to focus on sexual orientation, gender \nreassignment, and religion or belief, for example. We discovered a reluctance to ask \nabout these protected characteristics and assumptions that other protected \ncharacteristics are more likely to be the basis for exclusion from public digital \nservices. \n61\n Inclusive Design Principles (n.d.), ​https://inclusivedesignprinciples.org/  \n62\n Ontario Government (2020), ‘Inclusive design toolkit’, ​https://www.ontario.ca/page/inclusive-design-toolkit  \n63\n ​Government Digital Services (2018), ‘The importance of creating inclusive government services’, \nhttps://gds.blog.gov.uk/2018/06/29/building-inclusive-government-services/  \n64\n ​Citizens Advice (2017), ‘Citizens Advice finds people with mental health problems are being failed when trying to engage \nwith essential everyday services’, \nhttps://www.citizensadvice.org.uk/about-us/how-citizens-advice-works/media/press-releases/citizens-advice-finds-people\n-with-mental-health-problems-are-being-failed-when-trying-to-engage-with-essential-everyday-services/  \n65\n ​United Nations Special Rapporteur (2019), ‘Report of the Special rapporteur on extreme poverty and human rights’, \nhttps://www.ohchr.org/Documents/Issues/Poverty/A_74_48037_AdvanceUneditedVersion.docx  \n66\n ​Office for National Statistics (2019), ‘The scale of digital exclusion in the UK’, \nhttps://www.ons.gov.uk/peoplepopulationandcommunity/householdcharacteristics/homeinternetandsocialmediausage/arti\ncles/exploringtheuksdigitaldivide/2019-03-04#the-scale-of-digital-exclusion-in-the-uk  \n67\n ​Office for National Statistics (2019), ‘What is the pattern of internet usage among disabled people?’, \nhttps://www.ons.gov.uk/peoplepopulationandcommunity/householdcharacteristics/homeinternetandsocialmediausage/arti\ncles/exploringtheuksdigitaldivide/2019-03-04#what-is-the-pattern-of-internet-usage-among-disabled-people \n68\n ​Scope (n.d.), ‘Disability facts and figures’, ​https://www.scope.org.uk/media/disability-facts-figures/  \n69\n ​World Wide Web Consortium (2018), ‘Web Content Accessibility Guidelines (WCAG) 2.1’, \nhttps://www.w3.org/TR/WCAG21/  \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  15 \n\n \n \nBen Carpenter from the GDS said to us: “It seems that the timing of when to ask \npeople potentially very sensitive questions is hard to fit in with their user needs, so \nyou’re trying to provide a service that is just about what they need, whereas this is \nsomething that we need.”  \n \nUnderstanding that designing for equal access must consider all protected \ncharacteristics is an important step for organisations providing digital services to \ntake.  \n \nFurthermore, we must ensure that the problem of bias being built, often \nunintentionally, into automated systems using machine learning algorithms to make \ndecisions, does not impinge on equality of access to services.  \n \nAlready automated systems making decisions about people’s lives have been shown \nto have demonstrably negative impacts on people with protected characteristics. One \nexample is the UK’s visa application programme, which has been identified by some \norganisations as being biased against applications from black and ethnic minority \napplicants.  \n70\n \nWhether the system is biased or not is unclear. Answers to the problem are unlikely \nto become clear anytime soon, not solely because of government secrecy, but \nbecause the process of lifting the hood and interrogating algorithmic decision is \ncomplex at best. Challenging or seeking redress against a decision is rarely, if ever, \npossible. How future systems are audited to ensure that protected characteristics are \nbeing analysed and used appropriately and ethically is a critical concern which \nshould be addressed now.  \nWe lack data on the use of digital services \nA key source of information to help with understanding equalities in the UK today is \nthe ONS equalities data audit. The report audits data sources and publications on \n71\noutcomes for the nine protected characteristics covered in the Equality Act 2010, to \ninform policy. It is informed by the EHRC’s ‘Measurement framework for equality and \nhuman rights’ and the United Nations ‘A human rights-based approach to data’ \n72\nreport.  \n73\n \nOver 280 sources are listed in the equalities audit dataset and work is ongoing. The \nreport is interesting as it highlights that good guidance makes it easier for people to \nuse data; by explaining what the data is intended for, how it was collected, things to \nconsider before using it and important features to be aware of.  \n \nOne of the key findings of the report is that there is an increasing demand for robust \nand accessible data about equalities. The report also notes that access to information \nabout data sources is an issue, with the exception being good practice from NHS \nDigital.  \n \nComplementing the report are the Government Statistical Service’s (GSS) \n‘harmonised principles’. These principles are “guidance on how to make statistics \n74\n70\nThe Guardian (2018), ‘Lawyer blames visitor visa refusals on “deep underlying racism”’, \nhttps://www.theguardian.com/uk-news/2018/jul/06/lawyer-blames-visitor-visa-refusals-on-deep-underlying-raci\nsm  \n71\n ​Office for National Statistics (2018), ‘Equalities data audit, final report’, \nhttps://www.ons.gov.uk/methodology/methodologicalpublications/generalmethodology/onsworkingpaperseries/equalitiesd\nataauditfinalreport  \n72\n ​Equality and Human Rights Commission (2017), ‘Measurement framework for equality and human rights’, \nhttps://www.equalityhumanrights.com/sites/default/files/measurement-framework-interactive_pdf.pdf  \n73\n ​United Nations Human Rights (2018), ‘A human rights-based approach to data’, \nhttps://www.ohchr.org/Documents/Issues/HRIndicators/GuidanceNoteonApproachtoData.pdf  \n74\n ​Government Statistical Service (n.d.), ‘Harmonisation’,​ https://gss.civilservice.gov.uk/guidances/harmonisation/  \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  16 \n\n \nmore comparable by encouraging producers to use the same methods of data \ncollection and presentation”.​ ​The principles include​ ​“definitions, survey questions, \nstandards for administrative data, rules for presentation and guidance for users”. The \naim of them is to encourage “data collection to be consistent where appropriate to \nimprove understanding of data and statistics and to make statistics comparable”.  \n \nA couple of the people we interviewed referred to these principles as being helpful in \noffering some good practice and a clear approach which could be used by all. \nData protection is no barrier to statutory duty \nWe encountered concerns that public bodies connect compliance with the GDPR \nwith avoiding collecting and publishing data about protected characteristics. \nConcerns included collecting data without justification and being wary of \nnon-compliance with data protection. Data protection is no barrier to fulfilling \nequalities duties. The Information Commissioner’s Office (ICO) recently shared \nguidelines to help organisations collect sensitive data which overlaps with protected \ncharacteristics. \n \nWe spoke with the ICO to clarify this. Judith Jones of the ICO told us: “There is \nprovision in the Data Protection Act about collecting and retaining information for \nequality purposes and we’ve got guidance that’s just come out on what we would call \nspecial category data, which is pretty close to the protected characteristics data and \nwe very much emphasise it being fair and transparent, so telling people what you’re \ndoing and treating them fairly, but also what we would look at is proportionality.” \n \nThe guidance on collecting ‘special category data’ overlaps with protected \ncharacteristics in several areas. The key message is that public bodies must meet \ntheir legal obligations under the PSED as well as comply with the GDPR. Compliance \nwith the GDPR, therefore, is not, and should not, be seen as a barrier to the collection \nor publication of data, so long as the process adheres to the guidance from the ICO, \nparticularly around using a privacy impact assessment to detail how, among other \nthings, the data will be collected, for what purpose and for how long.  \n \nUnderstanding and implementing the ICO guidance will help data controllers define \nthe purpose, assess risks, take precautions and demonstrate they can protect this \ndata.  \nData about vulnerable people needs to be \nhandled ethically \nOutside of government, humanitarian organisations have produced guidance on \nworking ethically with data about vulnerable people; upholding their rights and \ntreating them with dignity and respect. Oxfam publishes the ‘Responsible data \nmanagement’ training pack, the US Agency for International Development (USAID) \n75\nprovides ‘Considerations for using data responsibly’, and The Centre for \n76\nHumanitarian Data shares the working draft of their ‘Data responsibility guidelines’. At \nthe ODI, we have published a theory of change, which demonstrates how those who \nsteward and create information from data can act in ways that lead to the best social \nand economic outcomes for all. \n75\n ​Oxfam (n.d.), ‘Responsible data management’, \nhttps://policy-practice.oxfam.org.uk/our-approach/toolkits-and-guidelines/responsible-data-management  \n76\n U​S Agency for International Development (2019), ‘Considerations for using data responsibly at USAID’, \nhttps://www.usaid.gov/responsibledata  \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  17 \n\n \n \nThe ODI theory of change \n77\n \n \nTrust was a key factor for organisations with experience monitoring who uses their \nservices. In the UK, the Equality Advisory & Support Service (EASS) shares data with \norganisations including the EHRC, as part of their work advising and assisting people \non equality and human rights.  \n \nWe learned from Andrew Goldsby, Community and Partnership Manager at EASS, \nthat they safely and securely collect detailed information about protected \ncharacteristics from people using their helpline. This information is provided on a \ncompletely voluntary and optional basis. Andrew told us that “it’s a case of you can \neither provide us with nothing, or some of the information, or everything that you feel \ncomfortable with.”​ ​This approach allows them to monitor which protected \ncharacteristics are prevelent when experiencing discrimination, as well as gaining an \nunderstanding as to who is using their service. \nThere are examples of using and publishing \nmonitoring data \nCollecting and publishing data to monitor public digital services is accepted practice \naccording to the ‘measuring success’ section of the GDS ‘Service manual’. Data \n78\nmust be collected and published on digital take-up, user satisfaction, completion rate \nand cost per transaction. The aggregated data is published to the performance \ndashboard and is available to service providers, government and the public. \n \n77\n ​Open Data Institute, ‘Theory of change’, \nhttps://theodi.org/about-the-odi/our-vision-and-manifesto/our-theory-of-change/  \n78\n ​Gov.uk (n.d.), ‘Service manual: Measuring success’, ​https://www.gov.uk/service-manual/measuring-success  \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  18 \n\n \n \n \nImage source: Gov.uk \n \nIn most cases, the published data does not break down these statistics based on \nprotected characteristics, nor does it describe the outcomes for different user \nsegments. One exception is voter registration, which tracks applications based on \nage. This demonstrates the technical feasibility of monitoring data being published \n79\non the performance platform. \n \nCitizens Advice was frequently mentioned by the government and the civil service as \nhaving good practices in collecting and publishing data about who uses its services. \nWe learned from Tom MacInnes, Head of Data at Citizens Advice, that its data \ncollection focuses on five of the nine protected characteristics, with gender \nreassignment, pregnancy and maternity, sexual orientation, and religion or belief \ncollected less frequently. This approach has clearly been of value, as Citizens Advice \nand the GDS worked together in 2018 to produce several dashboards which \n80\nhighlight the use of high-level data, including gender and location.  \n \nWhile collecting and publishing data about protected characteristics as people use \nservices isn’t widespread or consistent, organisations such as the EASS and Citizens \nAdvice have shown that it is possible.  \nInclusive services need more than numbers \nWe discovered concerns that providers of digital services may focus on data, \nespecially quantitative data, and lose sight of the objectives of equalities legislation, \nnamely creating a fairer, more inclusive society. \n79\n Gov.uk (n.d.), ‘Voter registration’, ​https://www.gov.uk/performance/register-to-vote  \n80\n Government Digital Service (2018), ‘Working with Citizens Advice and its amazing data’, \nhttps://gds.blog.gov.uk/2018/01/10/working-with-citizens-advice-and-its-amazing-data/ \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  19 \n\n \n \nCat Macauley, Chief Design Officer at the Scottish Government, told us: “As a \ndesigner, what I struggle with is helping my teams and the people that we work with \nunderstand the need to go beyond quant[itive] data. I think where we have real issues \nwith data is around qualitative data.” \n \nThis point about qualitative data is important. The need to understand not only who is \nusing a digital service, but who isn’t and why, is also important. As is the need to \ngrasp who is being excluded and who may be being discriminated against. If service \ndesigners can get a handle on these issues, and find a deeper understanding of the \nreasoning and behaviours behind these questions, they will gain insights which will, \nwe believe, help them design and build more inclusive services. Considering the \ncollection of different types of data and staying clear on the objectives outlined in \nequality legislation are critical elements of the design process.  \n \n \n  \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  20 \n\n \nOur recommendations \nCollect data to understand service users \nOur first set of recommendations is for those designing digital public services. \n \nThis report has described how digital public services may exclude people by putting \nup barriers to access, embedding discriminatory algorithms, and/or providing a \nsubstantially worse experience for people with protected characteristics. Collecting \ndata to understand service users can help those operating digital services to \ndemonstrate their adherence to equality duties and to understand where to iterate on \nthe design of the service to address any equality issues. \n \nWe recommend that service designers start to embed equalities monitoring into the \nprovision of digital public services. However, data about protected characteristics is \nsensitive and needs to be handled with respect and care. Collecting this data in itself \nmay discourage people from using the service and increase concerns about the \ngovernment’s use of personal data. We therefore recommend that service designers \ntake a measured and informed approach, with an emphasis on trust and ethical \npractice, and make its impact a focus of user research. \n \nIn particular, we recommend that any collection of protected characteristic data for \nmonitoring purposes is designed such that: \n \n●People can choose to provide information or not:​ People using digital \nservices must have a choice of whether to provide or withhold information, \nincluding opting out entirely or out of providing certain information, without \nthis having a negative impact on their ability to use the service. The absence \nof data, where people have opted out, should not be feared. It is valuable \ndata in itself. Data collection is important, but it is not more important than \nrights and autonomy. \n \n●Privacy is respected:​ People using digital services can provide information \nabout protected characteristics that aren’t linked to their records or \noutcomes; examples of how are already out there, notably the blind \napplications used by the civil service when hiring staff. Anonymous data \ncollection is more likely to encourage people to volunteer information about \nprotected characteristics, as they are less likely to feel that revealing \ninformation would be detrimental to them. Minimise personal data collected \nto provide the service and maintain a separation at all levels – from front end \nto back end – between that collected to provide the service and that required \nfor monitoring it. \n \n●Standards and guidance are followed:​ This report has described a number \nof sources of guidance for the design of accessible services and the \ncollection of protected characteristics data. Refer to and adopt the \nrecommendations of existing standards and guidance rather than develop \nnew ones. This not only reduces effort, but makes it easier to aggregate \nstatistics and compare services. \n \n●The results are transparent:​ People with protected characteristics may \nalready be concerned about discrimination. Hiding data that could reveal \ndiscrimination, such as disaggregated statistics about the outcomes \nexperienced by people with different protected characteristics, undermines \ntrust in government further. Transparency of this data, alongside explanations \nand action plans if the data reveals discrimination, can build trust. \n \n●Transparency follows good data practice:​ Publishing data about who uses \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  21 \n\n \na digital service is valuable for providers of the service, namely government \nand advocacy bodies. Transparency is important as long as good data \npractices are followed to aggregate data, reduce the chances of \n81\nre-identification by individuals recognising themselves, being identified when \ncombined with other data, or by emerging technologies that are not privacy- \npreserving. \n82\nCollaborate to develop standards, guidance and \ntraining \nOur second set of recommendations is for regulators and other bodies supporting \nand monitoring the adoption of digital public services. We want to see collaboration \nbetween them to develop standards, guidance and training on how to collect, use \nand publish data about the people using those services. \n \nWe’ve seen the impact of effective guidance and standards like the WCAG 2.1 in \n83\nhelping digital services improve accessibility. The GDS has committed to helping \npublic sector websites meet accessibility requirements; by 2020 for existing websites \nand 2021 for apps. Applying lessons learnt in this area is important to developing \n84\nsimilar, robust guidance and standards for wider equality. \n \nTo produce robust guidance, collaboration is recommended between regulators \nincluding the ICO and the EHRC, the GDS and organisations such as Citizens Advice \nand the EASS, who have mature practices in monitoring protected characteristics. \nSuch an approach would also help provide clarity for those building services so that \nthey understand clearly what they can and cannot do in relation to the various pieces \nof legislation in this space.  \n \nWe recommend that the Gov.uk Design System is developed to include styles, \ncomponents and patterns to collect data about who uses digital services. This should \nbe based on rigorous and collaborative user research, and should consider what data \nis required as part of the service, how data will be aggregated while protecting user \nprivacy, and when to harmonise data with official statistics to allow easier \ncomparison. Aligning with, or adapting, the GSS harmonisation principles will ensure \ndata collected is robust and comparable with official statistics. This will allow \ncomparison of who is using digital services with who is expected to do so and who \nmay be excluded. \n \nData at a minimum should include: \n \n●Protected characteristics:​ As a person uses a digital service they should be \nasked to provide information, optionally and anonymously, about their \nprotected characteristics. This allows the provider to understand who is using \ntheir service compared with the population expected to do so. \n \n●Where the person is: ​Protected characteristics guidance can depend on \nlocation. Data needed to better understand who is excluded may be \ncollected differently by devolved governments. User research is needed to \nunderstand what location data is good practice to collect, for example, \npostcode, location from IP addresses or other location information. \n \n81\n ​Government Statistical Service (n.d.), ‘Guidance’, ​https://gss.civilservice.gov.uk/guidance/  \n82\n ​Information Commissioner’s Office (2019), ‘Data minimisation and privacy-preserving techniques in AI systems’, \nhttps://ico.org.uk/about-the-ico/news-and-events/ai-blog-data-minimisation-and-privacy-preserving-techniques-in-ai-syst\nems/  \n83\n ​World Wide Web Consortium (2018), ‘Web Content Accessibility Guidelines (WCAG) 2.1’, ​https://www.w3 \n.org/TR/WCAG21/  \n84\n Government Digital Service (2018), ‘How we’re helping public sector websites meet accessibility requirements’, \nhttps://gds.blog.gov.uk/2018/09/24/how-were-helping-public-sector-websites-meet-accessibility-requirements/  \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  22 \n\n \n●Why the service has failed:​ When a person can’t use a digital service, they \nshould be able to share why and which protected characteristics, if any, have \ncontributed to the service failing for them. This allows service failure to be \ndirectly related to a group of protected characteristics.  \n \nWe recommend that guidance for the data elements of the Design System is \npublished as an open standard for data; a reusable agreement between \n85\norganisations with expertise in service design, equalities, official statistics and \nmonitoring protected characteristics, including the GDS, the GSS, the Race Disparity \nUnit, the ONS, and organisations outside government like Citizens Advice.  \n \nAny open standard for data developed should align with the ‘Open standard \nprinciples’ and be signed off by the Cabinet Office’s Open Standards Board. An \n8687\nopen standard signed off by the board will encourage reuse within and outside \ngovernment, providing leadership in how organisations collect and publish data about \nwho uses digital services. \n \nWe recommend that guidance covers how to compare who uses a service with the \npopulation expected to do so. This comparison should take into account where \npeople live or where they are gaining access from. Service providers should be aware \nof the impact of devolution when their service is location-specific, and consider \nmeasures for services provided throughout the UK. Demographic data, for example \ncensus data and Indices of Multiple Deprivation, are collected by respective devolved \nnations. Guidance around the PSED is also affected by devolution, with specific \nresponsibilities described in Wales and Scotland. The GSS provides detailed \nguidance on using official statistics and harmonising data across the UK.  \n \nWe recommend that guidance and training provided to service designers covers how \nto design services that collect and publish protected characteristics. Service \ndesigners should be trained on how to make reasonable adjustments for people who \nneed help with digital channels, as well as people who can’t use them. \n \nInclusive design training for service designers would focus on designing for a wide \n88\nrange of people, including those with protected characteristics. We recommend that \ntraining includes: \n \n●Designing coherent, multi-channel services:​ People with protected \ncharacteristics may require alternatives to digital channels, which should \nprovide a comparable experience, including monitoring for protected \ncharacteristics.  \n \n●Designing for opting-out:​ People using a service should have the option to \nprovide or withhold information about their protected characteristics. Their \nchoices should not impact the outcome of the service, for example a person \nchoosing not to share their sexual orientation with the passport service must \nnot be prevented from obtaining a passport. \n \n●Inclusive user research:​ Service designers should be aware of who would \nuse a service and what barriers they could face. Knowing who could be \nexcluded should inform the people and organisations invited to take part in \nrepresentative user research. User research techniques should also prevent \nbias in how information is presented and in the final results. \n85\n ​Open Data Institute (n.d.), ‘Open standards for data’, ​https://standards.theodi.org/  \n86\n ​Cabinet Office, The Rt Hon Matt Hancock MP and The Rt Hon Lord Maude of Horsham (2018), ‘Open standards \nprinciples’, ​https://www.gov.uk/government/publications/open-standards-principles  \n87\n ​Gov.uk (n.d.), ‘Open Standards Board’, ​https://www.gov.uk/government/groups/open-standards-board  \n88\n ​University of Cambridge (n.d.), ‘Inclusive design toolkit’, ​http://www.inclusivedesigntoolkit.com/whatis/whatis.html  \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  23 \n\n \nConduct further research \nOur final set of recommendations is for researchers, and the funders of research, on \nthis topic. \n \nThis report details the findings of a short research project which presents an overview \nof the current landscape in the UK. Further research could be undertaken in a number \nof areas including: \n \n●Are there other examples of monitoring equal access to services? ​We \nhave focused on digital public services in the UK. A broader study could look, \nfor example, internationally, examine practices in the private sector as well as \nthe public sector, and seek to learn more from existing experience in \ninclusive non-digital services. \n \n●What other characteristics should be monitored?​ We have described the \nprotected characteristics defined in the Equality Act 2010. However, these do \nnot include characteristics such as income, region, living situation or \nemployment status, which may also be associated with digital exclusion and \nalgorithmic bias that exacerbates current inequalities. Further research could \nexplore which other characteristics digital public services should monitor. \n \n●What impact does monitoring have on users of a service?​ Collecting data \nto monitor the use of a digital service may put people off using that service. \nThis might be particularly true for people who are already concerned about \ndiscrimination, which could exacerbate any exclusion that already occurs. \nFurther research could examine how the collection of such data changes how \npeople interact with a service, whether and how this can be mitigated \nthrough design, and the degree to which people with different protected \ncharacteristics react differently to this monitoring. \n \n●Can monitoring data be trusted?​ People with protected characteristics may \nbe more likely to opt out of data collection which asks about those \ncharacteristics, leading to biases in monitoring data. In addition, rather than \nopting out, people may provide misleading information when completing \nmonitoring forms (such as always selecting the first option). While there are \nalways uncertainties and biases in any optional, self-reported data, further \nresearch could examine the extent of these problems, help inform design to \nmitigate them, and guide analyses of monitoring data. \n \n●How do people feel about the collection of monitoring data?​ Those who \ncollect and use personal data must always make a decision about the \nbalance between the benefits that data can provide and the privacy impacts \non those the data is about. Clearly some data must be collected to enable \norganisations to demonstrate their compliance with their legal duties. But \nthere are choices to be made about the granularity of that data (for example, \nprecise age or age bracket) and the collection of data outside legally \nspecified protected characteristics. Further research could explore public \nattitudes to the collection of this data, to help guide the design of data \nstandards and guidance. \n \n \n \n  \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  24 \n\n \nConclusion \nMany government services, as well as services provided by charities and private \nsector organisations, have become, or are becoming, digital by default. Access to \nthese often essential services relies on the public knowing how to use websites and \napplications, as well as having access to digital devices and an internet connection. \nBut this cannot always be guaranteed or taken as standard. \n \nNot only is internet access or use not 100%, many people have certain protected \ncharacteristics, protected by equalities legislation, which make it more difficult for \nthem to use the internet; what the ONS describes as ‘digital exclusion’. Furthermore, \nwith the development of digital services that extend technology away from the \ninternet to biometric technology, such as voice or face recognition, the risk of \nexclusion based on algorithmic biases could cause harm we cannot yet fully predict.  \n \nMonitoring who uses digital services is necessary to understand who is excluded, \nand can help service designers make services fairer and more inclusive. Asking about \nthe protected characteristics of service users is a key element of this. Yet we found \nover the course of our research that organisations were concerned about asking \npeople to provide their protected characteristics. Concerns varied from questions \nbeing intrusive, to data collection causing non-compliance with the GDPR and the \nData Protection Act 2018. \n \nService providers should not shy away from understanding who uses their services, \nand people with protected characteristics should have their privacy and dignity \nrespected when it comes to collecting and publishing data. These goals are not \nmutually exclusive. To build trust, service providers must show that they can be \ntrusted to both protect privacy and act on the data they collect. Data protection law \ntakes both these points seriously and provides clear guidance on how to make use of \ndata without harming people’s privacy or security.  \n \nAnonymous, optional data collection, published using good data practice that \nprevents people from identifying themselves in the data or being identified by the \ndata, will help build trust with communities of people who are excluded from using \ndigital services. Providing suitable alternatives for people who are digitally excluded, \nas well as making services fair and inclusive, will ensure that more people can access \nessential services. \n \nOur research shows that it is possible and desirable to collect and publish data about \nwho uses digital services in a way that is safe, secure and respects people’s rights to \nprivacy. This data will enable service providers to demonstrate their Public Sector \nEquality Duty. It will help advocacy bodies, researchers and regulators to hold the \ngovernment to account. And it will help focus and inform improvements to those \npublic services, so that everyone can benefit from them.  \n \nOpen Data Institute 2020 / ReportMonitoring Equality in Digital Public Services​  25 ","version":"1.10.100"}