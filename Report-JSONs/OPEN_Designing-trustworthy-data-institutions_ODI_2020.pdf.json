{"numpages":41,"numrender":41,"info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"Skia/PDF m84"},"metadata":null,"text":"\n\n \n\n \n \n \n \n \n \nContents \nExecutive summary3 \nIntroduction4 \nAn ecosystem of trust6 \nWhat is a data institution trusted to do?6 \nData institutions as trust intermediaries7 \nThe external ecosystem8 \nBeing trustworthy and being trusted10 \nA framework for trust10 \nHow trust breaks down12 \nBeing trustworthy with data14 \nA system of rules14 \nEthical design17 \nOrganisational design18 \nOrganisational governance19 \nThe role of technology21 \nBeing trusted with data23 \nMapping trust mechanisms23 \nThird party trust26 \nAssessing trustworthiness27 \nTrusting others30 \nInvest in capability to take collective decisions30 \nBe fearless, be honest31 \nIf you want to go far, go together31 \nProvide opportunities to re-evaluate following new information33 \nStakeholders’ views can change33 \nData institutions as centres of debate34 \nConclusion and next steps35 \nAreas for further research35 \nSuggestions for those scoping, designing and running data institutions36 \nAppendix A: Methodology38 \nResearch questions38 \nDesk research38 \nInterviews38 \nAppendix B: Map of trust mechanisms40 \n \n  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  1 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nAbout \n \nThis report has been researched and produced by the Open Data Institute, and was \npublished in April 2020. The lead authors are Rachel Wilson and Olivier Thereaux, \nwith contributions from Sonia Duarte, Renate Samson, Jared Robert Keller, Jack \nHardinges and Jeni Tennison. \n \nIf you would like to send us feedback, please get in contact with us at \nresearch@theodi.org​. \n \n \n \nHow can it be improved? We welcome suggestions from \nthe community in the comments. \n \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  2 \n\n \n \nExecutive summary \nIn spring 2019, the Open Data Institute (ODI) released pilot reports concluding that \ndata trusts – new organisational structures providing independent stewardship of \ndata – could be useful in increasing access to data while retaining trust. Data trusts \nare one example of a broader range of data institutions. \n \nData institutions are organisations whose purpose involves stewarding data on behalf \nof others, often towards public, educational or charitable aims. For these institutions \nto achieve this purpose, they need to be both trustworthy and trusted. Some data \ninstitutions, however well intentioned, could fail to operate in an effective and \ntrustworthy way, possibly causing harm. In addition, data contributors and other \nstakeholders need to assess whether they should work with a particular data \ninstitution or not. \n \nThere are some things that a data institution ​must​ do, for example to comply with \nlaws and regulations, but there are others that, while not mandated, will help a data \ninstitution build and maintain trust.  \n \nA trust framework, combined with an understanding of the ecosystem of trust \nsurrounding a typical data institution, can give a clear understanding of what is \nexpected of a data institution, and what mechanisms are available to assess and to \ndemonstrate its trustworthiness. \n \nMany mechanisms and tools are available for data institutions to adopt. And much \nthat is needed to design a trustworthy data institution can be derived from exemplars \nin organisational design and governance elsewhere. Other mechanisms, such as \ncertification programmes for data institutions, need to be developed, tested and \nintegrated in the ecosystem.  \n \nThis exploratory research from the ODI ran in parallel to a related project on \ndesigning ​sustainable ​data institutions. Both projects have highlighted that trust and \n1\nsustainability are deeply connected, requiring strong governance and ongoing \ncommunity engagement. This report does not presume to have all the answers to \nwhat makes a ​good​ data institution, but it provides a way of thinking that will both \nguide new data institutions, and form a basis for future work in this field. \n  \n1\n ​Open Data Institute (2020), ‘Sustainable data institutions’, \nhttps://theodi.org/project/sustainable-data-institutions  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  3 \n\n \n \nIntroduction \nData stewardship involves collecting, maintaining and sharing data, and, in particular, \ndetermining who has access to it, for what purpose and to whose benefit. \n \nHow data is stewarded is important, as it affects what it can be used for and how it \nmay bring benefit or cause harm. Data institutions are organisations whose purpose \ninvolves stewarding data on behalf of others, often towards public, educational or \ncharitable aims. At the ODI, we have been exploring the role of data institutions in \nincreasing access to data. \n \nData trusts are one type of data institution. They provide independent, fiduciary \nstewardship of data. With data trusts, one party authorises another to make \n2\ndecisions about data on their behalf, for the benefit of a wider group of stakeholders. \nThe independent person, group or entity stewarding the data takes on a fiduciary \nduty, which is considered the highest level of obligation that one party can owe to \nanother. \n \nSome data institutions will follow a similar pattern, whereby an organisation, or group \nof organisations, entrusts them to share data with others. Other data institutions will \nplay different roles, such as combining or linking data, and providing benchmarks and \nother insights to the organisations that have contributed to them. \n \nSetting up institutions to steward data can create benefits for organisations, people \nand communities through data being used more widely. But data contributors need \nto be able to determine whether they should share data with or through the data \ninstitution; data users need to know whether to use data from it; and people, \norganisations and communities affected by the data institution need to assess \nwhether to support its operation or campaign against it. These judgements rest on \nthe question: is this data institution trustworthy? \n \nTo explore this topic, the ODI carried out desk research into trust and \ntrustworthiness, and the ways existing institutions make themselves trustworthy and \ntrusted. We also reviewed and built upon our earlier research on data trusts and data \ninstitutions. This was complemented by interviews with representatives from the \nfollowing data institutions: \n \n●Higher Education Statistics Agency (HESA): an official body which \n3\ncollects, analyses and publishes data about higher education in the UK. \nHESA collaborates with higher education providers, such as universities, to \ncollect and curate higher education data sources. Its products are used by \nresearchers and policymakers for transparency, retaining public trust and \ndecision making.  \n●Research Organization Registry (ROR): a community-led project working \n4\nto produce a unique, open, usable and sustainable identifier for every \nresearch organisation in the world. \n2\n Open Data Institute (2020), ‘Data trusts in 2020’, ​https://theodi.org/article/data-trusts-in-2020/  \n3\n Higher Education Statistics Agency (n.d.), ​https://www.hesa.ac.uk/  \n4\n Research Organization Registry (n.d.), ​https://ror.org/  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  4 \n\n \n \n●HiLo Maritime Risk Management: a not-for-profit joint industry initiative \n5\nproviding analysis of shipping data to make the industry safer. Shipping \ncompanies share safety-related data from vessels and HiLo runs it through a \nrisk algorithm, and shares insights with the companies.  \n●OpenCorporates: the world’s largest open database of information about \n6\ncompanies. All of the data on OpenCorporates comes from primary public \nsources, and is used by individuals, journalists, non-governmental \norganisations (NGOs) and companies.  \n●MusicBrainz:​ ​a project to create a collaborative database about artists, \n7\nsongs and albums. Any user can contribute and release the music metadata \nunder open licences. \n  \nThis report presents the results of our initial exploratory research and provides an \noverview for those designing or running data institutions about what to consider in \norder to be trustworthy, how to build and maintain trust, and how to avoid potential \nbreakdowns of trust. \n \nWe start by introducing a framework that describes how trust tends to operate. Using \nthis framework, we can better understand how different mechanisms for building trust \nare designed to work and what aspects of trustworthiness and trust they try to \naddress. \n \nWe then describe what a data institution will be expected to do to achieve its \nobjectives, that is, what makes it worthy of trust. These are primarily related to \nprocesses, capability or legal compliance that are, in the main, directly under the \ncontrol of the institution itself. We also describe what a data institution can do to \ndemonstrate its trustworthiness to other parties, and how to close the gap between \nbeing ​trustworthy​ and being ​trusted​.  \n \nThere are various legal, procedural and technical mechanisms that can be used to \nprovide assurances of trustworthiness throughout a data institution’s lifecycle. We \ndescribe some of these mechanisms in this report. Some of these mechanisms are \nthings a data institution ​must​ do, while others are things a data institution ​should​ do. \n \nWe hope this research will lead to the development of further guidance to support the \neffective adoption of trustworthy practices by new and existing data institutions, and \nto demonstrate their trustworthiness to those who want to use their services. \n \n \n \n  \n5\n HiLo Maritime Risk Management (n.d.), ​https://hilomrm.com/  \n6\n OpenCorporates (n.d.), ​https://opencorporates.com/  \n7\n MusicBrainz (n.d.), ​https://musicbrainz.org/  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  5 \n\n \n \nAn ecosystem of trust \n“Companies do not exist in isolation. To succeed in the \nlong term, directors and the companies they lead need to \nbuild and maintain successful relationships with a wide \nrange of stakeholders.” \n8\n \nTrust is inherently about relationships and communication between people and \norganisations. There are many actors interacting with a data institution who need to \nknow whether it is trustworthy. A data institution needs to demonstrate its \ntrustworthiness to these different people and organisations, and, in turn, needs to \ntrust those people and organisations. \n \nThe role of a data institution will differ depending on its mission; the needs of the \necosystem and community; the number of data contributors and users; the countries \nit operates in; and the sensitivity of the data being managed. \n9\n \nSome data institutions may focus their activities on governing access to data \nprovided by data contributors. But other institutions may be more actively involved \nacross the lifecycle, including collecting, processing, managing and transforming \ndata. These all entail different relationships and commitments. \nWhat is a data institution trusted to do? \nThe different people, communities and organisations that interact with a data \ninstitution will have different expectations of it, depending on the role that they play. \n \nData contributors​ (including individuals mentioned in the data if it contains personal \ndata) need to trust the data institution to govern access to the data, such that it is \nshared and used in accordance with the rules defined by the data institution. This \nmight include taking into account consent and preferences, keeping data secure, \nsafeguarding privacy, protecting the reputation of data contributors, and creating \nvalue and impact from the data. \n \nData users​, and the ​decision makers​ who use the tools and services created from \ninstitution-stewarded data, need to trust the data institution to deal with their \ndata-access requests fairly and equitably, and to supply data in a timely and reliable \nway. They need to trust that the data institution is stewarding the most appropriate \ndata to meet intended uses, in line with the data institution’s purpose, and is being \nopen about its limitations. They also need to trust that the data institution is not going \nto expose them to legal or reputational risks when it provides them with access to the \ndata. \n \n8\n Financial Reporting Council (2018), ‘UK Corporate Governance Code’, \nhttps://www.icaew.com/technical/corporate-governance/codes-and-reports/uk-corporate-governance-code  \n9\n Open Data Institute (2019), ‘Data trusts: lessons from three pilots’, p48, \nhttps://theodi.org/article/odi-data-trusts-report/  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  6 \n\n \n \nThose people, organisations and communities that might be affected by the sharing \nand use of data need to trust: that the institution will only share data with those who \nwill advance the institution’s purpose; and that data is used to benefit them, or at \nleast to do them no harm. They might also trust it to maintain proactive engagement \nwith them, and listen and respond to their views. \n \nFunders ​tend to support data institutions with the aim of encouraging healthy data \necosystems, pursuing philanthropic goals or as part of performing their public \nfunction. Therefore they need to trust the data institution to maximise the economic, \nsocietal or environmental value of the data it stewards, as defined by the data \ninstitution’s purpose. \nData institutions as trust intermediaries \nSome of a data institution’s trustworthiness will depend on other people and \norganisations, including data contributors and data users; it is therefore a trust \nintermediary. \n \nA data institution needs to assess and demonstrate the trustworthiness of one party \non behalf of others to be confident that it can be trusted itself, since a failure to do so \ncan affect its own reputation. This is especially important if any parties are legally \nliable for any negative outcomes or harmful behaviour. A data institution can increase \nthe trustworthiness of these stakeholders in several ways, such as by providing tools \nand training, or through binding their behaviour through formal contracts. \n \nData users need to be trusted to accurately declare what they are intending to do \nwith the data and not to cause harm through their use of it. Data users can be \nmonitored to ensure they are keeping to the terms of any data-sharing agreements. \nThis could include assurances that data is only accessed by those authorised to do \nso; that data is not shared with unauthorised people; and that data is kept secure if it \nis transferred between sites. \n \nData contributors, be they organisations or community volunteers, need to be \n10\ntrusted to provide continued access to good quality-data that is of trustworthy \nprovenance and is useful to the purpose of the data institution. \n \nPeople represented in the data need to trust the data institution – as a representative \nof the data contributors – to: collect only the required data; hold the data securely; \nand delete the data when it is no longer needed. \n \nA data institution will often store data and mediate interactions using technology, so it \nneeds to ensure the trustworthiness of its suppliers, technical solutions, products and \nservices – including algorithms. \n11\n \nFinally, the people, organisations and communities affected by potential uses of the \ndata need to trust the data institution – as a representative of the data users and \ndecision makers – not to cause them harm. \n10\n Open Data Institute (2019), ‘Collaborative data patterns’, ​https://collaborative-data.theodi.org  \n11\n Harvard Data Science Review (2020), ‘Should we trust algorithms?’, ​https://hdsr.mitpress.mit.edu/pub/56lnenzj  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  7 \n\n \n \nThe external ecosystem \nThe trust ecosystem also extends to actors beyond the immediate environment of the \ndata institution: this wider ecosystem includes legislators, regulators, oversight \nbodies, journalists, certifying bodies, insurers, and external bodies offering both \noversight and redress. \n12\n \nDespite best intentions, sometimes things go wrong. These external bodies provide \nassurance that data contributors, data users and the people, organisations and \ncommunities affected by the use of data will be protected. Trust in the external \nenvironment – such as in the effective enforcement of data protection law – gives \nstakeholders confidence to place trust in a data institution. This is one of the ways \nthat trust can be established even when there is little prior evidence for the behaviour \nof a data institution, for example when it is newly established. \n \nAssurance might come from an agreement with the data institution, such that it will \naccept liability or provide redress (see box below), or from the surrounding \nenvironment, such as the ability to take legal action to recover costs or reputation. \nMechanisms such as relevant insurance policies help to provide assurance that the \ndata institution will be able to satisfy any financial commitments this entails. \n \nThroughout this report, we refer to the actors who interact with data institutions \ncollectively as stakeholders, to differentiate them from communities who may be \nimpacted by the use and sharing of data. \n \n \nAccountability, liability and redress \nAn important expectation of a data institution is that it should protect all of its \nstakeholders from harm. A data institution will be responsible and accountable \nfor incidents, whether harms or errors arise intentionally or unintentionally. This \ncan mean being legally liable or enacting redress mechanisms. \n \nLiability or redress don’t intrinsically make data institutions more trustworthy, \nbut they provide confidence that undesirable or damaging situations will be \nremedied if trust is misplaced or something goes wrong. That assurance might \ncome from agreements with the data institution that it will accept liability, or \nfrom an oversight body or authority that is external to the data institution. \n \nAccountability, liability and redress have different legal definitions: \n13\n \nAccountability ​means being available to give an account, rationale or \nexplanation for an action or state of affairs. Sources of accountability can be \n12\n In ways similar to the Financial Services Compensation Scheme (FSCS) for financial institutions. Financial \nServices Compensation Scheme (n.d.), ​https://www.fscs.org.uk/ \n13\n Cornock M (2011), ‘Legal definitions of responsibility, accountability and liability’, \nhttps://www.deepdyve.com/lp/royal-college-of-nursing-rcn/legal-definitions-of-responsibility-accountability-and-\nliability-zkI79QFMtC  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  8 \n\n \n \nlegislative, organisational, contractual or informal. Systems of accountability \n14\nprovide reassurance that the behaviour of an organisation is being monitored \nand controlled. Such systems must be well designed, so as not to introduce \n15\nperverse incentives. \n16\n \nWhen legislation or a contract means that a party is legally answerable to \nanother party, we say they are ​liable​. Failure of a person or entity to meet that \nresponsibility can result in a court judgment. \n \nThe standard contractual penalty is financial damages. However, there are \nsituations where damages are not sufficient, and it may be necessary to compel \nor stop a certain action. These are called ‘equitable remedies’ or ‘​redress​’, and \nrequire clauses to be written into contracts or agreements. Redress functions \nas a restorative force in the ecosystem if something goes wrong, similar to an \ninsurance policy.  \n \nRemedies include: \n●monetary compensation, similar to contractual damages \n●correcting public information, for example, to restore someone’s \nreputation \n●deletion of data shared by a data institution \n●re-running processes that were affected by procedural flaws or bias. \n \nThe ability to seek redress should be easily accessible, responsive, not be \nunduly expensive or time-consuming, and be understandable. Appropriate \nredress for those affected by technology-driven harms is still developing. \nDoteveryone’s ongoing research into better online redress has three \nrecommendations that are relevant to data institutions: \n17\n \n●Define meaningful outcomes for redress, where not all harms are \nfinancial. \n●Develop new structures of redress fit for the scale and pace of online \nservices. \n●Make it easier for people to navigate digital complexity. \n \n \n \n \n  \n14\n McGrath S, Whitty J (2018), ‘Accountability and responsibility defined’, \nhttps://www.researchgate.net/publication/324582377_Accountability_and_responsibility_defined  \n15\n O’Neill O (2018), ‘Assessment, public accountability and trust’, \nhttps://www.cambridgeassessment.org.uk/images/126032-baroness-onora-o-neill.pdf  \n16\n O’Neill O (2002), ‘Reith Lectures 2002: Lecture 3: Called to account’, \nhttp://downloads.bbc.co.uk/rmhttp/radio4/transcripts/20020417_reith.pdf  \n17\n Doteveryone (2019), ‘Seeking redress in the online world – the current challenges’, \nhttps://www.doteveryone.org.uk/2019/12/seeking-redress-in-the-online-world-the-current-challenges  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  9 \n\n \n \nBeing trustworthy and \nbeing trusted \nThe degree to which we trust a person or organisation determines the agreements we \nare willing to enter into with them, and how we act and behave towards them. \n \nThere are various frameworks for describing trust, trustworthiness and what it means \nto be trusted. These frameworks attempt to distil trust into a few components like \n“credibility, reliability, intimacy and self-orientation”, “honesty, competence and \n18\nreliability”, or “rigorous logic, authenticity and empathy”. \n1920\n \nEach trust framework ​starts from the same premise​: that trust involves \ncommunicating and meeting expectations. This can be paraphrased as: ‘I want to be \ntrusted ​to do X​, and I will attempt to demonstrate to others that I am trustworthy. I \ntrust another ​to do Y​, and will attempt to assess that my trust is well placed’. \n \nFor this report, we have drawn especially on a framework developed by Dr Kieron \n21\nO’Hara at the University of Southampton. It is a useful basis for our research because \nit describes trust using components that scale well from interpersonal to institutional \ncontexts, while sidestepping debates about human nature and the role of authorities.\n The framework also explains how being trustworthy is different from being trusted, \n22\nand how the two must be aligned to avoid a breakdown of trust, and offers a useful \nway to reason about where trust can break down. \n \nThis section uses the ecosystem of actors introduced in the previous section to \nsummarise and expand on the framework developed by O’Hara. After introducing a \nnumber of useful concepts and vocabulary, we examine a range of ways that trust \nbetween parties operates and can break down.  \n \nAs the nature of trust is relational, in this section we have used named people ('Alice' \nand 'Ben') to help demonstrate the relationships. \nA framework for trust  \nO’Hara’s framework for trust starts with the notion of trustworthiness. Within his \nframework, a person or organisation is ​trustworthy​ if they do what they have \ncommitted to do. More specifically, they are trustworthy if they are ​able​, ​willing​ and \n18\n Trusted Advisor (n.d.), ‘Understanding the trust equation’, \nhttps://trustedadvisor.com/why-trust-matters/understanding-trust/understanding-the-trust-equation  \n19\n O’Neill O, Bardrick J (2017), ‘Trust, trustworthiness and transparency’, \nhttps://www.thebritishacademy.ac.uk/sites/default/files/Trust-Trustworthiness-Transparency.pdf  \n20\n Frei F (2018), ‘How to build (and rebuild) trust’, ​https://www.ted.com/talks/frances_frei_how_to_build_and_rebuild_trus​ t \n21\nO’Hara K (2012), ‘A general definition of trust’, ​https://eprints.soton.ac.uk/341800/1/ohara_trust_working_paper_aug_2012.pdf  \n22\n Mouritz T (2010), ‘Comparing the social contracts of Hobbes and Locke’, \nhttps://www.murdoch.edu.au/School-of-Law/_document/WA-jurist-documents/WAJ_Vol1_2010_Tom-Mouritz---\nHobbes-%26-Locke.pdf  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  10 \n\n \n \nmotivated​ to act or behave in such a way that makes good on their commitments. \nFurthermore, they are able, willing and motivated to behave this way in specific \ncontexts,​ and to the benefit of a particular ​audience​,​ ​which can include themselves, \nbut will usually be others. \n \nThe framework further distinguishes between being ​trustworthy​ and being ​trusted​. \nThe main difference is that ​being trusted​ is relational and involves an assessment by \nanother party. For example, ‘Ben’ must believe ‘Alice’ to be trustworthy before he \nplaces his trust​ in her. He must judge Alice’s ability, willingness and motivation to do \nas he expects her to do; the two need a common understanding of the boundaries of \nthe context in which Alice operates and the audience she intends to benefit from her \nactions; and he needs to correctly interpret all her behaviours as ultimately benefiting \nthat same audience.  \n \nIf Alice is unable to adequately demonstrate to Ben that she is trustworthy, or if Ben \nis unable to adequately assess whether Alice can indeed be trusted, then trust might \nnot be given when it is deserved. Or trust might be given when it is not warranted, for \ninstance if Alice is not as trustworthy as she claimed or if Ben doesn’t accurately \nassess her trustworthiness. As we will describe later, trust can also break down after \nit is given. \n \n \nComponents of trust \nO’Hara’s framework describes the components of trust; here we summarise \nhow they apply to data institutions. \n \nAbility, willingness and motivation \nAlice’s ability to do as she claims is fundamental to her trustworthiness. But in \norder to act, as well as being favourable to an idea, she also needs an intrinsic \nor extrinsic reason or incentive. For example, if Alice is a medical researcher, \n23\nshe may be ​able ​and ​willing​ to share her research findings, but until she is \nmotivated​ by the prospect of collaboration, she will delay doing so. \n \nA data institution’s ​ability ​to steward data on behalf of others depends on its \naccess to technology, resources and funding. It must also be ​willing ​to steward \ndata on behalf of others, by having it as part of its vision or mission. It may also \nhave a mix of positive and negative ​motivations,​ such as contributing towards a \nsocietal goal, or a legal compulsion. \n \nContext \nPeople are not equally able, willing or motivated in all circumstances. Instead, \nAlice’s context is the specific circumstances in which she claims to be \ntrustworthy, for example teaching mathematics, providing advice during office \nhours, or carrying out research into heart disease. Context might be extremely \nprecise, such as described in a contract. Or it might be informally assumed \nthrough social norms, or have to be clarified over time, for example through \ncase law. \n \nA data institution’s context will depend on its role within the ecosystem, the type \n23\n Bénabou R, Tirole J (2003), ‘Intrinsic and extrinsic motivation’, ​https://www.princeton.edu/~rbenabou/papers/RES2003.pdf  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  11 \n\n \n \nof data, and the domain. It could include aspects of data management, and \ncontrol of how data is used. The limits and expectations of the circumstances in \nwhich a data institution should be trustworthy are broadly defined and still \nevolving. \n \nAudience \nAlice’s audience are those who she anticipates will benefit from her \ntrustworthiness. Her promises will sometimes be precisely targeted to certain \nindividuals or groups. At the very least, Alice’s audience would reasonably \nexpect not to be harmed as a result of her behaviour. \n \nThe target audiences for a data institution’s trustworthiness will include all the \nactors within its ecosystem, as well as those using the insights, products and \nservices that it enables; and people, organisations and communities affected by \nthe sharing and use of the data it stewards. The diversity of these audiences \nadds complexity to the challenge of being trustworthy and trusted. \n \nActions, behaviours, claims and commitments \nAlice may make claims or commitments about how she is willing, able and \nmotivated to behave to serve the interests of the audience she is targeting. \nThese might be open-ended or quite precise claims. \n \nThese claims may be open to interpretation. For example, a data institution may \nbe very precise about the goal it is working towards, but it may give itself leeway \nin how it achieves this. \n \nAs claims become more explicit, they begin to resemble a contract. But it may \nbe that expectations of behaviour are defined by unwritten, implicit social \nnorms; being a ‘good steward’ implies a lot of things and raises a lot of \nexpectations, but is very open-ended.  \n \nA data institution represents itself as being willing, able and motivated to carry \nout stewardship duties on behalf of others. How it is expected to behave may be \ndefined in contracts, but there will also be an implicit expectation that their \noperation will not cause harm to their audience. \nHow trust breaks down \nThe trust framework outlined above is a useful way of pinpointing and describing the \nvarious components of trust and the calculations that often go into determining \nwhether or not a person or organisation can be trusted to do what they have \ncommitted themselves to do. Crucially, the framework also offers a means of \nanalysing the different ways that trust can be lost, broken or diminished.  \n \nMisrepresentation \n \nIt may be that Alice makes a ​misrepresentation​ (of her ability, willingness, etc). This \nis where we look for evidence to root out bad actors, dishonesty, incompetence or \nunreliability. But it might also be that Alice underestimates her own abilities and is \nmore trustworthy than she declares. Whether positive or negative, intentional or \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  12 \n\n \n \nunintentional, misrepresentations mean that Ben’s trust in Alice is misaligned with \nwhat is warranted. \nAn example of​ misrepresentation​ of a data institution’s ability might be if it provides \ndata contributors with assurances about data protection, but does not have good \nsecurity measures in place, which comes to light when it suffers a data breach. \n \nMisunderstanding \n \n ​It may be that Alice and Ben have a ​misunderstanding​. This arises when there is a \nfailure of communication such that Alice and Ben have different interpretations of the \ncontext, audience or expected behaviour. Again, misunderstandings can mean that \nBen places the wrong level of trust (too much or too little) in Alice. \nA ​misunderstanding​ of the audience could arise when a data institution claims to \nhave a social benefit purpose, such as improving healthcare, and furthers that \npurpose by sharing data with private sector organisations, such as pharmaceutical \ncompanies. The data institution may see their purpose at a system level, and the \ndevelopment of new drugs as ultimately contributing to better healthcare. But data \ncontributors may have a narrower view, and see companies making profit through \nusing data about them as unacceptable. \n \nInability to determine \n \nIt may be that Ben is ​unable to determine​ sufficient evidence to decide how much \ntrust to place in Alice. This lack of evidence may raise the risk for Ben, of both \nmisrepresentations and misunderstandings, such that he errs on the side of caution. \nIf Alice is indeed trustworthy, this results in an opportunity cost of not entering into an \nagreement that could otherwise have been mutually beneficial. It is therefore \nimportant for Alice to produce sound evidence of her ability, willingness and \nmotivation (reducing the risk of misrepresentation), and clarity about her context, \naudience and expected behaviour (reducing the risk of misunderstanding). \nA stakeholder might be ​unable to determine​ how much to trust a data institution if it \ncannot get access to information about the sources of the data it stewards, or the \nprocess through which requests for access are granted. \n \nFailure to communicate changes \n \n ​It may be that Alice ​fails to communicate changes in circumstances​. Her ability \nmay be hindered, or Alice’s context or audience – and therefore behaviour – changes \nin ways Ben is unaware of or didn’t expect. Ben’s expectations may no longer be \naligned with Alice’s reality. It is important that Ben is given the opportunity to \nre-evaluate how much trust to place in her, and revise any agreements he has \nentered into with her. \nA ​failure to communicate a change in circumstances​ might arise if a data \ninstitution is absorbed into, or spun out of, another organisation and this is not \ncommunicated clearly; or if new data contributors or data users enter into \nagreements with the data institution, particularly if those organisations have poor \nreputations. \n  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  13 \n\n \n \nBeing trustworthy with \ndata \n“The trustworthiness of a data institution is a product of the \npeople, systems and processes that enable and support \ntrustworthy stewardship of data.” \n24\n \nBeing trustworthy with data is not the same as being trusted with data. When we talk \nabout the trustworthiness of data institutions, we are primarily looking at internal \nprocesses, capabilities or legal compliance related to how a data institution will \nreliably deliver on what it promises.  \n \nWhen we talk about a data institution being trusted, on the other hand, we are \nlooking at what a data institution can do to demonstrate its trustworthiness to other \nparties, to ensure those parties are able to assess its trustworthiness and so decide \nwhether they can trust it to steward important data.  \n \nThe following two sections of this report examine these two related topics, starting \nwith how to be trustworthy with data. This section ends with a discussion of things a \ndata institution ​should ​or ​may​ do, but we start with what a data institution ​must​ do in \norder to be trustworthy with data. \nA system of rules \nAs a foundation, a trustworthy data institution is expected to follow a system of rules. \nRules such as laws, regulations or codes of practice define the ​behaviours​ expected \nof a data institution. In some cases, the rules stipulate what the data institution is ​not \nallowed to do. As well as motivating a data institution to act in a trustworthy way, this \nsystem of rules provides a base set of criteria that defines what it ​means​ to be \ntrustworthy with data, against which we can judge whether a data institution has \ndone what it must do. \n \nThese rules may be mandated by the data institution’s environment, stated by the \ndata institution itself, or may be implicit because of social or industry norms. \n \nLaws and regulations \n \nLaws and regulations define the ​behaviours​ expected of a data institution by an \nauthorising body. Some laws and regulations are principle based, rather than being \nproscriptive, and therefore are intended to encourage or stimulate, rather than \nproscribe. The promise of rewards (such as tax breaks) or the threat of penalties or \npunishments can increase a data institution’s ​motivation​ to comply. \n \n24\n Paraphrased from UK Statistics Authority (2018), ‘Code of Practice for Statistics’, \nhttps://www.statisticsauthority.gov.uk/code-of-practice  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  14 \n\n \n \nData institutions should have a good understanding of the duties and powers set out \nin legislation and regulation, and ensure these are applied in its governance and \nmanagement. Referring to specific legislation and oversight bodies in terms and \nconditions, and policy statements both informs stakeholders of their rights, and \ndemonstrates that the data institution is aware of, and is adhering to, legislation. \nLegislation relevant to data institutions in the UK includes: \n \n●Data Protection Act 2018: includes the General Data Protection Regulation \n25\n(GDPR) and is applicable to a data institution stewarding personal data. \n●Consumer Rights Act 2015: includes rights for the consumer regarding \n26\ndigital content, including in relation to services provided for free. \n●Equalities Act 2010: mandates against discriminatory practices so that a \n27\ndata institution provides equal access to users. \n●Protection of Freedoms Act 2012: relevant to data institutions collecting \n28\ndata such as CCTV footage. \n●Digital Economy Act 2017: addresses data sharing across government \n29\nincluding statistical information and a range of media, internet and mobile \nphone laws. Outlines some of Ofcom’s (Office of Communications) oversight \nrequirements. \n●UK Copyright and Rights in Databases Regulations 1997: describes \n30\nintellectual property rights in databases and other content. \n \nContracts \n \nLegally enforceable contracts help align different parties’ expectations in several \nrespects: they define expected ​behaviour​, clarify the bounds of the ​context​ of a data \ninstitution, and may specify its ​audience​. Contracts greatly reduce the risk that these \naspects will be misunderstood by parties. Penalties for breaking the terms of a \ncontract increase a data institution’s ​motivation​ to follow the rules it agreed to. \n \nPenalties \n \nThe threat of penalties, sanctions, fines and punishments gives us confidence that a \nperson or organisation will be ​motivated​ to comply with rules because they will incur \na sufficient cost if they do not. It is, however, necessary to trust in the external \nenforcement system, whether that be legal, regulatory or reputational. Whereas \npenalties are supposed to dis-incentivise harmful behaviour, redress is designed to \nprovide recompense to any harmed parties. See ‘Accountability, liability and redress’ \nabove. \n \nLegal agreements and laws define expected behaviour that has the backing of an \nexternal enforcement authority. However, there are other voluntary rules defining \ntrustworthy behaviour that have been developed for self-guidance, to meet a need, or \nthat codify community expectations. \n \n \n \n25\n UK Parliament (2018), ‘Data Protection Act’, ​http://www.legislation.gov.uk/id/ukpga/2018/12  \n26\n UK Parliament (2015), ‘Consumer Rights Act’, ​https://www.legislation.gov.uk/id/ukpga/2015/15  \n27\n UK Parliament (2010), ‘Equalities Act’, ​http://www.legislation.gov.uk/id/ukpga/2010/15  \n28\n UK Parliament (2012), ‘Protection of Freedoms Act’, ​https://www.legislation.gov.uk/id/ukpga/2012/9  \n29\n UK Parliament (2017), ‘Digital Economy Act’, ​https://www.legislation.gov.uk/id/ukpga/2017/30 \n30\n Cooley Go, ‘What you need to know about UK database rights’, \nhttps://www.cooleygo.com/what-you-need-to-know-about-uk-database-rights  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  15 \n\n \n \nStandards \n \nStandards are documented, reusable agreements that are used for consistency, to \nenable processes to be replicated, to make comparisons, or to reach a shared \nunderstanding. They include technical definitions, data formats, specifications for \n313233\nquality standards and management processes. If we know something complies with \n34\na standard, we can be confident how it will ​behave​. \n \nIn some industries, compliance with some standards will be expected, if not \nmandated by regulation. In other cases, implementing a standard may be voluntary \nas a way of improving an internal process, or to make it easier for others to interact. \n \nAn accredited body can certify compliance with a standard as a measure of \nassurance, although it is not always necessary. \n \nPolicies, processes, principles and codes \n \nDeveloping and publishing policies, codes of conduct, or lists of principle or values \nsignal a data institution’s ​willingness​ to ​behave​ in a particular way. Examples \ninclude: \n \n●ORCID’s organisational principles set out its ways of working to create a \n35\ntrustworthy, sustainable data infrastructure. \n●Council of Europe’s 12 Principles of Good Governance describe the \n36\nresponsible conduct of public affairs and management of public resources.  \n●The Code of Practice for Statistics aims to ‘provide the framework to ensure \n37\nthat statistics are trustworthy, good quality and valuable’.  \n●The Chartered Institute of Auditors’ codes of professional conduct and ethics\n aim to raise the professionalism of internal auditing. \n38\n \nNorms \n \nNorms are implicit or ‘unwritten rules’ of ​behaviour​ typically determined by social or \ncultural convention. Sometimes norms become codified as guidelines, standards or \n39\ncodes, especially in growing communities where new members need to learn the \n40\ncommunity’s norms in order to participate successfully.  \n \nExamples of norms include user experience (UX) practices; vocabulary; what is meant \nby terms like ‘respectful’ or ‘doing the right thing’; and what might be considered \nproportionate or fair use of data. \n31\n Open Data Institute (2018), ‘Open standards for data’, ​https://standards.theodi.org  \n32\n Wikipedia (2020), ‘USB standard’, ​https://en.wikipedia.org/wiki/USB  \n33\n Office for National Statistics (2020), ‘Data standards’, \nhttps://www.ons.gov.uk/aboutus/transparencyandgovernance/datastrategy/datastandards  \n34\n International Organization for Standardization (2020), ‘ISO-27001: Information security management’, \nhttps://www.iso.org/isoiec-27001-information-security.html  \n35\n ORCID (2011), ‘Our principles’, ​https://orcid.org/about/what-is-orcid/principles  \n36\n Council of Europe (2020), ‘12 principles of good governance and ELoGE’, \nhttps://rm.coe.int/12-principles-brochure-final/1680741931  \n37\n Office for Statistics Regulation (2018), ‘Code of Practice for Statistics’, \nhttps://www.statisticsauthority.gov.uk/code-of-practice  \n38\n Chartered Institute of Auditors (2020), ‘Our standards and ethics’, \nhttps://www.iia.org.uk/about-us/our-standards-and-ethics  \n39\n Kalkman S, et al (2019), ‘Responsible data sharing in international health research: a systematic review of \nprinciples and norms’, ​https://bmcmedethics.biomedcentral.com/articles/10.1186/s12910-019-0359-9  \n40\n Open Data Commons (2020), ‘Community norms’, ​https://opendatacommons.org/norms/odc-by-sa.1.html  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  16 \n\n \n \n \nBecause norms are usually unwritten and can evolve over time, they make it difficult \nto establish or determine trustworthiness. It is easy to unintentionally make a mistake \nor misinterpret others, especially for those new to a community or domain. Although \nthe ‘penalties’ for not following established norms are likely to be social or \nreputational, rather than legal or financial.  \nEthical design \nRules define explicit, externally defined and enforced expectations of a data \ninstitution, but many of the expectations of how a data institution should steward \ndata are informal and implicit. The rapidly changing context in which a data \n41\ninstitution operates – in particular with regard to increasing capability of technology, \navailability of data, and awareness of potential harms caused by data misuse – \nmakes it hard to determine fixed rules. \n \nJust as the rules and regulations recommend that organisations working with data \nshould build in privacy and security by design, data ethics should be built in by \n42\ndesign into every organisation stewarding data, typically through the publication of \nethical principles, and embedding those principles into processes and practice. \n \nEthical principles and values outline how an organisation ideally ​wishes​ to ​behave​, \nand what it is not ​willing​ to do, often to protect specific ​audiences​. Publishing \nprinciples and values could be taken as a sign of intrinsic ​motivation​. \n \nEthical principles should be developed collaboratively so that they capture the \nexpectations of a data institution’s audiences. Once published, they can be used to \nhold the data institution to account.  \n43\n \nHowever, what people perceive to be ethical and unethical use of data is rapidly \nevolving, and codes of practice are likely to quickly go out of date. This means data \nethics principles need to be practical, and need to evolve.  \n \nPrinciples and values can also be difficult to put in practice: they can be too vague to \noffer clear guidance for day-to-day decisions.  \n \nPractical ethical systems and processes can be developed early in the organisation’s \nlifecycle, and embedded into organisational design, governance practices and \nprocesses, and the way the data institution develops products and services. \n44\n \nMany practical data ethics tools exist, including Doteveryone’s Consequence \nScanning, the Data Ethics Self Assessment tool by the UK Statistics Authority and \n4546\n41\n Open Data Institute (2020), ‘Building trust in how you handle data: a hierarchy’, \nhttps://theodi.org/article/building-trust-in-how-you-handle-data-a-hierarchy \n42\n For example, Information Commissioner’s Office (2018), ‘Data protection by design and default’, \nhttps://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gd\npr/accountability-and-governance/data-protection-by-design-and-default \n43\n Raji I, et al (2020), ‘Closing the AI accountability gap: defining an end-to-end framework for internal algorithmic \nauditing’, ​https://arxiv.org/abs/2001.00973  \n44\n NowNext Design (2017), ‘Ethical design sprints’, ​https://www.cennydd.com/ethical-design-sprint-schedule  \n45\n Doteveryone (2019), ‘Consequence scanning’, \nhttps://www.doteveryone.org.uk/project/consequence-scanning  \n46\n UK Statistics Authority (2019), ‘Ethics self-assessment’, \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  17 \n\n \n \nthe ODI’s Data Ethics Canvas. Most of these tools include guidance on identifying \n47\nwho may be affected by the stewarding or use of data, and recommend engagement \nwith stakeholders and those affected by the use of data, particularly in the event of \nsomething going wrong. \nOrganisational design \nOrganisational design is the process of aligning the structure of an organisation with \nits objectives, with the aim of improving efficiency and effectiveness. It includes, for \n48\nexample, the business model, revenue model, and legal and corporate structures.  \n49\n \nA data institution needs to ensure sustainable organisational and financial ​ability​ to \nimplement good governance and deliver on its purpose. Certainly “crises of financial \nsustainability (or challenges of expansion) for these organisations are often coupled \nwith or lead to a crisis in governance and/or community trust”. \n50\n \nAll five of the experts we interviewed for this report highlighted the relationship \nbetween trust and organisational sustainability. Issues of trustworthiness that they \nassociated with sustainability included fitness of technical systems; data protection; \ncreating high-quality and useful data; and building a sense of community. For \nexample, the representative from MusicBrainz said, “[A culture of honesty] builds \ntrust, and this trust builds sustainability”. \n \nIn some cases, the structure of an organisation expresses ​willingness​ and \nmotivation​ to act in its stakeholders’ interests over and above a profit motive. For \nexample, after several years of operation, OpenCorporates created the \nOpenCorporates Trust to oversee their public interest purpose: “[our corporate \n51\nstructure] ensures we’ll always be independent and always act in the public interest \nand follow the rules that we’ve set ourselves”. \n \nLegal forms, such as trusts, charities, community interest corporations, and industrial \nand provident societies, are organisational structures that legally enshrine social \n52\nobjectives rather than financial duty to shareholders. But it is not as simple as \nchoosing a not-for-profit structure. For some data institutions, a commercial or \nprofit-driven business model might interfere with the types of value they are trying to \ndeliver, whereas for others, a commercial focus might enable them to invest more in, \nand maximise the value from, their services. \n53\n \nhttps://www.statisticsauthority.gov.uk/about-the-authority/committees/nsdec/data-ethics/self-assessment-2  \n47\n Open Data Institute (2019), ‘The data ethics canvas’, ​https://theodi.org/article/data-ethics-canvas  \n48\n University of Southampton (n.d.), ‘Organisational development & design explained’, \nhttps://www.southampton.ac.uk/hr/services/od-explained/index.page  \n49\n  Osterwalder A, Pigneur Y (2010), ‘Business model generation: a handbook for visionaries, game changers, and \nchallengers’, \nhttps://www.wiley.com/en-gb/Business+Model+Generation%3A+A+Handbook+for+Visionaries%2C+Game+Cha\nngers%2C+and+Challengers-p-9780470876411  \n50\n Bilder G, Lin J, Neylon C (2015), ‘Principles for open scholarly infrastructure’, \nhttps://wiki.lib.sun.ac.za/images/f/f6/2015-principle-for-open-scholary-communication-infrastructures.pdf \n51\n OpenCorporates (2018), ‘Announcing the OpenCorporates Trust’, \nhttps://blog.opencorporates.com/2018/06/11/announcing-the-opencorporates-trust  \n52\n GOV.UK (2011), ‘Legal forms for social enterprise: a guide’, \nhttps://www.gov.uk/government/publications/legal-forms-for-social-enterprise-a-guide  \n53\n Open Data Institute (2020), ‘Designing sustainable data institutions’, \nhttps://theodi.org/project/sustainable-data-institutions  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  18 \n\n \n \nConsidering different audience’s ethical expectations could affect the organisational \ndesign and governance of the data institution. Kieron O’Hara’s paper ‘Data trusts: \nethics, architecture and governance for trustworthy data stewardship’ explains: “Not \nall [audiences] can be pleased all at once. The purpose of the data trust should \nrealistically be to benefit one or two of these [classes of audience]. The rules and \nethical principles of the trust should be tailored to create the optimal signals of \ntrustworthiness to those classes.” For example, an organisation designed primarily \n54\nto be trusted by data contributors might emphasise corporate structures that enable \nindependent stewardship; whereas one designed to primarily create trust among \nindividuals mentioned in the data might de-emphasise business models that depend \non sharing data with third parties. \n \nIndependent stewardship is necessary for some data institutions such as data trusts,\n to ensure trustworthy decisions about data access. They can demonstrate their \n55\nindependence by screening out conflicts of interest; recruiting a diverse board; and \nchoosing a funding model that doesn’t override the data institution’s purpose. \n \nThe ODI’s research into sustainable data institutions identified tensions in relation to \n56\nsome common institutional goals that would influence the organisational structure \nand funding. For example, charging data users to access data creates tension by \nincentivising the data institution to share data with more users in order to secure \ngreater revenue. Resolving these tensions is necessary to align the expectations of \ndifferent stakeholders, without which there is risk of losing their trust. \nOrganisational governance \nGovernance practices attempt to align the interests of stakeholders and define \n57\nwhich ​audiences​ benefit from the data institution’s operation and how. Publishing \ngovernance materials, such as charters or terms of reference, provides clarity and \ntransparency about the activities and behaviours that stakeholders should expect. \n \nGood governance helps a data institution be more trustworthy by setting rules for \nitself and designing internal structures and processes to ensure those rules are \nfollowed, usually in a way that is transparent to stakeholders. As such, governance \nassures, controls and communicates a data institution’s ​behaviour​; as well as its \nability​ and ​willingness​ to act towards its stated purpose. \n \nA data institution’s governance model needs to be appropriate to its operating \ncontext and for whom it needs to build trust. Research from Nesta suggests two axes\n that could influence governance models for data institutions stewarding personal \n58\ndata. One axis represents how much control or choice the individual has in \ndetermining how data is shared and used; and the other is whether value from using \nthe data is public (benefiting everyone) or private (benefiting data users).  \n54\n O’Hara K (2019), ‘Data trusts: ethics, architecture and governance for trustworthy data stewardship’, \nhttps://eprints.soton.ac.uk/428276  \n55\n Open Data Institute (2019), ‘Data trusts: lessons from three pilots’, \nhttps://theodi.org/article/odi-data-trusts-report \n56\n ​Open Data Institute (2020), ‘R&D: Sustainable data institutions’ \nhttps://theodi.org/project/sustainable-data-institutions \n57\n Organisation for Economic Co-operation and Development (2004), ‘G20/OECD principles of corporate \ngovernance’, ​http://www.oecd.org/corporate/principles-corporate-governance  \n58\n Nesta (2019), ‘The new ecosystem of trust’, ​https://www.nesta.org.uk/blog/new-ecosystem-trust  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  19 \n\n \n \n \n \nSource: Nesta | The new ecosystem of trust \n \nWhere a data institution sits on these two axes determines its institutional \ngovernance. For example, a data institution that stewards data where individuals \nhave little control over data sharing – and the data should benefit everyone – will \nrequire people in accountable roles who can explain why particular data sharing \nchoices are made. In contrast, data institutions that create both public and private \nvalue, and where control is by individual consent, may better suit governance with \nnetworked trust relationships and collective decision-making similar to a \nco-operative. \n59\n \nGuidance for publicly run organisations, such as the UK Corporate Governance \n60\nCode, covers themes related to trust and is therefore relevant to data institutions. In \n61\nterms of the trust framework we have built on in this report, the guidance talks about \nhow to: \n \nEstablish the data institution’s ​context​, and how its ​behaviour​ in this context \ncontributes to its objectives \nfor example, by aligning company culture with a clear purpose and strategy, and \nexplaining the rationale for actions the company takes with consistency. \n \nEnable ​ability​ to maintain long-term sustainable success and achieve wider \nobjectives  \nfor example, by recruiting an effective board, and ensuring they have the necessary \ntime, resources and information available for the company to meet its objectives. \n \nDemonstrate ​willingness​ and ​motivation​ to be trustworthy  \nfor example, by ensuring and publicising how workforce policies and practices are \nconsistent with the company’s values. \n59\n Hafen E (2019), ‘Personal data cooperatives – a new data governance framework for data donations and \nprecision health’, ​https://link.springer.com/chapter/10.1007/978-3-030-04363-6_9  \n60\n Department for Transport (2018), ‘Ports good governance guidance’, \nhttps://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/684839/ports\n-good-governance-guidance.pdf  \n61\n Financial Reporting Council (2018), ‘UK Corporate Governance Code’, \nhttps://www.icaew.com/technical/corporate-governance/codes-and-reports/uk-corporate-governance-code  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  20 \n\n \n \n \nGive wide-ranging consideration to diverse ​audiences​, including those who \nshould benefit from, and those affected by, use of data  \nfor example, by establishing a board with diverse perspectives and giving regard to \nthe interests of, and relationships with, employees, suppliers, customers, the wider \ncommunity and the environment. \n \nEnable stakeholders to make ​informed judgements​ about the data institution’s \ntrustworthiness  \nfor example, by setting high standards of transparency, and by using a variety of \nengagement approaches to communicate meaningfully and consistently with \nstakeholders. \n \nTo be trustworthy, data governance and oversight should also extend beyond internal \nprocesses and data access to include how the data is used. It will almost certainly \n62\nextend to the way in which data users use and onwardly share the data that has been \nshared with them. Depending on the design and function of the data institution, it \nmay also extend to how data contributors manage, use and share data themselves. \nTechnology has some role to play in monitoring adherence to the rules created by the \ndata institution. \nThe role of technology \nTechnology is mainly used to bolster a data institution’s ​ability​ to keep to its data \nsecurity commitments. Anonymisation techniques, for example, can help reduce the \nrisk of re-identification of data subjects. Security techniques, access control and \n63\nlogging mechanisms help restrict and monitor access to data. \n \nThe methods of data access and data formats should be reliable, sustainable and \nnon-prohibitive in terms of cost and complexity to be considered trustworthy by \nthose data users who are permitted access. \n“ \nBecause trust is embedded in our social relationships \nand our relationships with technological systems,  \nthese are the areas policymakers must pay more \nattention to, in addition to data privacy and security \nissues.​\n59 \n \nResearch from the University of Manchester cautions against viewing new digital \nservices simply as new means of providing the same personal service. It suggests \n64\nthat we broaden the conversation around trust in technology beyond issues of \nprivacy, security and data sharing, and consider its potential to disrupt the trusted \n62\n Tzovaras B (2019), ‘Alternative personal data governance models’, ​https://osf.io/preprints/metaarxiv/bthj7  \n63\n Open Data Institute (2019), ‘Anonymisation and open data: an introduction to managing the risk of \nre-identification’, ​https://theodi.org/article/anonymisation-report \n64\n Ribeiro B (n.d.), ‘Beyond privacy and security: opening-up ‘trust’ in digital healthcare’, \nhttps://policyatmanchester.shorthandstories.com/on-digital-trust/index.html#group-Trust-in-Healthcare-RDrtklFazP \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  21 \n\n \n \nrelationships between people. For example, in the relationships between patients and \ncaregivers, technology can change how and where care takes place, producing new \nforms of communication and attributing responsibility to new points of contact. \n \nComplex social issues like this mean data institutions might need to make efforts to \nbe trusted in new ways. The next section discusses measures and mechanisms to \nmediate some of the relationships inherent in trust. \n \n \n  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  22 \n\n \n \nBeing trusted with data \nAs we saw in the section ‘​How trust breaks down​’, there are several ways \nstakeholders’ trust in a data institution can be undermined. Many mechanisms have \nbeen developed to help people and organisations overcome these potential failures, \nand to bridge the gap between the understanding of those involved in a data \ninstitution and those who are trying to judge whether that institution can be trusted. \n \nSome of these mechanisms are intended to help people or organisations be more \ntrustworthy, such as by undergoing training; some are designed to help people or \norganisations be more trusted, for example by publishing the minutes of meetings \nwhere decisions are made. Often mechanisms have a dual function, for example \nstudying for an exam both teaches someone the material, and demonstrates to \nothers that they have attained a certain level of qualification. \n \nSome of the measures will be implemented by the data institution itself, such as \nperformance monitoring or drafting data sharing agreements; others are carried out \nby external actors to provide assurance, such as auditing and certification. \n \nDifferent mechanisms will address potential misunderstandings or misrepresentations for \ndifferent components in the framework. For example, interviews are a way to interrogate \nsomeone’s abilities; drafting licences is a way to avoid misunderstandings about how \ndata can be used in different contexts; and kitemarks help people determine how a data \ninstitution should behave in accordance with which quality standards. \n \nUnderstanding how these mechanisms relate to the trust framework, as introduced in \nthe previous section of this report, can help data institutions use them more \neffectively to strengthen trustworthiness and build trust. \nMapping trust mechanisms \nDrawing on our desk research and interviews, we identified a number of common \nmechanisms used by and between organisations to demonstrate or assess \ntrustworthiness. We conducted a mapping exercise taking these various mechanisms \nand distributing them across a matrix with (i) the specific elements of trustworthiness \n(ability, willingness, etc) on one axis; and (ii) the possible ways trust can break down \n(misrepresentation, misunderstanding or the failure to communicate in times of \nchange) on the other axis. The result of the mapping exercise is presented in \nAppendix B: Map of trust mechanisms​. \n \nWhile the mapping exercise is not authoritative or comprehensive, it reveals a number \nof insights. The main one is that ​there are gaps where no standard mechanism \nexists​; the gaps suggest areas where trust can easily break down. For example, it is \nnot easy to prove one’s motivations. \n \nThe second insight is that ​there is no panacea: ​we did not find any mechanism \nwhich would help prevent all possible ways trust can break down, nor did any \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  23 \n\n \n \nmechanism appear to cover all the elements of the trust framework. Most \nmechanisms address one or two potential failure points.  \n \nA notable exception is the use of contracts,​ ​which define expectations of behaviour, \ncontext and, in some cases, how benefit is to be distributed to the intended \naudience. Audits also address several aspects: defining and verifying a data \ninstitution’s ability or behaviours, and acting as evidence: if a data institution passes \nan audit, you can expect them to meet a certain standard of ability or behaviour. \n \nCommunication and transparency \n \nA further insight surfaced by the mapping exercise was a lack of standard \ncommunication mechanisms. Although many mechanisms are designed to root out \nmisrepresentation, a significant proportion of breakdowns of trust are caused by \nfailures of communication – either to align understanding or to communicate changes. \nBut we identified very few standard mechanisms to address this type of problem. \n \nSome mechanisms such as contracts or reports are themselves forms of \ncommunication. But effort to align understanding is particularly important between \nparties that aren’t covered by contracts or other more formal mechanisms. In these \ncases, proactive communication is vital. \n \nWe can learn from the case of data sharing between the Royal Free Hospital and \nDeepMind. The Royal Free Hospital shared patient data with artificial intelligence (AI) \ncompany DeepMind, which was developing an app to help detect patients with acute \nkidney injury. The Information Commissioner’s Office ordered an audit of the app after \nwidespread concerns from patient groups about the scale and scope of the project – in \nother words, the ​context​ and ​behaviours​ were not what the patients expected. In \nresponse, DeepMind resolved to increase and improve communication around future \nwork. \n65\n“ \nExplanations are a positive opportunity to \ncommunicate, not an onerous obligation. \n66\nA data institution needs to consider communication in several respects: \n \n●Demonstrate it has considered and addressed all the ways it needs to prove \nits trustworthiness. \n●Ensure all parties have a shared understanding of the data institution’s \ncontext or purpose; of how behaviours and activities relate to the purpose of \nthe data institution; and who will benefit from those activities. \n●Explain changes to circumstances that may change that shared \nunderstanding. \n65\n DeepMind (2017), ‘The Information Commissioner, the Royal Free, and what we’ve learned’, \nhttps://deepmind.com/blog/announcements/ico-royal-free  \n66\n Financial Reporting Council (2018), ‘UK Corporate Governance Code’, \nhttps://www.icaew.com/technical/corporate-governance/codes-and-reports/uk-corporate-governance-code  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  24 \n\n \n \n \n \nIntelligent transparency \nTransparency is common to many mechanisms where sharing or publishing \nevidence helps others make informed judgements. For example, publishing a \nrecord of decisions made by a data access board helps others determine if \ndecisions are being made in the interest of the expected audience. \n \nOnora O’Neill cautions against transparency for transparency’s sake, since \n67\n“increasing transparency can produce a flood of unsorted information and \nmisinformation that provides little but confusion unless it can be sorted and \nassessed”. \n \nInstead, O’Neill advocates for ‘intelligent transparency’ and says that \ninformation should be: \n \n●accessible – people should be able to get at it \n●comprehensible – people should be able to understand it \n●useable – it should suit their needs \n●assessable – interested parties should, if necessary, be able to examine \nthe workings and assess its quality. \n \nThis view is echoed by David Pozen, who also cautions that “transparency \n68\nmandates hold complex processes to unrealistic standards” and “there is \nnothing incoherent about transparency policies yielding positive outcomes in \ncertain settings and negative or even opposite outcomes in other settings”.  \n \nPozen advises careful consideration of transparency’s relationship to \ngovernance goals, such as constructive deliberation, and advises implementing \nthe means of transparency in service to each goal.  \n \nMechanisms throughout a data institution’s lifecycle \n \nBeing trustworthy and being trusted both need to function over time. In our previous \nproject to pilot data trusts, we proposed a simple lifecycle that describes the stages \n69\nof setting up and running a data institution.  \n \n67\n O’Neill O (2002), ‘Reith Lectures 2002: Lecture 4: Trust and transparency’, \nhttp://downloads.bbc.co.uk/rmhttp/radio4/transcripts/20020427_reith.pdf  \n68\n Pozen D (2019), ‘Seeing transparency more clearly’, ​https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3478005  \n69\n Open Data Institute (2019), ‘Data trusts: lessons from three pilots’, ​https://theodi.org/article/odi-data-trusts-report  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  25 \n\n \n \n \nImage source: Open Data Institute \n \nDifferent mechanisms will be more appropriate in different phases in the lifecycle of a \ndata institution. For example, use cases, ecosystem maps and empathy maps are \n7071\nmore likely to be used to create shared understanding in the scoping and co-design \nphases, while the context and audiences for the data institution are being defined. \nWhereas after launch, a data institution might use mechanisms of transparency such \nas decision logs or financial reporting to help stakeholders make accurate \nassessments of the data institution’s trustworthiness. \nThird party trust \nPeople and organisations can make claims about trustworthiness on another’s \nbehalf. This is one of the ways that trust can scale. We cannot know everyone \npersonally, so we rely on recommendations from organisations we trust, in turn to \nunderstand the trustworthiness of others.  \n \nAs we discussed previously, a data institution will need to act as a trust intermediary. \nUsing this framework, we can see this role as providing assurances around another \nperson or organisation’s ​ability​ to supply data that is of a particular quality, or to hold \ndata securely. It may need to provide evidence that helps people decide whether to \ntrust each other, or in some cases provide incentives that ​motivate​ stakeholders to \nbehave as they claim. \n \nOther trusted people or organisations may also make claims about the \ntrustworthiness of a data institution. For example, by being involved in the data \ninstitution, data contributors implicitly indicate that they trust it. More explicit claims \nof trustworthiness may be made by auditors or certifiers. \n70\n Open Data Institute (2018), ‘Mapping data ecosystems’, ​https://theodi.org/article/mapping-data-ecosystems \n71\n XPLANE (2017), ‘Updated empathy map canvas’, \nhttps://medium.com/the-xplane-collection/updated-empathy-map-canvas-46df22df3c8a  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  26 \n\n \n \nAssessing trustworthiness \nAudits and certifications are assessments that can be conducted internally by a data \ninstitution to improve its own trustworthy operation, or externally by a third party. \nThat third party could be a direct stakeholder – such as a prospective data \ncontributor or user performing due diligence – or a trusted independent assessor, \nwhose assessments are then used by prospective stakeholders. \n \nAudits  \n \nAudits are tools for interrogating complex processes, often to determine whether they \ncomply with company policy, industry standards or regulations. In this way, audits \n72\nassess a data institution’s ​behaviours​ and ​ability​ to deliver on expectations.  \n \nExternal audits typically examine the finances of an organisation; whereas internal \naudits consider the effectiveness of governance, risk management and control \nprocesses, and even wider issues such as the organisation’s reputation, growth and \nimpact on the environment. \n73\n \nA data institution will need to demonstrate to auditors that it is​ ​“delivering on its \npurposes, has effective processes for promoting beneficial use and mitigating harm, \nis appropriately assessing its non-financial impacts, is achieving an equitable balance \nbetween the needs of different stakeholders, and so on”. Assessment mechanisms \n74\nmight include stakeholder surveys and interviews, public research, and stress-tests of \na data institution’s processes and policies. \n \nA data institution may pose challenges to traditional audits, however, due to the need \nfor auditors to understand the operational and data contexts. There may eventually \nbe the need to find auditing approaches that are specific to data institutions, for \nexample, processes to determine compliance with declared ​willingness​ to uphold \nethical principles. \n75\n \nCertification \n \nCertification is a process where a third-party authoritative body verifies that a \nnon-authoritative person, process, product or organisation meets standardised \ncriteria. A certification will have a target audience such as customers, shareholders or \nregulators. If successful, the non-authoritative entity is allowed to signal compliance \nusing mechanisms such as kitemarks. The certifying authority usually acts as an \nauditor to verify ongoing compliance, as well as having powers to enact redress \nmechanisms.  \n \nWe can trust certifying bodies by ensuring there is oversight of them by accreditors. \n72\n Liu J (2012), ‘The enterprise risk management and the risk oriented internal audit’, \nhttps://www.researchgate.net/publication/272673574_The_Enterprise_Risk_Management_and_the_Risk_Oriente\nd_Internal_Audit  \n73\n Chartered Institute of Internal Auditors (2020), ‘What is internal audit?’, \nhttps://www.iia.org.uk/about-us/what-is-internal-audit  \n74\n Open Data Institute (2019), ‘Data trusts: how decisions are made about data sharing’, \nhttps://theodi.org/article/data-trusts-decision-making-report  \n75\n Raji I, Smart A, White R(2020), ‘Closing the AI accountability gap: defining an end-to-end framework for internal \nalgorithmic auditing’, ​https://arxiv.org/abs/2001.00973  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  27 \n\n \n \nAccreditation confirms that the process of certification is carried out correctly. For \nexample, the UK Accreditation Service and the International Accreditation Service. \n \nCertification is a special type of mechanism because it is designed to incorporate \nother mechanisms. For example, to meet ISO-9001 requirements, an organisation \nmust ​train staff​ with adequate abilities, and define ​acceptance criteria​ for product \nbehaviour. \n \nAs such, certification serves many purposes: guidance; monitoring; independent \naccountability; and as a signal to others that an organisation has been through a \nrigorous process, which others may consider when deciding whether to trust it. \n \nExisting certifications that are likely to be relevant for data institutions include: \n \n●Technical expectations​ such as technical or security adequacy. For \nexample the National Cyber Security Centre’s Cyber Security certification, \n76\nwhich “helps you to guard against the most common cyber threats and \ndemonstrate your commitment to cyber security”. \n●Organisational processes​ for example ISO-9001, which aims to ensure the \nquality of products and services by establishing a rigorous quality \nmanagement system. \n77\n●Organisational structure and mission​ for example B-Corp, which verifies \nwhether a company meets “standards of social and environmental \nperformance, public transparency, and legal accountability to balance profit \nand purpose”. \n78\n●Comprehensive certification​ such as CoreTrustSeal’s Trustworthy Data \nRepositories certification, which certifies repositories that have an explicit \n79\nmission to provide access to and preserve data. It covers matters of \npreservation, licences, financial and technical sustainability, ethics, \norganisational structure, guidance, data quality and integrity, evaluation, \ndocumentation, data discovery, enabling data reuse, technical infrastructure, \nand security. \n \nThe costs of formal certification, which include employee training and auditors’ fees, \nneed to be balanced against the value it brings in terms of the standard achieved and \nthe signal of trustworthiness it produces. HESA told us it had let its ISO-9001 \ncertification lapse having “decided in the last few years that the benefits didn’t justify \nthe costs involved [...] but we do still follow the procedures that were set up internally \nto comply”. \n \nCertifications need to be renewed and so are not a permanent guarantee. For \nexample, OpenCorporates preferred to use irs organisational structure and \ngovernance processes to assure its public interest mission rather than certification \nbecause of the “overhead” involved and because the certification doesn’t provide \nprotection: “there’s no guarantee the owners won’t sell to someone else the day after \ntomorrow and you’ll no longer be a B-corp after that”. \n \n76\n National Cyber Security Centre (2020), ‘Cyber essentials’, ​https://www.cyberessentials.ncsc.gov.uk  \n77\n British Assessment Bureau (2018), ‘Quality management systems explained’, \nhttps://www.british-assessment.co.uk/insights/what-is-a-quality-management-system  \n78\n Certified B Corporation (n.d.), ‘About B Corps’, ​https://bcorporation.net/about-b-corps  \n79\n CoreTrustSeal (2019), ‘CoreTrustSeal Trustworthy Data Repositories Requirements’, \nhttps://www.coretrustseal.org/why-certification/requirements  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  28 \n\n \n \nA certification of trustworthiness? \nCertifications often have specific requirements, for example, ‘product and service \nquality’ or ‘corporate responsibility’. At the time of writing, there is no known \ncomprehensive ‘certification of trustworthiness with data’ that considers all \naspects necessary to demonstrate trustworthiness and align trustworthiness and \ntrust in a rigorous way. However, we suggest the CoreTrustSeal Trustworthy Data \nRepositories would make a good basis. \n \nA certification of trustworthiness might ask to what extent the data institution has: \n●communicated the quality and coverage of appropriate mechanisms, \nincluding laws and regulations, codes and standards \n●communicated the context, audience and behaviours to avoid \nmisunderstandings throughout a data institution’s lifecycle \n●a plan to re-communicate and re-consent if one or more of the context, \naudience, behaviours or abilities were to change during the lifetime of the \ndata institution. \n \nThere are two options for such a certification:  \n●An all-encompassing certification that would assess all aspects necessary \nto demonstrate trustworthiness and align trustworthiness and trust in a \nrigorous way. \n●Several focused certification bodies that assess separate aspects. In this \ncase, the data institution may make use of advisory and consultancy \nservices to create coherent coverage. \n \nEarlier research from Oxford Insights into certification for data trusts \n80\nrecommended the discovery, prototyping and testing of potential certification \nmodels with stakeholders. The ODI intends to follow these recommendations in a \nfuture phase of our research and development.  \n \n \nSignals such as kitemarks or trustmarks may have limitations with some audiences. \nDoteveryone carried out extensive research into trustmarks for technology and \n81\nfound that they would take significant investment to establish, and with limited \nbenefit. Requirements for a trustmark in the face of fast-changing technology \nservices, and lack of consumer levers and interest in a domain where choices are \nalready complex, led Doteveryone to conclude that a more effective solution would \nbe to work with businesses to introduce a more flexible, value-based approach to \nensure the trustworthiness of their processes and products. This could be coupled \nwith lightweight accountability and enforcement, without the cost and scale of a full \nstandards body or certification authority. \n  \n80\n Oxford Insights (2019), ‘Exploring data trust certifications’, \nhttps://theodi.org/article/data-trusts-will-certification-work-report  \n81\n Doteveryone (2019), ‘Why we haven’t made a trustmark for technology’, \nhttps://www.doteveryone.org.uk/2019/09/digital-products-and-services-arent-bananas  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  29 \n\n \n \nTrusting others \nIn the section ​‘An ecosystem for trust’​, we discussed how a data institution needs to \nassess the trustworthiness of those parties it depends on or represents. It can do that \nusing the same mechanisms described in the previous section. \n \nFor example, when hiring staff, it may assess their ability through interviews, professional \ncertification and exams; and data access panels within a data institution will assess \nwhether prospective data users will behave in accordance with agreed criteria. \n \nBut trust isn’t merely transactional; it is relational. Collaboration requires mutual trust. \nAnd for the relationships to be mutually beneficial, a data institution also needs to \ntrust its stakeholders. \nInvest in capability to take collective decisions \nA data institution will have to make many decisions throughout its lifecycle. For \nexample, what types of data users should have access to, what services to provide \nand what business model to adopt. \n \nResearch into decision making for data trusts – by Communication Chambers and \nInvolve and commissioned by the ODI – states: “Deliberative decision-making [...] is \nimportant for data [institutions], given wider societal mistrust and uncertainty around \ndata sharing and use. A data [institutions]’s legitimacy – and, by extension, the trust \nof stakeholders – comes from its capacity to enable, encourage and benefit from \ncollective discussion, reasoning and decision-making.” \n82\n \nBefore a data institution is willing to open its processes to external influence, it will \nneed to trust that its stakeholders are invested in shared problems. By investing in \nstakeholders’ capability and skills to understand complicated issues, a data \ninstitution will have the confidence to act on the feedback and perspectives \nthey provide. \n \nMany data institutions will have a broad stakeholder group with a range of economic \nand data literacy. True engagement requires sustained, iterative effort to produce \naccessible materials and develop a shared vocabulary that is meaningful to both \nsides of the conversation; and necessary for aligning understanding and trust. \n83\n \nEven so, many organisations report positive experiences and successful engagement \nprogrammes involving diverse groups with a range of data literacy, such as the \n84\nRoyal Society’s public dialogue work on machine learning. The Ada Lovelace \n85\n82\n Involve (2019), ‘Data trusts: how decisions are made about data sharing’, \nhttps://theodi.org/article/data-trusts-decision-making-report  \n83\n O’Hara K (2019), ‘Data trusts: ethics, architecture and governance for trustworthy data stewardship’, \nhttps://eprints.soton.ac.uk/428276  \n84\n University of Manchester (2020), ‘We need to re-think health data sharing and public trust’, \nhttps://www.manchester.ac.uk/discover/news/we-need-to-re-think-health-data-sharing-and-public-trust-says-pub  \n85\n Royal Society (2017) ‘Public views of machine learning’, \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  30 \n\n \n \nInstitute reports: “When engaged in a way that fosters critical democratic scrutiny, \npublics are capable of discussing the use of data in a sophisticated manner... \n[supporting] policymakers and regulators to broaden the conversation on the use and \ngovernance of data.” \n86\nBe fearless, be honest \nInevitably, even for trustworthy actors events don’t always go to plan or new \ninformation comes to light. By investing in stakeholder’s capability and skills to \nunderstand complicated issues, a data institution can trust in their discernment \nenough to be honest with them if something goes wrong. \n \nData institutions that are not open with their stakeholders, or try to manage \nmessaging, risk being misinterpreted as untrustworthy; as Onora O’Neill points out, \ndeception is the real enemy of trust. O’Hara expands on this idea saying, “Even if \n87\nthe organisation has done everything it could and is not to blame for a breach, an \nill-thought-out communication strategy gives an impression of a cover up.[...] At best, \nit means that the organisation is focused on its own problems of liability, and not on \nthe harms to its stakeholders”. \n88\n \nThere are good examples of frank apologies, reparations, open post-mortems \n899091\nand incident reports that have prevented a technical or procedural mishap from \n92\nescalating into an issue of mistrust and damaging relationships. \n \nHonesty is the foundation on which to rebuild trust. If a data institution has built and \nmaintained a relationship with its stakeholders using the techniques described in the \nrest of this report, they may be supportive.  \n \n \n \n \nhttps://royalsociety.org/-/media/policy/projects/machine-learning/publications/public-views-of-machine-learning-\nipsos-mori.pdf  \n86\n Ada Lovelace Institute (2020), ‘Rethinking data’, ​https://www.adalovelaceinstitute.org/our-work/rethinking-data  \n87\n O’Neill O (2002), ‘Reith Lectures 2002: Lecture 4: Trust and transparency’, \nhttp://downloads.bbc.co.uk/rmhttp/radio4/transcripts/20020427_reith.pdf  \n88\n O’Hara K (2019), ‘Data trusts: ethics, architecture and governance for trustworthy data stewardship’, \nhttps://eprints.soton.ac.uk/428276 \n \n89\n Gitlab (2019), ‘Important updates to our terms of service and telemetry services’, \nhttps://gitlab.com/gitlab-org/gitlab/issues/34833  \n90\n DeepMind (2017), ‘The Information Commissioner, the Royal Free, and what we’ve learned’, \nhttps://deepmind.com/blog/announcements/ico-royal-free  \n91\n Google Cloud Platform (2020), ‘Fearless shared postmortems’, \nhttps://cloud.google.com/blog/products/gcp/fearless-shared-postmortems-cre-life-lessons  \n92\n Cloudflare (2020), ‘Post Mortem’, ​https://blog.cloudflare.com/tag/postmortem  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  31 \n\n \n \nIf you want to go far, go \ntogether \n“The failure on the part of policy and industry organisations \nto open up the conversation to the wider public has moved \nthe current discourse on data out of step with people’s \nexpectations and attitudes.”  \n93\n \nTrust is dynamic. It is built, and must be nurtured over time. The relationship between \ndata institutions and the communities that surround and support them is one of \nmutual interaction and influence. A change or evolution of either of these is bound to \nhave an impact on, or bring about changes in, the other. Over the life of a data \ninstitution, this changing relationship can present a number of challenges to the \nunderstanding between a data institution and its stakeholders. \n \nStakeholder engagement is a means to continually align understanding, for example \nthrough open processes where external parties are able to influence outcomes \nthrough consultation, dialogue, negotiation, compromise and relationship building.  \n \nSpecialist engagement skills are required to identify stakeholders, incentivise \nparticipation, design events, facilitate and mediate, and summarise and feed back \nrecommendations into existing processes. The complexity of the task should not be \n94\nunderestimated. A data institution will need access to people with the right skills, \neither in house or by working with specialist agencies. \n \nThere are many engagement approaches appropriate to the message being \ncommunicated, the purpose of the engagement, and the needs of the group, \nincluding:  \n \n●interviews and dialogues \n95\n●roundtables \n●citizens’ juries \n96\n●advisory committees \n●public forums \n97\n●consultation on specific subjects or projects \n98\n●open annual meetings \n93\n Ada Lovelace Institute (2020), ‘Rethinking data’, ​https://www.adalovelaceinstitute.org/our-work/rethinking-data  \n94\n MIT Sloan Management Review (2005), ‘Managing stakeholder ambiguity’, \nhttps://sloanreview.mit.edu/article/predicting-customer-choices-2  \n95\n Royal Society (2017) ‘Public views of machine learning’, \nhttps://royalsociety.org/-/media/policy/projects/machine-learning/publications/public-views-of-machine-learning-\nipsos-mori.pdf  \n96\n  Ada Lovelace Institute (2019), ‘The Ada Lovelace Institute supports Wellcome Trust to undertake citizen juries \non fair data sharing in the NHS’, \nhttps://www.adalovelaceinstitute.org/the-ada-lovelace-institute-kicks-off-citizen-jurie \ns-on-fair-data-sharing-in-the-nhs \n97\n Involve (2020), ‘21st century town meeting’, \nhttps://www.involve.org.uk/resources/methods/21st-century-town-meeting  \n98\n UK Biobank (2020), ‘Public consultation’, ​https://www.ukbiobank.ac.uk/public-consultation  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  32 \n\n \n \n \nFor example, ROR has established a community advisory group composed of \ndomain experts with whom they convene regular stakeholder prioritisation sessions. \nA steering group with experts and leaders from non-profit and academic institutions \nbrings a wealth of expertise to ROR, lending it a sense of authority and trust. \n \nThe following are occasions when two-way engagement is particularly appropriate to \naligning trustworthiness and trust. \nProvide opportunities to re-evaluate following \nnew information \nA data institution’s circumstances can change such that the foundations on which \ntrust was built may shift. The trigger for change can be internal, for example, staffing \nor business models change; or caused by external forces, for example, new \ninformation comes to light, or regulations change. \n \nIn seeking to evolve, scale and adapt to changing circumstances, however, it is \nimportant that data institutions assess whether they will be changing in ways that will \nupset or alienate members of their current stakeholders, community or ecosystem.  \n \nFor example, as a data institution grows and evolves, it may need to evolve its \nbusiness model, possibly by offering new services or by welcoming new data \ncontributors, users or decision makers to the ecosystem.  \n \nHESA described to us how its business model has adjusted over time. It wanted to \nmove away from commercialisation of data resources towards commercialisation \nbased on expertise, such as data analysis and data visualisation. Its board of \ndirectors has always been careful to ensure that HESA’s commercial activities are not \nin conflict (or perceived by stakeholders to be in conflict) with HESA’s core functions. \n \nThe ODI’s Data Ethics Canvas guidance recommends organisations regularly revisit \ntheir ethics assessment, for example, quarterly, or at project milestones. Similarly, if \nthe conditions under which trust was originally given change, stakeholders and those \naffected by the use of data should be given the opportunity to review new information \nand re-evaluate any agreements they have entered into. \nStakeholders’ views can change \nAs a data institution grows, the community around it is likely to grow as well, and the \nneeds, motives and expectations of that community are almost certain to evolve. \n \nEngagement can help a data institution identify any changes in public perception or \nchanges in how trustworthiness and trust is aligned, giving the data institution the \nopportunity to make any necessary changes. \n \nFor example, OpenStreetMap has corporate sponsors who provide funding and are \nincreasingly involved in the project by contributing data, open source code and other \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  33 \n\n \n \nresources. Their contributions represent their evolving sense of what is important to \nthe project. These contributions help make the project more sustainable, but have \nraised concerns from the existing community about the ease with which those \norganisations could shape the future of the project. \nData institutions as centres of debate \nThe Ada Lovelace Institute observes: “The failure on the part of policy and industry \norganisations to open up the conversation to the wider public has moved the current \ndiscourse on data out of step with people’s expectations and attitudes.” This \nmisalignment is fertile ground for the breakdown of trust. \n \nPrevious ODI commissioned research found that data institutions could play a role \n99\nin defending the interests of parties who:  \n \n●cannot negotiate effectively because they are too dispersed, for example, the \npublic \n●lack sufficient information about other parties’ incentives \n●are invested in the social and non-financial benefits. \n \nData institutions could be a centre for debate: bringing together and enabling data \nscientists, data subjects and other stakeholders to interact, debate and refresh \nmutual understanding of what constitutes trustworthy behaviour. \n100\n  \n99\n Open Data Institute (2019), ‘Data trusts: how decisions are made about data sharing’, \nhttps://theodi.org/article/data-trusts-decision-making-report  \n100\n O’Hara K (2019), ‘Data trusts: ethics, architecture and governance for trustworthy data stewardship’, \nhttps://eprints.soton.ac.uk/428276  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  34 \n\n \n \nConclusion and next \nsteps \nThis report summarises an initial exploratory study to help understand the factors that \ncontribute to the creation of trustworthy data institutions. \n \nData institutions are a relatively new type of organisation, and it is important that they \nare designed and operated in a trustworthy way, such that they establish and \nmaintain the trust of their stakeholders.  \n \nAdopting the language and concepts of formalised trust frameworks can help us \nunderstand the evolving ecosystem of trust around a data institution. A trust \nframework can also be used to understand the rules governing the activities of data \ninstitutions, and to organise our knowledge of the many mechanisms which they and \nothers can use to either assess trustworthiness, or try to demonstrate it to create \nricher and more resilient networks of trust. \n \nTrust can be conferred to data institutions by third parties. By providing audit and \ncertification, already-trusted members of the data ecosystem can help bolster trust in \nnew data institutions, as earlier research into certification for data trusts suggests. \n101\n \nMapping these mechanisms reveals where there are gaps: trust is often undermined \nwhen there is a failure to communicate around change; and there is only so much \nkitemarks and principles can help in those cases. Most importantly, our work has \nhighlighted how trust is dynamic: it can only be built over time, through \ndemonstration of trustworthiness, and honest, open engagement across the \necosystem.  \n \nTo conclude, we identify some areas for further research and provide some initial \nrecommendations for those currently scoping, designing and running data \ninstitutions. \nAreas for further research \nWe plan to apply the framework introduced in this report to support further analysis \nof the ways data institutions ensure their trustworthiness and help others decide to \ntrust them.  \n \nThere are several areas that merit further work, including: \n \n●Developing a more comprehensive review of the mechanisms adopted by \ndifferent types of data institutions across sectors, and, in particular, exploring \nsome who have suffered from breakdowns of trust. \n101\n Oxford Insights (2019), ‘Exploring data trust certifications’, \nhttps://theodi.org/wp-content/uploads/2019/04/Report_-Exploring-Data-Trust-Certification.pdf  \n \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  35 \n\n \n \n●Further work to understand whether a combination of trust mechanisms \nwould create an effective certification programme, and to understand how \nsuch a programme would affect the ecosystem of trust. \n●Developing and testing practical tools, for example, a canvas, using the trust \nframework as a basis to help support data institutions in developing \ntrustworthy practices and aligning understanding. \nSuggestions for those scoping, designing and \nrunning data institutions \nWhile our exploratory research was not intended to produce a comprehensive survey \nof the many data institutions that exist across sectors, through our desk research and \ninterviews we have identified some common issues and challenges in aligning \ntrustworthiness and trust. \n \nBased on those insights, we offer some initial suggestions for those currently \nscoping, designing and running data institutions, to help them navigate \ntrustworthiness and trust. \n \nBeing trustworthy: reliably deliver on promises \n \n●Define explicit expectations and boundaries. ​Everything a data institution \ndoes should be constrained by its context – its purpose – to benefit some \naudiences and not cause harm through its actions. It should understand its \nrole in the ecosystem: the relationships and dynamics in which it operates, \nincluding data flow and funding that could affect its purpose. It should \nunderstand its own abilities, limitations and where it should cooperate, and it \nshouldn’t overstep those boundaries. \n●Surface implicit expectations.​ Some expectations of a data institution will \nbe implicit. Seek to understand the expectations of all those who have an \ninterest in the operation: from regulators and direct stakeholders, to those \nwho may be affected by using the data being stewarded. \n●Implement trustworthy practices.​ Follow the rules set by the data \ninstitution itself, and by its environment. Practise ethical design with special \nconsideration to any implicit expectations. Establish an organisational \nstructure, governance practices and organisational processes that are \naligned with the declared values and principles, and that enable the people in \nthe organisation to deliver on expectations. Hire employees with the right \nskills. Be fearlessly honest. \n \nBuilding and sustaining trust: close the perception gap \n \n●Demonstrate​ that the data institution has implemented trustworthy \npractices. \n●Communicate​ the data institution’s own expectations and boundaries \nclearly. \n●Engage people with empathy.​ Build mutually beneficial relationships. \nUnderstand how the data institution and its employees are perceived. \nInternalise the understanding gained in surfacing implicit expectations. Meet \npeople where they are. Use language they understand. Demonstrate trust in \nthe data institution’s stakeholders. \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  36 \n\n \n \n●Adapt and evolve collaboratively.​ Circumstances change and new \ninformation comes to light, and organisations need to adapt – but trust that \nwas placed in the data institution in one set of circumstances may or may not \nendure in a new set. Explain changes to stakeholders and give them the \nopportunity to re-establish trust on new terms. Open up the data institution’s \nprocesses to influence and evolve together. \n \nWe plan to apply these recommendations as we continue to work with a range of \norganisations that are establishing new data institutions. As our research and \npractical work continues, we will revisit, revise and expand these recommendations.  \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  37 \n\n \n \nAppendix A: \nMethodology \nTo inform this exploratory research project, we conducted broad desk research into \nconcepts of trustworthiness relevant to the context of data institutions. We then \ndefined a set of criteria to select different types of data institutions we would look at \nin more details. We conducted desk research about these institutions and, where \npossible, interviewed representatives of the data institutions.  \n \nThe brief timeframe of this research resulted in several limitations, including:  \n \n1.Limited number of interviews. \n2.Potential sector bias – our desk research has been informed significantly by \nour prior knowledge of specific institutions. \n3.Focus on one trust framework. \nResearch questions \nMain research question \nWhat mechanisms exist to assess (and verify) the trustworthiness of people, products \nand institutions, and which ones may be relevant in the context of data institutions? \n \nSupplementary research questions: \n \n1.What laws and regulation currently affect data institutions? \n2.What mechanisms do organisations use to prove their trustworthiness? \n3.Which groups of people or organisations do the data institutions aim to prove \ntheir trustworthiness to? \nDesk research \nOur desk research covered academic and professional literature on trust and \ntrustworthiness, accountability, certification and accreditation, and data governance \nmodels. We also reviewed and built on our earlier research on data trusts and data \ninstitutions. \nInterviews \nWe complemented the information gathered through desk research with interviews \nwith representatives of data institutions. We interviewed representatives from five \norganisations covering some of the following criteria: \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  38 \n\n \n \n \n1.Type of data institution:  \na.Organisations that steward data on behalf of a community \nb.Organisations that steward digital resources or a platform on behalf \nof a community \nc.Organisations that steward a physical resource on behalf of a \ncommunity or set of stakeholders \n2.Life stage of the data institution:  \na.Organisations in scoping or co-design stage  \nb.Organisations that are operational but relatively young  \nc.Well-established or ‘successful’ institutions  \nd.Organisations that tried to set up a data institution but could not \novercome the challenges \n \nWe interviewed representatives from the following data institutions:  \n \n●Higher Education Statistics Agency (HESA): an official body which \n102\ncollects, analyses and publishes data about higher education in the UK. Its \nproducts are used by researchers and policymakers for transparency, \nretaining public trust and decision making.  \n●Research Organization Registry (ROR): a community-led project working \n103\nto produce a unique, open, usable and sustainable identifier for every \nresearch organisation in the world. \n●HiLo Maritime Risk Management: a not-for-profit joint industry initiative \n104\nproviding analysis of shipping data to make the industry safer. Shipping \ncompanies share safety-related data from vessels, HiLo runs it through a risk \nalgorithm and shares insights with the companies.  \n●OpenCorporates: the world’s largest open database of information about \n105\ncompanies. All of the data on OpenCorporates comes from primary public \nsources, and is used by individuals, journalists, non-governmental \norganisations and companies.  \n●MusicBrainz: a project to create a collaborative database about artists, \n106\nsongs and albums. Any user can contribute and release the music metadata \nunder open licences. \n107\n \nThe questions asked during the one-hour interviews covered themes related to \nsustainability and trustworthiness, specifically: \n108\n \n●Revenue streams \n●What sustainability looks like \n●Alignment of business models with data institutions’ core goals \n●Mechanisms for ensuring trustworthiness \n○Laws or regulations that help prove or improve trustworthiness \n○Used or planned to use mechanisms to prove trustworthiness  \n○Mechanisms for redress if trust is broken \n○Ways of demonstrating trustworthiness to different groups of people.  \n102\n Higher Education Statistics Agency (n.d.), ​https://www.hesa.ac.uk/  \n103\n Research Organization Registry (n.d.), ​https://ror.org/  \n104\n HiLo Maritime Risk Management (n.d.), ​https://hilomrm.com/  \n105\n OpenCorporates (n.d.), ​https://opencorporates.com/  \n106\n MusicBrainz (n.d.), ​https://musicbrainz.org/  \n107\n MusicBrainz (n.d.), ‘About: Data license’ ​https://musicbrainz.org/doc/About/Data_License  \n108\n ​Open Data Institute (2020), R&D: Sustainable data institutions, \nhttps://theodi.org/project/sustainable-data-institutions \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  39 \n\n \n \nAppendix B: Map of trust \nmechanisms \nThis appendix presents a map of mechanisms that can be used or called upon by data institutions \nor others in their ecosystem. The table below presents those mechanisms mapped against the \nelement of trust in the framework in the section ​‘A framework for trust’​, with columns mapping the \nways trust can break down presented in the section ‘​How trust breaks down​’.  \n \nThe map is not intended to be comprehensive, but indicative of the kind of mechanisms \nconsidered during our research. \n \n Avoid misrepresentation  Avoid misunderstanding  Avoid being unable to \ndetermine \nCommunicate \nchanges \nAbility ●Exams \n●Interviews \n●Performance monitoring \n●Audit \n●Certification \n●Professional certification \n●Accreditation \n●Oversight eg regulatory  \n●Peer review \n●Quality standards  \neg ISO-9000 \n●Exams \n●Interviews \n●Performance \nmonitoring \n●Audit \n●Certification \n●Training \n●Quality standards  \neg ISO-9000 \n●Privacy technologies \n \nWillingness ●Interviews  ●Principles \n●Codes of ethics \n●Codes of conduct \n \nMotivation   ●Penalties \n●Redress \n●Values \n \nContext  ●Contracts \n●T&Cs \n●Licences \n●Data sharing  \nagreements \n●Citizens’ juries \n ●Re-issuing \nT&Cs \nBehaviour ●Data access  \npanels \n●Audit \n●Review boards \n●Minutes of  \nMeetings \n●Certification \n \n●Laws \n●Regulation \n●Contracts \n●T&Cs \n●Licences \n●Sharing agreements \n●Data standards \n●Ethics assessments \n●Citizens’ juries \n●Audit \n●Data standards \n●Principles \n●Codes of ethics \n●Codes of conduct \n●Kitemarks \n●Re-issuing \nT&Cs \nAudience ●Financial reporting \n●Decision logs \n●Contracts \n●T&Cs \n●Licences \n●Register of interests \n●Ecosystem map \n●Empathy map \n ●Re-issuing \nT&Cs \n \n \nOpen Data Institute 2020 / ReportDesigning trustworthy data institutions  40 ","version":"1.10.100"}