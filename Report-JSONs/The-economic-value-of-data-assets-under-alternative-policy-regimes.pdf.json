{"numpages":40,"numrender":40,"info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Microsoft Word - ODI Report Proofed Final v4 April.docx","Keywords":"","Creator":"Word","Producer":"Mac OS X 10.11.3 Quartz PDFContext","CreationDate":"D:20160419145047Z","ModDate":"D:20160420092430+01'00'"},"metadata":{"_metadata":{"xmp:createdate":"2016-04-19T14:50:47Z","xmp:creatortool":"Word","xmp:modifydate":"2016-04-20T09:24:30+01:00","xmp:metadatadate":"2016-04-20T09:24:30+01:00","pdf:keywords":"","pdf:producer":"Mac OS X 10.11.3 Quartz PDFContext","dc:format":"application/pdf","dc:title":"Microsoft Word - ODI Report Proofed Final v4 April.docx","xmpmm:documentid":"uuid:109c1352-675f-ef47-83f3-e03b55e2aeed","xmpmm:instanceid":"uuid:b4fabe86-98f0-a54d-9d8c-e442a5e35eca"}},"text":"\n\n \n \n \n  \n \n \n \n \n \nPermission granted: The \neconomic value of data assets \nunder alternative policy regimes \n \n \n \nA Lateral Economics report for the Open Data \nInstitute \n \n \n \n \n \nMarch 2016\n \n\n \n \n    \n \n \nii \nExecutive Summary \nIntroduction and background \nThe myriad and continually growing uses of data – public sector information \n(PSI) and other data (including research and private data) have great social \nand economic value. However, there are formidable challenges in estimating \nthe economic value of much of this. \n• First, the phenomenon of data is vast and multifarious. There are \ninnumerable data series, all with specific micro-economic \ncharacteristics. Data is typically acquired by intermediaries and/or \ndevelopers and distributed via a great many products and services.  \n• Second, it is extremely difficult to arrive at a measure of economic \nvalue (e.g. pound sterling) of the final consumption of data because \nso much of it occurs for free. Even if one successfully addresses the \nconceptual issues (for instance, by envisaging some consumer \n‘willingness to pay’), the practical challenges of obtaining empirical \nevidence remain. Free consumption is part of the increasingly \nimportant ‘dark matter’ of GDP.  \nAs much as we might be tempted to think the quantification of such uncertain \neffects irresponsible, those who must make important decisions are entitled \nto press analysts for their best guess of the indicative magnitudes we could \nbe dealing with. \nAs one would expect, given this level of ignorance and uncertainty, existing \nempirical estimates of the value of open data vary considerably in scope. \nHowever, they suggest that the value added associated with open data varies \nbetween 0.4 and 1.4 per cent of gross domestic product (GDP) with the wide \nmargin between these two numbers providing some quantification of our \nignorance. \nODI has asked Lateral Economics to assist it to consider the economic \nimplications of the commercial terms on which core data sets which form the \nbulk of PSI (e.g. land registry data and transport data) are distributed.   \nPricing and licencing \nData providers incur various costs in acquiring, curating and distributing data. \nThey may attempt to recover some or all costs by charging for access to the \ndata. Or they may go further and maximise their own financial return. At the \nopposite end of this spectrum, data can be provided free and open licenced. \nIn many industries, cost-reflective pricing is efficient. However, with \ninformation goods like data, once it is made publicly available, the marginal \ncost of additional distribution is effectively zero. Thus, pricing at above this \npoint will reduce demand and so curtail some information distribution that \nwould be cost effective. On the other hand, just as private firms must find the \n\n \n \n    \n \n \niii \nwherewithal to meet all their costs, so government agencies will sometimes \nfind it appropriate to charge for data to meet fixed costs even though the \nmarginal cost of additional distribution is effectively zero. Accordingly, this \nstudy investigates the magnitude of the economic effects of this latter course.  \nThe impact of changing price regimes \nTo provide an indicative estimate of the impact of shifting from cost-recovery \npricing to open data, we build on prior work that estimates the impact of \nreducing the prices of PSI. We estimate that the increase in re-use of data \nfrom removing licence restrictions is similar in magnitude to the impact of \ndropping prices to zero. In terms of the value created, a shift from a cost-\nrecovery to an open-access regime is likely to more than double the value of \nthe re-use of the data, adding around 0.5 per cent to GDP. \nThe impact of moving in the other direction – from an open-access regime to \na cost-recovery regime – will reduce the impact, perhaps by around half, at \nleast in the shorter term. This is because once the search for new and \ninnovative uses has been done under open data, those subsequently \ncharging for data have an interest in preserving that outcome. Nevertheless, \nonce charging and licensing is introduced, the search for further beneficial \nuses for data will be curtailed which will see the loss from charging gradually \nclimb back towards 0.5 per cent.  \nThe implications of a profit-maximising regime are more uncertain. On the \none hand, the revenue from sale of data is likely to rise – producing a further \nfall in demand, suggesting losses greater than 0.5 per cent. However, a \nsophisticated profit maximiser would probably do considerably less harm than \nmight be expected from a firm that priced its data products crudely. It would \nseek maximally open options to monetise its data – such as advertising and \nfreemium access. Further, a savvy profit maximiser might invest in additional \ndata collection, curation and quality assurance work to optimise the value of \nits product. However, our report identifies substantial risks in such a course.  \nImplications \nAcross the value chain (with the exception of the acquisition of core data), \nthere appear to be no material barriers to competition. So we expect \nreductions in costs to make their way to the ultimate consumers – the public. \nThere will be some exceptions (for example, where firms can enhance \nexisting products) and there will be winners and losers where there are risky \ndevelopments. Empirical studies suggest that once open data is provided, \ndemand for re-use will rise rapidly. However, the full value to final consumers \nmay take some time to eventuate as new applications are developed.  \nThe two biggest obstacles to further developing the market for core data \nassets are, as they have been in the past, apathy and/or opposition within \ndata providers to opening their data and investing in optimising its quality for \nusers rather than solely the PSI producers. But the UK is a world leader in \ntackling these issues. And with further effort comes further opportunity.  \n\n \n \n    \n \n \niv \nTable of contents \nEXECUTIVE\tSUMMARY\tII\t\nTABLE\tOF\tCONTENTS\tIV\t\n1\tINTRODUCTION\t1\t\n2\tBACKGROUND\t2\t\n2.1\tAn\toverview\tof\topen\tdata\tassets\t2\t\n2.2\tThe\tvalue\tchain\tfor\topen\tdata\t3\t\n2.3\tEstimating\tthe\tvalue\tof\topen\tdata\t5\t\n2.3.1\tEmpirical\tstudies\t6\t\n3\tIMPLICATIONS\tOF\tA\tPAID-ACCESS\tREGIME\t9\t\n3.1\tCharging\tregimes\tfor\tdata\t9\t\n3.2\tImplications\tof\tdifferent\taccess\tregimes\t10\t\n3.2.1\tThe\tcommon\trationale\tfor\tpaid\taccess\t10\t\n3.2.2\t‘Abundance\tthinking’:\tThe\teconomics\tof\tinformation\tgoods\t10\t\n3.2.3\tTransactions\tcosts\t13\t\n3.2.4\tNetwork\texternalities\tand\tinnovations\t15\t\n4\tESTIMATING\tTHE\tIMPACT\tOF\tA\tPAID-ACCESS\tAPPROACH\t17\t\n4.1\tOverview\tand\tapproach\t17\t\n4.2\tBasic\tapproach\t17\t\n4.3\tModelling\tthe\teffect\tof\tchanging\tprice\tregimes\t19\t\n5\tFURTHER\tMATTERS\t23\t\n5.1\tImplications\tacross\tthe\tvalue\tchain\t23\t\n5.2\tTiming\t25\t\n5.2.1\tTiming\tof\teffects\t25\t\n5.2.2\tAccelerating\tthe\tchange\t25\t\n5.2.3\tMarket\tdevelopment\t26\t\n6\tREFERENCES\t28\t\n7\tAPPENDICES\t30\t\n7.1\tFurther\tdetails\tof\tstudies\tundertaken\t30\t\n7.2\tTechnical\tappendix\t31\t\n7.3\tEvidence\tof\tchanges\tin\tresponse\tto\tprice\t34\t\n \n  \n\n \n \n    \n \n \n1 \n1 Introduction \nThe mission of the Open Data Institute (ODI) is to ‘connect, equip and \ninspire people around the world to innovate with data’. A cornerstone of \nachieving this mission is encouragement of open access to data, \nparticularly that produced by government agencies. The ODI seeks to \nbetter understand the implications of charging for data and has \nengaged Lateral Economics to explore the economic implications of \npaid access compared to open licencing.  \nLateral Economics has been asked these questions: \n1) What is the expected economic value to a national economy from \ncore data assets under two different access models? \na) Paid access – where all organisations must sign a contract, \npay a fee and potentially abide by licence restrictions on the \npurposes that the data can be used for \nb) Open licence – where anyone can access, use and share the \ndata  \n2) Assess how this value will accrue across the different parts of the \nvalue chain that use the data to deliver products/services to the \nmarket. \n3) What is driving any difference in economic value between the two \naccess models, e.g. network effects, time saving, allocative \nefficiency, etc.? \n4) What are the expected timescales to realise the change in \neconomic value if data is moved between these different access \nmodels (for example, from paid to open, or from open to paid)? \n5) What steps can be taken to accelerate the change in economic \nvalue? \nThe rest of this document addresses these questions: \n• Chapter 2 provides background including a description of the \nvalue chain and recent estimates of the value of open data \n• Chapter 3 explores the economics of paid and unpaid access \nin a qualitative way  \n• Chapter 4 offers an indicative quantification of those issues \n• Chapter 5 offers comments on the remaining matters in our \nterms of reference \n• Chapters 6 and 7 incorporate References and Appendices  \n\n \n \n    \n \n \n2 \n2 Background \n2.1 An overview of core data assets \nThe core data assets that are the subject of this study include \ndata assets such as land registries, ordnance surveys, \nmeteorological data and transport movements. This data \nincludes data that is purposefully collected (e.g. national \nstatistics and meteorological data) and data collected as a by-\nproduct or some other function (for instance, business \nregistration and court records). These data sets are most \ncommonly referred to as public sector information\n1\n (PSI) as they \nare almost always generated by (or for) public agencies, referred \nto in this report as PSI holders (PSIH).  \nDiscussions on the re-use of data, commonly focus on PSI. However, \nthere are other sources of data. Two other important sources are:  \n• research or science data, especially that arising from publicly \nfunded research, and \n• private sector data. For example, sales data collected by \nprivate sector firms may be useful for economic \nmanagement. \nThere are a great many applications of such data. Coupled with \ngrowth in the growth of applications, there has been growing \nrecognition that such data has great value.  \nThe data can be used to add value in myriad areas of the \neconomy in myriad ways. It: \n• reduces costs in providing services both by government and \nprivate sector (i.e. doing the same for less cost) \n• enables new services and improved quality of services, and \n• improves accountability for government services indirectly \nimproving responsiveness and performance and in the \nprocess engendering greater trust in government. \nMany of the benefits accrue directly to consumers of products \nand services that have made use of the data. However, there are \n                                                        \n1\n  Note, in this report, except where otherwise made clear, the words “data” and \n“information” are used interchangeably. \n\n \n \n    \n \n \n3 \nalso benefits that accrue to the wider community. These benefits \ninclude, for example:\n2\n \n• public benefits associated with improved transparency of \ngovernment \n• improved social cohesion, and \n• positive externalities that may arise. For example, one \nperson’s use of transport data to optimise transport usage \ncan improve traffic management and reduce congestion for \nother users. \n2.2 The value chain for re-use of data  \nThere are many descriptions of the value chain for the re-use of \ncore data assets.\n3\n For our purpose, we propose to describe the \nvalue chain in terms of the following groups: \n1. Data providers – these include PSIH, other government \norganisations and private organisations and individuals \n2. Intermediaries, including \na. data aggregators who source data from existing \nopen data sources into a more useable form \nb. data enablers who facilitate the supply or use of \ndata through reorganisation and reformat \n3. Providers of products and services to consumers \nincluding \na. developers who create applications for individual \nconsumption \nb. data users who use data to enhance existing \nproducts and services or create new ones \n4. End users (being the ultimate beneficiaries), including: \na. direct users of the end product, and \nb. others who indirectly benefit from the open data \nusage by direct users. \nThe connection between the groups is depicted in Figure 1 \nbelow.  \n                                                        \n2\n  This list is adapted from Deloitte (2013, p. 182). \n3\n  See, for example, Deloitte (2013, p. 85), POPSI (2011, p. 14), PIRA (2000, p. \n14) and Vickery (2011, p. 13). \n\n \n \n    \n \n \n4 \nFigure 1: Value chain for core data assets re-use \n \nSource: Lateral Economics.\n4\n \nThe market characteristics of each group are discussed in \nSection 3.3.5. However, we note here that publishers or core \ndata-sets are typically sole suppliers of information because they \nhave privileged (often statutory) access to information, there are \nsunk costs in collection, they receive government funding or \nbecause they have an established reputation for quality. As a \nresult, data providers have (at least some) power in determining \ndata prices. \nReviewing the pricing policy for PSI, a European Commission \nstudy (De Vries et al., 2011, pp. 25-30) finds it useful to \n                                                        \n4\n  Any of the stages of production may be conjoint with any other. Someone using \nGoogle Maps will often be providing data back to the app, for instance, on \ntraffic flow. Data providers may deal with intermediaries or product and service \nproviders and release data to consumers. Further, there may be multiple chains \nbefore reaching the end user. Thus, government data providers may share data \nwith other agencies. Similarly, there may be multiple steps in the value chain \nbefore a product or service is provided to an end user. A 2006 survey of \nbusinesses regarding their use of PSI, found that less than 30 per cent of \nbusinesses used PSI to make products for consumers (OFT, 2006, pp. 28-29). \n \nDirect\tusers\nData\tpublishers\nIntermediaries\nEnablersAggregators\nProduct\tand\tservice\tproviders\nDevelopersData\tusers\nWider\tcommunity\nData\tproduction\n\n \n \n    \n \n \n5 \ncategorise (direct) end users as being high end or low end. It \ndescribes the high-end market as consisting of a relatively small \nnumber of re-users that provide high value-added services to \nmeet the needs of professional clients.\n5\n In contrast, the low-end \nmarket consists of re-users providing low value-added services \nto a large number of clients (e.g. mashing up free content to \nintegrate into other services). Such a distinction may be \nimportant for pricing policies, as the high-end market will be less \nprice sensitive. \n2.3 Estimating the value of open data \nThere is a literature of reasonable size – to which Lateral \nEconomics has contributed – estimating the benefits of open \ndata (defined as data that anyone can access, use and share). \nThis study seeks to measure the contribution of open data to \ngross domestic product, or GDP (which is measured by summing \ngross value added, GVA, through the production chain). Though \nthe limitations of GDP are well recognised,\n6\n it is a convenient \ncommon metric. \nFurther, measuring the impact of some policy requires \ncomparing different reference points (or scenarios). For example, \nthe ‘current’ value of open data might be considered as the value \nthat would be lost should the relevant data not be available. \nHowever, this later, hypothetical, scenario is difficult to envisage. \nIt leads to consideration of what substitutes the market might \ndevelop should existing data be inaccessible. \nThe period over which value is created is also relevant. We are \ninterested in the future, but this may differ substantially from the \npast (which we can measure). Other measurement challenges \ninclude: \n• there are a great many end uses of the products; \n• there is very little data on the end use of the products; and \n• the prices paid by consumers – very often zero – will \ngenerally be significantly less than the value derived. \n                                                        \n5\n  De Vries et al. (2011, p. 25) give the example of a meteorological company that \nprovides very detailed weather forecasts to oil rigs, based on enhancing PSI \ndata. \n6\n  More broadly, government policy should generally be concerned with wellbeing \nfor citizens in the present and the future.  \n\n \n \n    \n \n \n6 \nThus we risk significantly, perhaps hugely, underestimating the \nvalue of data if we derive values from observed prices. \n2.3.1 Empirical studies \nEconomic evaluations of the impact of open data may focus on \nparticular applications or, as in this study, the whole economy. \nSimilar economy-wide evaluations have varied in scope. Notable \ndimensions include: \n• The sources of data considered. Most studies have focussed \nonly on PSI. Other studies also consider the value of \nresearch data and private sector data. \n• The region considered. Most studies have been limited to a \nsingle country (e.g. the UK) or a select group of countries \n(e.g. the G20). \n• Sectors considered. Some studies have focussed on a \nspecific sector (e.g. transport).  \n• The scope of benefits considered, in particular, whether \nwider benefits (such as relating to reduced corruption) are \nincluded. \n• Whether the value considered is an existing value or some \nmeasure of potential value. Some studies have just focussed \non the net benefits; that is the value added less the cost of \nproduction. \nIn Table 1 below, we summarise estimates derived from the \nresults of some key studies. To facilitate comparison, for some \nstudies we have applied some additional analysis to the results \npresented in the study (see footnotes to the table) and for \nconsistency and convenience we express these as a percentage \nof GDP.  \nThe table is divided into two sections. The top section describes \nstudies that have attempted to measure the current contribution \nof open data. The bottom section refers to two recent studies \nthat attempt to estimate the potential additional contribution of \nopen data. \n  \n\n \n \n    \n \n \n7 \nThe approaches used vary. The approach used by PIRA (2000) \nhas been described as “top-down” as it begins with value added \nand then attempts to assess the contribution of data to the value. \nOFT (2006) contrasted this with a bottom-up approach which is \nbased on attempting to estimate the value derived (interpreted in \nterms of willingness-to-pay) by consumers.\n7\n  \nWe expect the values of open data (as a percentage of GDP) to \nincrease over time due to the rapid expansion of new \napplications and the greater opportunities for re-use by \nconsumers as a result of increased penetration of digital devices. \nThe narrowest scope scenario we might consider is the current \nnet benefits to direct users. The widest scope is future gross \nvalue added from PSI and other data to direct users and the \nwider economy. For the purposes of evaluating the issue of paid \naccess for core data sets, we propose the appropriate reference \npoint is core data assets , broad in terms of beneficiaries, and \nincorporating the value added in the near term (i.e. more than is \njust presently realised). \nBased on the existing studies, we concluded that the current \nGVA of core data assets to the economy is in the order of 0.4-1.4 \nper cent of GDP. \n                                                        \n7\n  OFT (2006, p. 114) raised the concern that the top-down approach risks \noverestimation in part because it takes no account of the possible use of \nalternative data sources that might be used. Conversely, a risk of the bottom-up \napproach is underestimation, not least because of difficulties in accounting for \nwider impacts.  \n\n \n \n    \n \n \n8 \nTable 1: Estimates of the value of open data \nStudy (year) Country/ \nregion \nMeasure estimated As % of \nGDP \nGVA % \nof GDP \nStudies estimating current value  \nPIRA (2000) PSI in \nEurope \nTotal value added of PSI  1.4% \nDotEcon \n(2006) \nUK Net surplus (i.e. net of costs \nof supply) of PSI, excluding \nwider economic benefits \n0.25% n/a \nMEPSIR \nstudy (2006) \nEU25 + \nNorway \nMarket size for PSI, excl. \nwider economic benefits \n0.25% n/a \nPollock (2011) UK Welfare gains of opening up \nof PSI in 2006 \n0.11-\n0.13% \n0.3-\n0.4%\n8\n \nVickery (2011) Europe \nPSI \nGVA of PSI in 2008 (incl. \nwider economic benefits) \n 1.2%\n9\n \nDeloitte \n(2013) \nUK PSI GVA of PSI (incl. wider \neconomic benefits) \n 0.4%\n10\n \nStudies estimating potential benefits  \nMcKinsey \n(2013) \nGlobal Potential additional value 1.4%\n11\n n/a \nLateral \nEconomics \n(2014) \nG20 \ncountries \nPotential additional value \nfrom selected case studies \n1%\n12\n n/a \nSource: Lateral Economics analysis. See Table 2 in the appendix for further \ndetails. A summary of many of the studies is provided at Lateral Economics \n(2014, sections 3.2 and 3.3). \n                                                        \n8\n  Extrapolated from results and parameters of median estimate reported in \nPollock (2011). The author had estimated the welfare gain of moving to free \nand open-access. We applied the core assumption and parameter values to \nestimate the value of open data to GDP. \n9\n  Vickery’s method was based on extrapolating estimates from previous studies.  \n10\n  We are not clear as to how this estimate was derived. \n11\n  See Lateral Economics (2014, p. 30). This is the estimated contribution to \ncumulative GDP growth over the next five years.  \n12\n  See Lateral Economics (2014, section 3.5). \n\n \n \n    \n \n \n9 \n3 Implications of a paid-access regime \nThis chapter examines the contrasting economic implications of paid \nand open access to data. It begins with a description of the alternative \nregimes. To assess the economic impact of a paid-access regime \nrelative to an open-data regime, one must first identify and describe the \nimplications of paid access relative to open data. Subsequent sections \nexplore specific aspects of the economics of data. \n3.1 Charging regimes for data \nThis review compares paid- and open-access regimes. It is useful to \ndistinguish between multiple models including:\n13\n \n• Paid access  \no profit maximisation — whereby the data provider sets \nprices to maximise its profit \no cost-recovery of data production — pricing to recover the \ncosts of data production \no cost-recovery of initially establishing data distribution for \nre-use \no marginal cost pricing of additional distribution — setting a \nprice equal to the cost of supplying data to an extra user, \nwhich for digital data is essentially zero, and \n• Zero-priced access — where data is not charged for but subject to \nrestrictions on its use and redistribution. \n• Open data  — data that anyone can access, use and share.\n14\n \nGenerally, we would expect the prices charged and the revenues \nraised to be lower as we move down the list above.\n15\n  \n                                                        \n13\n  This list is adapted from Pollock (2008, p. 8). Pollock also notes that many \nPSIHs also have the ability to charge those parties providing updates to the \ninformation. For example, PSIHs dealing with registration of property, vehicle \nand company ownership may fund their data collection and processing \nactivities from those registering the item. \n14\n  See http://theodi.org/blog/closed-shared-open-data-whats-in-a-name.  \n15\n  A risk with subsidised supply is that there will be an excessive supply (e.g. \ninvestment in the provision of data). Conversely, there is the risk that there will \nbe insufficient incentive for investment. However, there will be exceptions, \nparticularly where demand is very responsive to price. De Vries et al. (2011) \nnoted cases where the lowering of prices resulted in increased revenues. \nFurthermore, as discussed below, a profit maximising data provider might \nemploy a mix of pricing strategies. Another argument for cost recovery is that \n\n \n \n    \n \n \n10 \n3.2 Implications of different access regimes \nTo assess the implications of different access regimes, we first \nconsider the common rationale for paid access before considering \nissues particular to open data. \n3.2.1 The common rationale for paid access  \nIn most markets, users pay, and this is highly efficient. User charges \nensure that resources needed to provide services are taken up only \nwhere their value is demonstrated by users’ willingness to pay. In this \nway, data consumers decide whether or not to fund the collection and \ndissemination of that data. In terms of the charging schemes discussed \nabove, the argument often leads to an incremental cost charging \nregime, whereby the supplier (in this instance, the data provider) \nrecovers the incremental cost of providing access.\n16\n A pricing regime \ncan, therefore, send a signal as to the optimal investment.\n17\n  \n3.2.2 ‘Abundance thinking’: The economics of information \ngoods \nHowever, while the fixed costs of data provision is often large, marginal \ncosts of additional dissemination are often negligible. If prices are set \nabove marginal cost, then additional use will be discouraged even \nthough its benefits exceed the (negligible) additional costs. As in many \nother industries, marginal cost pricing leads to an under-recovery of \ncosts as there is no revenue to fund fixed costs. In essential services, \nsuch as energy and water, the problem may be addressed with two \nsets of charges corresponding to fixed and marginal costs. However, \nsuch a strategy is only effective when the fixed price does not deter \naccess.\n18\n Outside government, very low marginal costs of information \n                                                                                                                        \nthe alternative suggests raising additional taxation revenue. This is costly \nbecause taxes generally distort behaviour away from what is socially optimal. \n16\n  As is discussed in Section 3.2.2.1, profit-maximising pricing can also be \nefficient under the (albeit seemingly rare) conditions that the supplier is able to \ndifferentiate its charging so as to capture any consumer surplus. \n17\n  With regard to open data, this is likely to be the greater risk. As noted by \nPollock (2008, p. 13), requiring an organisation to charge at less than average \ncost can reduce the incentive for the organisation to develop new products. \n18\n  Two-part pricing is also operative on the internet where internet service \nproviders typically charge a fixed fee for access to the internet and nothing \nfurther for use (sometimes up to some cap on data usage).  \n\n \n \n    \n \n \n11 \nprovision has produced various business models. In most services for \nthe mass market, resources are provided by means other than prices.\n19\n  \n3.2.2.1 Profit maximisation and price discrimination \nA concern with paid access is that the data publisher will attempt to go \nbeyond the recovery of incremental costs and instead maximise its \nprofit\n20\n Prima facie this would increase prices and further reduce \ndemand. However, there are additional considerations. Profit \nmaximisation may stimulate demand by price discriminating; charging \nusers different prices depending on their willingness to pay.  \nIn principle, perfect price discrimination is as efficient as perfectly \ncompetitive pricing, but the informational and behavioural demands on \nthe seller to bring this about are Herculean.\n21\n In practice, price \ndiscrimination is usually difficult and can result in additional waste. \nSuppliers of information goods adopt a number of strategies. These \ninclude: \n• Discriminating using quality of product or service whereby a lower \nprice is offered for lower quality products. Common strategies are: \no Windowing – whereby the product is brought to market at \ndifferent times in different formats. For example, films are \nreleased first in the cinemas and then at a later date onto \nother mediums.  \no Versioning – whereby the product is released with differing \nlevels of quality.  \no Service modifications – whereby there are differences in \nthe level of support. \n• Bundling, whereby to obtain a product, consumers are required to \npurchase a bundled package. \n                                                        \n19\n  Open-source software leverages the voluntary efforts of software users fixing \nbugs or adding features. Wikipedia uses philanthropy to run a platform that \nusers volunteer their time on. Facebook, Twitter and Google provide their \nservices for free while ‘monetising’ the social value they create from advertising \nrevenue. Elsewhere a dominant strategy is ‘freemium’ – a form of price \ndiscrimination we explore further in the following section. \n20\n  By this term, we do not mean marginal costs, but rather the full cost arising \nfrom the public distribution of the data. This may involve the full costs of all data \ncollection, curation and distribution, or where governments already collect \nand/or curate the data in any event, all additional costs in curating and hosting \nthe data for public release. \n21\n  Thus each buyer’s willingness to pay must be known and charged without \nanyone arbitraging the differences in prices in the downstream market. \n\n \n \n    \n \n \n12 \nWhere lower quality products generate inconvenience or lower utility to \nthe consumer, whilst saving the producer nothing, economic losses \narise.\n22\n  \nFreemium  \nThere is a growing army of products funded through ‘freemium’ \nbusiness models in which data and other services are freely distributed \nwhilst those seeking higher levels of quality or service pay. Free \nservices are effective marketing including lowering buyers’ transactions \ncosts by allowing them to ‘try before they buy’. Freemium products \ninclude LinkedIn, Google Apps, Evernote, Dropbox, Feedly, Pocket.  \nChris Anderson (2009) coins the term ‘abundance thinking’ to describe \nthe mindset that produces ‘freemium’ pricing – making the abundance \nof the digital world and its zero marginal cost of production – work for \nconsumer and user alike. As Gruen (2015, p. 5) puts it, while funding \nthe fixed costs of these services raises the free rider problem, the near-\nzero marginal costs of expansion mean that the free rider opportunity \nwill often trump the free rider problem. \nGiven all this, it is likely that a sophisticated profit maximising data \nprovider would do considerably less harm than might be expected if a \nfirm were to price its data products crudely. It is even possible to \nimagine circumstances where profit maximisation would provide \nincentives to invest in additional data collection, curation and quality \nassurance work, and that this could increase economic welfare above \nthe level that might be achieved by a relatively mediocre government \nagency administering government mandated policies of open data.\n23\n \n                                                        \n22\n  Since the price discriminating firm’s sole interest is to maximise its access to \nconsumer surplus without regard to the resulting disutility to customers, it may \ndo more harm to the total utility to consumers than its expansion of supply \nbenefits economy-wide welfare. These issues are not new. The economist \nJules Dupuit raised concerns in 1849 with regard to price discrimination of \nrailway carriages with little left undone to make conditions unpleasant for third \nclass passengers, not to save costs, but to avoid second class passengers \nbuying third class tickets. Today’s mobile phone packages may well provide a \ncontemporary example of price discrimination which lowers general wellbeing \ngiven the additional costs of staying within plans and the cost of informing \noneself of their respective terms. Nevertheless, the digital age gives us a new \ntwist as the complexity of modern mobile phone plans also establishes a \n‘confusopoly’ making it harder for consumers to understand various trade-offs.\n  \n23\n  Google Maps has invested substantial sums in generating and curating data for \ndistribution which it can monetise by charging premium users. Nevertheless, it \noffers free access to a standard product for the vast bulk of direct users of the \nservice. https://developers.google.com/maps/pricing-and-plans/#details  \n\n \n \n    \n \n \n13 \nNevertheless, it seems unlikely, and there are further risks in such a \ncourse. First, the entrepreneurial flair of a highly innovative profit \nmaximising incumbent might give way to more complacent behaviour in \nthe future in which a more mature firm’s managers use their monopoly \nposition to meet quarterly revenue and profit growth targets. Second, \nthe data would almost certainly be distributed according to licencing \nrestrictions which is likely to seriously curtail economic welfare (see \nSection 3.2.3 below). Third, if we can imagine excellence in \nharmonising general economic welfare with profit maximisation, we can \nsurely imagine excellence in the public sector which can target \neconomic welfare more directly without the additional imperative of \nprofit maximisation with all the distortions it entails here. \n3.2.3 Transactions costs \nThe transactions costs borne by consumers and the suppliers differ \ngreatly between access regimes. The process of vending data is almost \nby definition more complex than simply disseminating it for free. The \ncosts to the supplier include administrative costs such as invoicing, as \nwell as costs of managing a licensing and compliance regime, and De \nVries concluded they were significant (2011, p. 6). They include: \n• Building an online sales environment where the qualities of \ndata are described pending their sale. \n• Building the relevant security layers or sub-contracted platform \nservices to take commercial payment. \n• Commissioning the work to know what kind of licensing terms \nto impose and then the legal work to design those terms. \n• Considering whether or not to take action against those who \nbreach them and, if so, funding that.  \nNevertheless, there are potentially more profound forces at work. \nInformation is a non-rival good. Use in one application does not \npreclude use in another. And with near zero costs of distribution, even \nsmall transactions costs can be a big deal as has been recently \nillustrated on the internet (See Box 1 below).  \n\n \n \n    \n \n \n14 \nBox 1: The significance of transactions costs on the net \nThe global phone network and the internet are both built around \n‘interconnect’ agreements in which nodes on the network \nexchange access to each others’ users. The phone network \nfacilitates dedicated connections between users. So large telcos’ \nnegotiate interconnect agreements fiercely, with each seeking to \nmaximise its ‘cut’ of the economic rent.  \nThe internet works by routing addressed data packets, each \nmaking its own opportunistic way through the net depending on \nnetwork conditions. If someone won’t negotiate interconnect \nreasonably, others can be found and, so, few are tempted to \nnegotiate unreasonably. As a result, transactions costs between \nservice providers negotiating reciprocal access to each others’ \nservices collapse. Virtually all - 99.5 per cent – of reciprocal \naccess agreements occur informally without written contracts. \nWhat does this mean for efficiency and productivity? On an \nequivalent voice-per-minute rate, internet rates are around one \nhundred thousandth of typical voice rates. \nThe collapse of transactions costs in cyberspace has led to the \nburgeoning of new social and economic formations. Anyone – \nincluding (crucially) any innovator – can access the network \nwithout requiring the permission of, or paying rent to, monopolistic \ngatekeepers – as one must with telephone or TV networks.  \nAdapted from Gruen (2012). \nPrices impose transactions costs on users and, given that they are \nborne by each user, they constitute a potentially much larger source of \ndeadweight loss. These costs not only include administrative costs \nsuch as those associated with reviewing licence agreements and \nmaking financial transactions but also — as described by Szabo (1999) \n— “mental transaction costs” to consumers. Szabo has categorised \nthem into costs associated with dealing with uncertain cash flows, \nobserving product attributes and complexity of decision making. If these \nare ‘cognitive’ costs, there are also ‘psychological’ transactions costs. \nAs Chris Anderson has documented (2009), free is a very special price \nand, for many consumers, a quantum leap beneath very low prices. \nFree means free of the risk of losing money, free of being taken \nadvantage of, free to trust or to suspect vendors after inspecting their \ngoods.  \nThe implications of transaction costs are demonstrated in the figure \nbelow, which documents the huge rise in the availability of book titles \non the market once copyright expires. The paradox is that there is \ndemand for books from which publishers and copyright owners could \nmake some profit (as the sale of out of copyright books demonstrates), \n\n \n \n    \n \n \n15 \nwhich they nevertheless forego. In other words, in the absence of \ntransactions costs, one would expect more book titles to be in print \nduring the copyright term rather than less, because the copyright \nincreases the potential profit in their sale. And the magnitude of the \neffect is large – with book titles reduced by over 80 per cent.  \nFigure 2: Book titles in print from Amazon warehouse by decade \n \nSource: Rosen, 2012.  \nThere are also other costs to consumers to consider. A significant risk \nto commercial users of open data is that future supply will no longer be \navailable or its quality will fall or that access will become more limited. \nSuch concerns are in effect a cost borne by consumers. In sum, the \ntransactions costs associated with charging for data and/or licensing \nthat data to control redistribution can be substantial, but largely \ndisappear under an open-data regime.  \n3.2.4 Network externalities and innovations \nFor many information goods, and in particular for data assets, both the \nsupply and consumption of data can stimulate greater demand for \nseveral reasons. First, there can be consumption externalities. Thus, \nfor instance, people using real-time transport data to avoid congestion \nlower congestion for everyone. Second, the rate of adoption of a \nparticular service may increase with the penetration of the market due \nto the social influence of early adopters on later adopters.\n24\n  \n                                                        \n24\n  For example, persons who use a data-enabled app (e.g. that provides real-time \ntransport) may do so because they were told about it by a friend and/or \ninfluenced in their decision to adopt it from observing others. Such effects are \ncommonly discussed in the literature on ‘diffusion of innovations’. \n\n \n \n    \n \n \n16 \nThird, there are network effects associated with different re-use. Great \nvalue can often be derived when data sets are integrated with one \nanother; for instance, TripAdvisor adds to the accumulated value of \ngeospatial data and customer ratings data to help people identify and \nfind travel destinations to their taste. Greater value still could be \ngenerated if its maps also integrated with live transport data. The \ngreater the number of data-sets accessible, the lower the technical and \ncommercial barriers to their integration, the greater the value generated \nby each data series. \nFinally, there are supplier network effects. Increasing the number of \ndevelopers using a particular data-set can stimulate additional \ndevelopment through a number of mechanisms. Greater re-use can \nresult in economies of scale in the provision of intermediary services \n(i.e. by aggregators and enablers). Perhaps more significantly, there \nare network benefits in terms of innovation as developers help each \nother out in developer communities. Prima facie, we might expect that a \ncharge on information would not materially inhibit the development of \nan innovation where the benefits far exceed the information costs.  \nHowever, empirical evidence suggests that even a small charge may \nsignificantly impede innovation.\n25\n There are several reasons for this.\n26\n \nFirst, the returns to the innovation may be highly dispersed among \nsuppliers. The parties purchasing the data may not expect to recoup \ntheir investment as most of the value is captured further down the value \nchain. Second, the cost of obtaining information (including the costs \nassociated with licensing) may need to be borne by multiple parties \ninvolved in development. Third, sellers are unlikely to know of all the \nways their data can be valuable to others, and the magnitude of that \nvalue and this uncertainty is likely to make negotiating access a fraught \nprocess as each party seeks to capture what it sees as its share of \nbenefit.  \nThe combination of the above effects have prompted a number of \nparties to argue that the priority strategy for information goods should \nbe on abundance of use as this will in turn stimulate greater supply and \ndemand.\n27\n \n  \n                                                        \n25\n  Pollock (2008, Appendix A2) notes that “Weiss (2004) argued, marginal cost \naccess to weather data in the US was a large factor in the development of the \nmulti-billion dollar weather derivatives industry”. \n26\n  Some of these are discussed by Pollock (2008, Appendix A2). \n27\n  There appears to be broad support from researchers (e.g. Pollock 2011, \nVickery 2011, and Shakespeare 2013) for open data. There is also public \nsupport. De Vries et al. (2011, pp. 10-12) note that the majority of responses \nfrom public consultation were in favour of free access. \n\n \n \n    \n \n \n17 \n4 Estimating the impact of a paid-\naccess approach \n4.1 Overview and approach \nThe discussion above highlights why, for several reasons, paid access \nresults in sub-optimal re-use of data. To estimate the impact of paid-\naccess, we have used the estimates from Chapter 2 on the value of \nopen data as a baseline. In effect, we are estimating the economic \nvalue lost through paid access. \nThe impact of paid access relative to open data depends in part on \nwhich paid-access pricing approach is employed; whether, for instance, \nit focuses on profit maximisation rather than cost recovery. The next \nsection considers methodological issues. \n4.2 Basic approach \nThe difference between open access and paid access to data is \nillustrated in Figure 3 below. It shows the demand for core data assets \nand the ‘effective price’ paid under different pricing regimes. We have \ndefined the ‘effective price’ as the financial cost plus the costs \nassociated with complying with any licence agreements. Of note, this \nprice under a free-but-restricted regime is greater than zero.\n28\n A shift \nfrom open data to ‘free but restricted’ will increase transactions costs \nfor sellers (see above) and may also raise ‘mental transactions costs’ \nfor consumers. It is also likely to depress indirect demand for the data \nby those who might have otherwise received the data through the initial \ncustomer, but did not because the customer was not authorised to pass \nit on.\n29\n The indicative shape of the demand curve in Figure 3 is \nconsistent with the conclusions of De Vries et al. (2011, pp. 25-30) who \nargue that sufficient price reductions open up a large low-end market. \nThe supply curve (which reflects the marginal cost of supply) varies by \nregime. Under open access it is, in effect, the horizontal axis.\n30\n Another \nrelated effect not captured in the illustration is that under paid-access \n                                                        \n28\n  There are potentially alternative ways of illustrating this additional impact, (e.g. \nincluding a separate demand curve) however, this seemed the simplest \napproach.  \n29\n  Thus, for instance, if Hansard data was only available directly to users, but not \nfor free redistribution, the organisation They Work For You, \n(http://www.theyworkforyou.com/) which substantially increases the distribution \nof Hansard information, might have been discouraged from distributing it. \n30\n  More precisely the marginal cost of supply is high for the first consumer but \neffectively zero for each subsequent user. \n\n \n \n    \n \n \n18 \nregimes, the cost of supply also shifts upwards (from zero to a positive \namount).  \nFigure 3: Demand for core data assets under different pricing \nregimes \n \nA shift between charging regimes will be associated with a change in \nthe value added and societal welfare. However, there are several \nproblems with attempting to quantify these effects. Estimating the \ndemand is particularly difficult. There is some information collected on \ndemand and how this responds to changes in price;\n31\n however, this will \nnot be representative of the welfare associated with open data.  \nAs Pollock (2008) notes, there are two key issues. First, data is \ntypically distributed to intermediaries and developers, not end \nconsumers. The demand information captured, therefore, does not \nrepresent what the final consumers are willing to pay and the welfare \ngains to consumers. Because data can be re-used at negligible cost \nand developers are not able to capture many of the resulting consumer \nbenefits, they are likely to underestimate them by a considerable \namount. With much of the data supplied at zero price, there is no \nmarket signal of its value.\n32\n \nSecond, the information captured will represent the demand when it \nwas captured, yet with the rapid change that characterises the area, the \npresent may be a poor guide to the future. \n33\n  \n                                                        \n31\n  Pollock (2008) provides a useful summary. \n32\n  For example, simple economic accounting for the value of Google would \nsuggest that it is limited to its value as an advertiser, yet more sophisticated \nattempts to measure its economic value produce conservative estimates \nseveral times higher than this with debate ranging from ten to one hundred \ntimes the amount directly recorded in GDP. See Worstall (2015).  \n33\n  There are numerous additional issues in measurement. For example, the \nvolume of direct access to a data-set may decrease as a result of consumers \nPerceived  per\n-\nunit  cost  to customers\nFree but \nrestricted\nAccess regimes for data assets\nIncremental \ncost recovery\nopen-access\nQuantity of info. utilised\n\n \n \n    \n \n \n19 \nAnother set of issues relates to assessing the pricing regimes that \nmight emerge. As we discussed in Section 3.2.2.1, an organisation \nmight employ a variety of pricing strategies and business models, \nincluding approaches that simultaneously seek to maximise profit and \nre-use. \n4.3 Modelling the effect of changing price \nregimes \nIn this section, we estimate the effect of a shift between paid and open-\naccess pricing regimes. Our initial focus is on the change between cost \nrecovery and open data. We then consider the implications of a profit-\nmaximising pricing regime in which price-discrimination policies might \nbe applied. \n4.3.1.1 A model for estimating the impact of paid-access  \nA useful starting point is the work of Pollock (2008 & 2011). \nConsidering a number of the limitations itemised above, Pollock \ndeveloped a model to estimate the welfare effects of moving from \naverage cost to marginal cost pricing for PSI as a function of.  \n• the fixed costs incurred in producing and maintaining the PSI \n• the responsiveness of direct consumers (technically the price \nelasticity of direct demand), and \n• a demand multiplier that reflects the difference between direct \ncustomers’ willingness to pay and the total value provided to all final \ncustomers, many of whom have no direct relationship with the data \nprovider. \nOf course, the challenge with this approach is obtaining reasonable \nestimates for the key parameters. The fixed costs of providing data may \nbe estimated with a reasonable degree of certainty; however, direct \nobservation of the elasticity of demand and the demand multiplier is not \npossible. Pollock offers estimates of elasticity and the demand \nmultiplier based on a review of evidence from several sources.  \nPollock’s model (summarised in Box 2 on page 31 in the appendix) is \nreasonably intuitive. The more elastic (price responsive) the demand, \nand/or the greater the multiplier, the greater the loss from charging for \ndata. \n                                                                                                                        \nchoosing to access the information via new applications developed by \nintermediaries. For example, all else being equal, the volume of direct users of \nmeteorological data sets may fall as a result of the development of weather \napps on smart-phones that access the data via intermediaries. \n\n \n \n    \n \n \n20 \nUsing his model, Pollock (2011) estimated the welfare gains in the UK \nin 2011 from ‘opening up' (i.e. moving to marginal cost pricing). His \nestimates ranged from 0.11 per cent to 0.4 per cent of GDP, around \nfour to 11 times the cost of providing PSI.  \nA study on Danish address data (DECA 2010) provides one opportunity \nto test the estimate. The study estimated that the annual benefits of \nopen address data were EUR 14 million at an annual ongoing cost of \nEUR 0.2 million. Other information in the report suggests the cost of \nproviding the data was higher. Nevertheless, the case study provides a \nresult that is above the higher range estimated by Pollock.\n34\n   \n4.3.1.2 Refining the model \nPollock estimated the change to a marginal cost pricing regime, under \nwhich he notes it would be “natural for the PSIH to make the data \n‘openly’ available” (2008, p. 9). However, our interpretation is that the \nmodel and parameter estimates are more consistent with a reduction in \npricing and not a removal of restrictions on use. In particular, Pollock \nassumed that the demand curve is linear (i.e. does not curve as \nillustrated in Figure 3) and uses evidence of elasticity estimates that \nincluded cases where prices were reduced but were not made free.  \nAs discussed in section 4.2, we expect that transaction costs for uses \nof data are significant and that, as a result, demand will expand \nsignificantly when moving from a free-but-restricted regime to an open-\ndata regime. To account for this, we extend Pollock’s model to include \na kink when transaction costs are removed (see appendix 1 for details). \nThis approach brings new challenges. As discussed below, there is \nsome anecdotal evidence on the increase in direct demand when \nshifting an open-access regime is introduced.  \nHowever, we must place a value on that additional demand. There are \na number of considerations. In standard economic models, all \neconomic agents have perfect knowledge and are perfect competitors \nand this means that lower priced uses are lower value uses. We take it \nas a reasonable assumption of the more complicated reality.  \nGenerally the assumption will be reasonable, but it will impart a \ndownward bias on estimates of the value of open data. The increased \nsearch facilitated by negligible transactions costs will probably facilitate \nthe serendipitous discovery of some unanticipated high-value uses. \n                                                        \n34\n  Other information in the DECA (2010) report indicates that the cost of \ndistributing PSI had been higher. The paper reports the costs of the agreement \nover 5 years to move to open data were EUR 2 million (i.e. EUR 0.4 million per \nyear). Using this latter figure gives a benefit to cost-of-provision ratio of 35 to 1. \nHowever, this is unlikely to be indicative of the average result as high value \nopportunities are more likely to be enacted, studied and reported. \n\n \n \n    \n \n \n21 \nAnd the value of both existing and new uses will probably be magnified \nby the strengthened network externalities associated with burgeoning \nre-use. \nWe also expect that the average value added lost by transaction costs \nwill be related to the size of these costs. That is, the greater the \ntransaction costs, the greater the average value added that is lost. To \naid calculation, we assume that the value added per new re-use under \nopen data is in direct proportion to the size of the transaction costs that \nare removed in moving to open data. \nUsing a model described in the appendix, we can estimate the change \nin GVA as follows  \nGVA under open-access regime\nGVA under cost-recovery regime\n=1+\n푒\n푓\n+푡푒\n표\n2+1/푒\n푓\n \nWhere: \n푡=\n푝\n!\n푝\n!\n  \nthe ratio of transaction costs to the monetary costs \npaid by direct users under incremental cost \nrecovery \n푒\n!\n=\n푞\n!\n푞\n!\n \nthe increase in demand from a cost-recovery \nregime to a free-but-restricted regime \n푒\n!\n=\n푞\n!\n푞\n!\n  \nthe additional increase in demand from a free-but-\nrestricted regime to an open-access regime \nFollowing’s Pollock (2011)’s work, we use an estimate of 푒\n!\n=2 and, \ntherefore, the above equation can be simplified to: \nGVA under open-access regime\nGVA under cost-recovery regime\n=1.8+0.4푡푒\n!\n \nBased on other case studies (see section 7.3), we think it reasonable to \nsuggest that 푒\n!\n is around 2 to 4 (with a midpoint of 3). \nFor the parameter t, we have found no existing estimates. Based on \nour experience on similar issues and our own experience in acquiring \ndata, we think it conservative to suggest that these transactions costs \nare around one-third of the financial costs of a purchase.\n35\n In such \ncases, using the above formula, we have a GVA under open data of \naround 2.2 times the GVA under a cost-recovery regime. \n                                                        \n35\n  In considering this issue, we considered the time taken to review agreements \nand the ‘mental transaction costs’ of adhering to the agreements. In our \nexperience these costs increase with the financial value of the contract and \ntherefore the (average) value of the t parameter may not vary significantly with \nhigher-cost data sets. \n\n \n \n    \n \n \n22 \nIf we were to use recent estimates of GVA under a cost-recovery \nregime of around 0.4 per cent of GDP, then the GVA under an open-\naccess regime would be in the order of 0.9 per cent; that is, an \nadditional 0.5 per cent of GDP. \n4.3.1.3 Shifting between other pricing regimes \nThe above analysis considered the implications of changing from cost \nrecovery to open data. The impact would probably be less moving from \nopen data to cost-recovery pricing because many benefits of open data \narise from the way it facilitates the search for new data applications. \nOnce established, many will likely remain.\n36\n \nIt is also of interest to consider what might occur when shifting between \nprofit maximisation and open data. As discussed above, profit \nmaximisation may involve more complex pricing strategy – for instance, \ndifferentiated pricing such as ‘freemium’ to encourage re-use amongst \nlower value users. \nUltimately, the impact of profit maximisation depends on the strategy \nadopted by the organisation. At one extreme, an organisation \nintroduces a simple charging mechanism that aims to maximise the \nshort-term revenue from the data. At the other extreme, an organisation \nadopts a strategy that attempts to optimise profits over the longer term \nand/or across a broader business base.\n37\n A third possibility is \nsomething in between, whereby attempts to implement differentiated \npricing result in waste.  \nClearly, the change in GVA between these two extremes is large. \n                                                        \n36\n  Note, however, as the example of Amazon book titles in print suggests, that \nthose with an interest can still leave ‘money on the table’ where transactions \ncosts offset its value sufficiently. Nevertheless, once data has found its way into \nuseful applications, makeshifts will often be found to maintain these \narrangements generally by way of renegotiations of access to the data. \n37\n  For example, Google Maps offers differentiated pricing regimes which \nencourage re-use by small users and attempts to recover costs from greater \nabundance of use. \n\n \n \n    \n \n \n23 \n5 Further matters \n5.1 Implications across the value chain \nHow will the value of free and open data accrue through the data value \nchain introduced in sub-section 2.2? \n5.1.1.1 Data publishers \nData publishers could use their market power to maximise profits, \nincreasing profits in the short term. However, we doubt this would be \nsubstantial for several reasons. First, the public good nature of digitised \ndata makes it difficult for any publisher to capture much of the \nconsumer surplus generated. To prevent downstream competition \nbetween direct customers receiving their data, a data publisher seeks \nto control distribution, removing competition in downstream markets; \nhowever, this would likely lead to problems. If the data provider is not \nvertically integrated with the data developer, there is a risk of double \nmarginalisation whereby both monopolists attempt to maximise profit \nand, in combination, reduce the value they obtain.\n38\n The data provider \nmay attempt to solve the problem by vertical integration; however, this \nis likely to be relatively inefficient as it results in the data provider \nundertaking services outside its core capability. \nSecond, often some form of substitute can be generated. For much \npublic data, there are potentially other (though sometimes more \nexpensive or less efficacious) ways of obtaining substitute data. Thus, \nfor instance, if it is no longer possible to obtain data from traffic \nauthorities on the speed of traffic, or if it has risen in price, one can \nseek it from mobile phone carriers who can measure the speed of \nmobile phone movement on the road. Third, there are substantial costs \nassociated with employing charging mechanisms to counter the issues \nabove. The combination of these factors suggests that charging may \nsignificantly increase costs whilst reducing demand. \n5.1.1.2 Intermediaries \nData aggregators \nData aggregation involves compiling existing open data sources into \nmore useable forms.\n39\n Typically, aggregators provide basic access for \nfree and charge for higher value-added services. Aggregation appears \n                                                        \n38\n  This problem is known as double marginalisation. \n39\n  There are several companies that offer data aggregation services. An informal \nreview of some companies is available at http://www.eveahearn.com/judging-\nopen-data-aggregators/ (accessed 22/1/2016). \n\n \n \n    \n \n \n24 \nto be competitive. There appear to be few material barriers to entry into \nthe market, though we expect substantial investment is required in \nsystems and marketing and, therefore, the primary market will be \ncontested by a discrete number of larger firms with smaller \norganisations competing in niches. \nGiven this, we expect a shift to charging would see aggregators \nnegotiating with publishers over pricing in the short term with \naggregators’ profits falling somewhat. Over time, the market will adjust \n(e.g. with some aggregators exiting or new entry falling) such that the \naverage profitability of aggregators remains relatively stable. \nEnablers \nCore data assets  are often in a format that developers find difficult to \nwork with. So-called ‘enablers’ address this problem by further \nprocessing the data, for instance, by providing an application program \ninterface (API), a set of routines, protocols, and tools for building \nsoftware applications.\n40\n The market for enablers appears similar to that \nof aggregators, with substantial fixed costs but no barriers to entry and \nplenty of room for competition and for self-provision amongst its \ncustomers. \n5.1.1.3 Product and service providers \nBroadly, there are two types of product and service providers: \n• Developers who create applications for individual consumption \n• Data users who use data to enhance existing offerings \nIn the ‘developer’ market, there are no material barriers to entry. \nHowever, the success of any product may be highly uncertain. The \n‘data user’ category consists of providers of established products. In \nthese markets, the suppliers of products may have some market power. \nThe enhancement to the established products may result in a greater \nreturn to those established providers. The ‘data user’ beneficiaries will \ntypically include other government organisations,\n41\n who would, we \nexpect, pass on the value to the public through improved services or \nreduced costs.  \nFor example, the increased re-use of core data assets has increased \nthe value to final consumers from owning smart mobile devices to the \nbenefit (greater producer surplus) of those suppliers of such devices. \nNevertheless, competition (or the threat of competition) will typically \nlimit the extent to which such providers will be able to capture the \n                                                        \n40\n  An example of an enabler is http://www.transportapi.com/. \n41\n  For example, DECA (2010, pp. 2, 5) concluded that around 30 per cent of the \nbenefits from open access to Danish address data accrued to the public sector. \n\n \n \n    \n \n \n25 \nvalue. Furthermore, the greater re-use of data will reduce profits of \nsuppliers of products that are displaced by the data re-use. A simple \nexample is that of providers of maps whose business has been \ntransformed by digitisation of data. \n5.1.1.4 Consumers  \nAs indicated in this sub-section 5.1.1, competition through the value \nchain will deliver most of the additional value created from open access \nto end data consumers. \n5.2 Timing \n5.2.1 Timing of effects \nWe outline below a number of what seem reasonable scenarios \nregarding the timing of market effects. The time period over which the \ndemand impact modelled in section 4.3 should be regarded as \nreasonably short (in the order of one or two years), suggesting that the \nfull effects of shifting from paid access to open data are felt reasonably \nquickly. \nHowever, there are some other considerations. The studies referred to \nchanges in direct demand which will include intermediaries and \ndevelopers. There will be a lag — which may be quite significant — \nfrom the time that developers acquire the data to the time that value is \nrealised in the form of products and services and widely adopted in \nsociety . \nThe speed of change will also depend on the direction of change. The \nstudies examined looked at the impact of price reductions; none \nexamined the impact of price increases or the introduction of more \nonerous pricing regimes. The first-round impact of price rises is likely to \nbe faster as the search for value adding uses of the data has already \nbeen done. Here the market will move fairly quickly to new price \nconfigurations, with some further adjustment as buyers and sellers test \neach other out and react to counter-party responses.  \n5.2.2 Accelerating the change \nHow can we accelerate the change in the economic value when \ntransitioning from paid access to open data? Change may be slow for \nvarious reasons. De Vries et al.’s case studies (2011) highlight the \nimportance of removing barriers to reform including reliance on data \nrevenues, organisational constraints and perceived risks to change. \nThey note that public sector bodies relying on PSI sales revenues and \nvalue adding appear deadlocked “when there is no other sustainable \nalternative income stream available”. \n\n \n \n    \n \n \n26 \nThey also noted, “Further barriers to change relate to statutory \nprovisions imposing cost-recovery schemes, the legacy of old re-use \nregimes, and the sheer difficulty of changing existing practices”, and \nnoted incumbent re-users with considerable interest in preservation of \nstatus quo may try to prevent PSBs lowering charges. \nThey noted that change could be driven by a top-down process (e.g. by \npolitical mandate) or by a bottom-up process (i.e. from within the \norganisation). In the case of the latter, additional effort was required to \njustify the reform and secure funding for the transition. Regardless, the \nstudy noted “the PSBs interviewed declared that a clear path to \ntransition and the financial means to do so have been of crucial \nimportance”. \nAnd with the market changing fast, measures to deepen market \ndevelopment will also help accelerate the achievement of beneficial results \nas set out in the following sub-section.  \n5.2.3 Market development \n5.2.3.1 Fostering additional investment in data curation  \nSome data, such as meteorological and geographical data, is created \nfor its use to those downstream, and so in this sense, is created \nessentially for its value to users (even if it is rarely created by those \nusers). However, other data is often a by-product of other activities – \nfor instance, registration and tax data. In these cases, data may be \npublished without much regard to its usefulness. As a result, those \ncreating and curating the data will have little incentive, and often little \nknowledge of what uses the data may be best put to, or how further \ninvestment in the curation and documentation of the data may add \nvalue to downstream users. This data curation will be a public good to \nthose downstream who may use and add value to the data. \nAccordingly, they should have some role in the governance of data \ncuration and dissemination.  \nMechanisms might be developed to allow downstream users to identify \nand build on opportunities. For example, by PSIHs facilitating feedback \nmechanisms and performing tasks (at cost) for those prepared to \ncurate and prepare additional data.\n42\n Additional incentives might be \nprovided by enabling PSIHs to obtain additional funding for further data \ncuration.\n43\n  \n                                                        \n42\n  Subject to any privacy, security or other technical concerns, they allow \noutsiders into their systems to work on the data themselves. \n43\n  For example, by providing subsidies to PSIHs to assist with some of the costs \nof further data curation by outsiders on the grounds that the resulting benefits \ncannot be captured entirely by those doing the work. Other opportunities might \ninvolve granting PSIH’s time-limited monopoly privileges over the improved \n\n \n \n    \n \n \n27 \n5.2.3.2 Building value  \nThe great data projects driven by the private sector have tended to \naccumulate around digital artefacts – generally platforms – that \ngenerate value that draws in users. Those users then contribute their \ndata.\n44\n While government agencies do not generally, and should not, \nseek a competitive advantage over anyone, they should seek to \ngenerate value where they can. And those in government in an \nincumbent position frequently pay too little attention to serving users \nand generating value as an integral part of their operating strategy. \nThus, in addition to making data available, government agencies could \ngive some thought to fostering value creation with that data.  \nIn addition to further investments in curation (discussed in the previous \nsub-section) governments can seed the development of communities of \npractice – rather like the community around an open source software \nproject – with an increasing user base generating positive network \nexternalities for all members of the growing community to enjoy. In \naddition, they may be able to seed projects and/or the development of \nplatforms which might grow into ‘data traps’. While this may not sit \neasily within departments of state with fundamental line responsibilities, \ncertainly more independent agencies tasked with market development \nlike the ODI might seek to pursue such goals possibly in collaboration \nwith other private and public interests. And such initiatives might also \nsit well with innovation units within line agencies.  \nIt should be noted that such an approach swings the government into \nthe business of using its own assets to seed deeper data markets – \nbuilt not just on PSI and government resources in establishing a \nplatform, but also on private data.\n45\n  \nGovernments can do this using their own resources to seed platforms, \nthey can help those platforms succeed by nudging or compelling their \nown agencies to contribute.\n46\n  \n                                                                                                                        \ndata and/or given PSIH’s capacity to levy stakeholders (e.g. In Australia \nfarmers have statutory powers to collectively levy themselves in Australia to \nfund public good research). \n44\n  As Matt Turck (http://mattturck.com/2016/01/04/the-power-of-data-network-\neffects/) has put it, “An approach I particularly like is building a ‘data trap’. The \nidea is to build something that delivers real, tangible value to users from the \nbeginning, and incite them to start contributing their data’.  \n45\n  An example is discussed in Gruen (2015), “Innovation? How about TripAdvisor \nfor the arts?” 27th Dec, 2015 in The Age, http://goo.gl/iTjwOj. \n46\n  For example Lateral Economics report commissioned by Omidyar Network, by \ncontributing to the development of standards which draw out others’ data \nbecause the standard has now enhanced its informational value. \n\n \n \n    \n \n \n28 \n6 References \nACIL Tasman, 2008. “The Value of Spatial Information”. Spatial \nInformation Systems Limited. Available at \nhttp://www.crcsi.com.au/assets/Resources/7d60411d-0ab9-\n45be-8d48-ef8dab5abd4a.pdf \nAnderson, C., 2009. “Free: The future of a radical price”. Random \nHouse. Summary available at \nhttps://summaries.com/index/Free.pdf.  \nBrin, David, 2015. “Stop Using Adam Smith and F.A. Hayek to Support \nYour Political Ideology: The irony of faith in blind markets”. \nEvonomics, 15th December, 2015. At http://evonomics.com/stop-\nusing-adam-smith-and-hayek-to-support/  \nDe Vries, M., Kapff, L., Negreiro Achiaga, M., Wauters, P., Osimo, D., \nFoley, P., Szkuta, K., O'Connor, J., and Whitehouse, D. \n\"POPSIS – Pricing of Public Sector Information \nStudy.\" European Commission Information Society and Media \nDirectorate-General (2011). \nDECA, 2010. “The value of the Danish address data: Social benefits \nfrom the 2002 agreement on procuring address data etc. free of \ncharge”. Available at http://www.adresse-\ninfo.dk/Portals/2/Benefit/Value_Assessment_Danish_Address_D\nata_UK_2010-07-07b.pdf . \nGruen, Nicholas, 2011. “The David Solomon Lecture: Government 2.0 \na couple of years on”. Available at http://goo.gl/5qAlsb. \nGruen, Nicholas, 2012. “Telcos reciprocate and market is a net winner”. \nThe Sydney Morning Herald, Nov. 14, 2012. At \nhttp://www.smh.com.au/business/telcos-reciprocate-and-market-\nis-a-net-winner-20121113-29adq.html#ixzz41dV7N2eG \nGruen, Nicholas, 2015. “Government as Impresario: Emergent public \ngoods and public private partnerships 2.0”. NESTA. At \nhttp://www.nesta.org.uk/sites/default/files/government_as_impre\nsario.pdf \nHicks, J. R., 1939. “Value and Capital”. Oxford University Press, \nOxford. \nHoughton, J. W., 2011. “Costs and benefits of data provision”. \nAustralian National Data Service. \nLateral Economics, 2014. Open for Business: How Open Data Can \nHelp Achieve the G20 Growth Target. Report commissioned by \nOmidyar Network. June 2014. \n\n \n \n    \n \n \n29 \nMorando, F., Lemma, R., & Basso, S., 2013. “Is there such a thing as \nfree government data”? INTERNET POLICY REVIEW. \nMcKinsey Global Institute, 2013. “Open data: Unlocking innovation and \nperformance with liquid information”. New York. \nOdlyzko, Andrew, 2003. “Privacy, Economics, and Price Discrimination \non the Internet”. Available at \nhttp://www.dtc.umn.edu/~odlyzko/doc/privacy.economics.ps \nOffice of Fair Trading, 2006. “The commercial use of public information \n(CUPI)”. OFT861. United Kingdom. \nOtteson, James R., 2002. “Adam Smith's marketplace of life”. \nCambridge University Press. \nPollock, R., 2008. “The economics of public sector information”. \nUniversity of Cambridge, Faculty of Economics. \nPoplin, A., 2010. “Methodology for Measuring the Demand Geo-\ninformation Transaction Costs: Based on Experiments in Berlin, \nVienna and Zurich”. International Journal of Spatial Data \nInfrastructures Research, 5, 168-193. \nRosen, Rebecca, 2012. “The Missing 20th Century: How Copyright \nProtection Makes Books Vanish”, Atlantic Monthly, March 30th. \nAvailable at http://goo.gl/Z2xKi  \nShakespeare, S., 2013. “Shakespeare Review: An independent review \nof public sector information”. London: BIS. \nShirky, Clay, 2008. “Here Comes Everybody: The Power of Organizing \nWithout Organizations”. Penguin Press, New York. \nSmith, Adam, 1776. “An Inquiry into the Nature and Causes of the \nWealth of Nations”. Available at \nhttp://oll.libertyfund.org/titles/smith-an-inquiry-into-the-nature-\nand-causes-of-the-wealth-of-nations-cannan-ed-vol-1#lf0206-\n01_label_153 \nSzabo, N., 1999. “Micropayments and mental transaction costs”. In 2nd \nBerlin Internet Economics Workshop. \nVarian, Hal. “Economic Value of Google”. At \nhttp://cdn.oreillystatic.com/en/assets/1/event/57/The%20Econom\nic%20Impact%20of%20Google%20Presentation.pdf.  \nVickery, G., 2011. “Review of recent studies on PSI re-use and related \nmarket developments”. Information Economics, Paris. \nWorstall, Tim, 2015. “Even Google Doesn't Understand Google's Value \nto the Economy”. Forbes, Sep 17, at http://goo.gl/7fvVbZ.  \n\n \n \n    \n \n \n30 \n7 Appendices \n7.1 Further details of studies undertaken \nTable 2: Scope of studies examined \nStudy Time \nperiod  \nRegion Data \nsource \nUser \nbenefits \nScenario Units \nPIRA \n(2000) \n1998-\n2000 \nEU PSI Direct + \nIndirect \nCurrent GVA \nMEPSIR \nstudy \n(2006) \n2004-\n2006 \nEU25 + \nNorway \nPSI Direct Current GVA \n(market \nsize for \nPSI)  \nACIL \nTasman \n(2008) \n2006-\n2007 \nAustrali\na \nSpatial \ninfo \nDirect + \nindirect \nCurrent GVA \nPollock \n(2008) \nSurveye\nd 1996- \n2007 \nUK PSI Direct + \nindirect \nReleased \nthrough \nopening \nof data \nWelfare \nDeloitte \n(2013) \n2011-\n2012 \nUK PSI Direct + \nIndirect \nCurrent GVA \nMcKinsey \n(2013) \n2013 Global Open \ndata \nfrom 7 \nsectors  \nDirect + \nindirect \nPotential Output by \nsector \nLateral \nEconomics \n(2014) \n2015 to \n2020 \nG20 All \nopen \ndata \nDirect + \nindirect \nPotential GVA \n  \n\n \n \n    \n \n \n31 \n7.2 Technical appendix \nWe build on a model by Pollock (2008 & 2011), summarised in Box 2 \nbelow, that examined the welfare change from moving between \naverage-cost and marginal-cost pricing regimes. \nBox 2: Pollock’s (2008 & 2011) model \nPollock estimates the loss of welfare from an average cost pricing \nregime to a marginal cost regime as  \n Welfare loss\n47\n = \n!\n!\n휀휆퐹  \nwhere: \n• F — The fixed costs producing and maintaining the information \n• ε — The elasticity of demand as measured when changing from an \naverage (cost-recovery) price to marginal cost pricing, and \n• 휆 — The demand multiplier. \nUsing a combination of parameter estimates, Pollock (2011) estimates \nthe welfare loss (which we present in terms of GDP):\n48\n \n• Upper-end estimates of 휆 = 8; 휀 = 3.5 give gains of approximately \n0.3 to 0.4 per cent of GDP annually.  \n• Mid-range estimates of 휆 = 5; 휀 = 2 give gains of approximately \n0.11 to 0.13 per cent of GDP annually. \nWe modify the Pollock model by introducing a kink to the demand curve \nand explicitly consider the impact of transaction costs. This is illustrated \nin Figure 4 below, which (similar to the Pollock model) shows the direct \ndemand for data assets. To reflect transaction costs, the figure \npresents demand in terms of the perceived price, which includes \ntransaction costs.  \nThe figure shows a two-part demand curve to better approximate the \nreal demand. While the first part of the demand curve is identical to \n                                                        \n47\n  The ‘2/5’ amount in the equation reflects the assumption that the demand curve \nis linear and an adjustment for distributional consequences of the subsidy \nwhich reduces the welfare loss by a factor of 4/5. Pollock (2008) argues that \nbenefits from lowering the price of PSI are received in proportion to income \nand, therefore (from a welfare perspective), there is an adverse distributional \nimpact of subsidising PSI. We are sceptical of the need to apply this \nadjustment. However, in our opinion, an adjustment of similar magnitude is \nappropriate to account for the marginal excess burden of taxation.  \n48\n  These estimates are from Pollock’s 2011 paper. These parameter estimates \n(both for of 휆 and 휀) are higher than suggested in Pollock’s earlier (2008) work \nas the scope of the PSI considered was broader. \n\n \n \n    \n \n \n32 \nPollock’s linear demand curve, the second part is kinked with elasticity \nrising reflecting the fact that, once the data is open licenced, the \ndistribution of the data becomes ‘permissionless’, powerfully reducing \nfrictions which would otherwise frustrate the data finding its way to \nvaluable uses. \nFigure 4: Demand for data assets \n \nEmpirical evidence suggests that the second part of the demand curve \nis much flatter than the traditional demand curve (which will be \ndiscussed in the next subsection). In other words, the transactions \ncosts associated with the chain of permissions to distribute data in a \nlicenced regime deter a sizeable amount of users from utilising data \nassets. Using this basic approach, we can estimate the proportion of \nvalue loss from a paid-access regime using a few parameters:\n49\n \n• the proportionate increase in demand that occurs when moving \nbetween pricing regimes, and \n• the significance of the transactions costs in proportion to the costs \nof acquitting the public sector data. \n                                                        \n49\n  Note: the diagram illustrates a situation in which new users brought into the \nregime from its move to open licensing will gain relatively low value as they are \nfurther down the demand curve. This assumption tends to underestimate the \nvalue of increasing demand from permissionless distribution. This is because \nthe transactions costs of licensing frustrate search for users and once search \ncosts fall and new uses are found, it seems likely that some new uses will turn \nout to have relatively high value. For instance, some of the users introduced to \nautomated voice directions while driving on Google Map’s free system would \nexperience a functionality from the service which, had they known of it before, \nwould have induced them to pay for positively priced services like Navman or \nTomtom. This possibility is discounted in our treatment.  \nPerceived  per\n-\nunit  cost  to  customers\nDirect demand for data assets\nOpen data\nQuantity of info. utilised\nCost recovery \npricing\nFree but \nrestricted\nE\nFD\nABC\n\n \n \n    \n \n \n33 \nIn the diagram:  \n• 푝\n!\n is the per-user monetary cost of information under cost recovery \npricing \n• 푝\n!\n is the per-user transaction cost in a free-but-restricted pricing \nregime \n• 푞\n!\n is the quantity demanded under cost recovery pricing and 푞\n!\n \nand 푞\n!\n is the additional quantity under free-but-restricted regime \nand open data. \nThe additional welfare of moving from cost recovery to marginal cost \n(free-but-restricted) is the area D times a demand multiplier (λ). If the \ndemand multiplier (λ) is constant across the demand curve, then the \nGVA of core data asets under cost recovery is λ (E+F) and under a \nfree-but-restricted regime is similarly λ(E+F+D). \nIn moving to an open-access regime, two additional effects happen. \nThere is an increased demand reflected in the area C. There is also a \nreduction in transaction costs to existing re-users equal to the area \nA+B. To determine the increased GVA associated with increased re-\nuse, we have taken a similar approach by multiplying the area C by the \nsame demand multiplier; that is, λC. \nThe reduction in transaction costs for existing users (area A+B) would \nhave a net-welfare benefit but would not impact on GVA. Similarly, \nthere would be a reduction in transaction costs for suppliers of data \nassets. Similarly, this reduction would have a net-welfare benefit but no \nimpact on GVA. \nThe impact of moving from cost recovery to open access is, therefore, \nto increase GVA from (E+F)λ by the amount (D+C)λ. \nAs a multiple, the increase in GVA is 1+\n!!!\n!!!\n \nWe set up three ratios to help solve the model.  \n푡=\n푝\n!\n푝\n!\n  \nthe ratio of transaction costs to monetary costs \n푒\n!\n=\n푞\n!\n푞\n!\n \nthe increase in demand from a cost-recovery \nregime to a free-but-restricted regime \n푒\n!\n=\n푞\n!\n푞\n!\n  \nthe increase in demand from a free-but-restricted  \nregime to an open-access regime \nThe areas C, D, E and F can all be computed as a function of F. These \nare: \n• 퐶 = ½푡푝\n!\n푞\n!\n=½푡푒\n!\n퐹 \n• 퐷 = ½푝\n!\n푞\n!\n=½푒\n!\n퐹 \n\n \n \n    \n \n \n34 \n•  퐸 = ½푝\n!\n푞\n!\n =½퐹/푒\n!\n \nTherefore, shifting from a cost reflective to an open-licence regime will \nincrease GVA by a multiple of: \n1+\nD+C\n퐸+퐹\n=1+\n푒\n!\n+푡푒\n!\n2+1/푒\n!\n \nConsistent with Pollock (2011)’s mid-range estimate of elasticity, we \nassume 푒\n!\nto be equal to 2 (Of note, his higher estimate is 3.5). As \ndiscussed in the next sub-section, we assume that 푒\n!\n is between 2 and \n4 (with a mid-point of 3). \n7.3 Evidence of changes in response to price \nA number of studies have examined the changes in demand for PSI as \na result of changes in prices. Pollock (2008) provides a survey of \nevidence of price elasticity estimates for PSI. The elasticity analysis in \nPollock is complemented by a more recent study — De Vries et al. \n(2011) — that involved 21 in-depth case studies where public sector \nbodies (PSB) had changed prices. The case studies were divided into \nfour domains, where the three major domains each encompassed a \n100 per cent price-cut case. \nA brief summary of the cases reported in these two papers is provided \nbelow. While the elasticity estimates in Pollock’s papers are within “a \nlarge range”, the sensitivity of quantity demanded can be alternatively \ninferred from De Vries et al.’s case studies. Using these results, we \ndeveloped estimates of the parameters for the modelling. For change in \ndemand from cost-recovery to marginal-cost pricing, we have assumed \nan increase of 200 per cent. This is consistent with Pollock’s (2011) \nmid-range estimate. To estimate the impact of open data, we more \nclosely examined the changes in demand reported by De Vries et al. \n(2011). As can be seen from the summaries, there are very large \ndemand increases following price cuts.  \nWhen comparing cases, there have been 100 per cent price cuts. With \ncases with slightly small price cuts, we observe very different changes \nin the usage increase — with a 100 per cent price cut, the increase is \nmuch more significant. In terms of the monetary costs to customers, the \n100 per cent price cut cases are similar with (for example) a case \nwhere there is a 97 per cent price cut case. Because the latter case is \nnot completely free of charge, there will be transaction costs, which we \nexpect to be the main driver for the usage difference. \nIn both the Meteorological and the Geographic domain examples \nprovided (from De Vries et al. 2011) below, the increase in demand \nfollowing a 100 per cent price cut was around three times as great. \nThat is, for example, if shifting to close-to-zero prices leads to a 200 per \n\n \n \n    \n \n \n35 \ncent increase, then shifting to free and open access would result in an \nadditional 400 per cent increase (for a total of 200x3 = 600 per cent). \nThe additional increase we observe could also in part be attributed to \nfurther price reductions (from near to zero to zero). In conclusion, we \nthink it is reasonable to assume that moving from free-but-restricted to \nopen-access will (in terms of demand) lead to an additional 200 to 400 \nper cent increase in the demand for core data assets (i.e. suggesting \n푒\n!\n will be between 2 and 4). \nIn light of the above analysis, we have assumed for a mid-range \nestimate 푒\n!\n=2  and 푒\n!\n=3. \nDe Vries et al. (2011) \nIn this study, four domains, Meteorological PSI, Business register PSI, \nGeographic PSI and Other PSI were examined. A summary of demand \nchange in response to price changes are as follows. \nMeteorological PSI: \n• KNMI — following an 80 per cent price cut, the number of re-users \nincreased by 1,000 per cent. \n• Met.no — following a 100 per cent price cut, the number of re-\nusers grew by 3,000 per cent. \nGeographic PSI:  \n• BEV — following an up-to-97 per cent price cut, usage volume \nincreased, which includes: 250 per cent increase for digital \ncadastral maps, 200-1,500 per cent increase for cartographic \nproducts, 7,000 per cent for digital orthophotos, 250 per cent for \nthe digital elevation model, 1,000 per cent for the digital landscape \nmodel, and 100 per cent increase in external-use licenses.  \n• Spanish Cadastre — following a 100 per cent price cut, the number \nof digital maps downloads increased by 800 per cent, alphanumeric \ndata downloads increased by 1,900 per cent, total downloads \nincreased by 965 per cent. \nOther PSI: \n• Destatis — following a 100 per cent price cut, the number of unique \nvisitors increased by 1,800 per cent; and the number of downloads \nincreased by 800 per cent. \nFrom Pollock (2008) \nPollock (2008) documented a number of cases about the sensitivity of \ndemand when there is a price change (see Pollock 2008, for the \nreferences). \n\n \n \n    \n \n \n36 \n• The Office of Fair Trading (2006) — estimated an elasticity of 0.3 \n(lower bound) and 2.2 (upper bound) for New Zealand national \nmapping data. \n• Davies and Slivinski (2005) — estimated an elasticity of 0.3 for \ndemand of weather forecasts. This was considered as a lower \nbound because it excludes demand coming from intermediaries \nand the private sector. \n• Bedrijvenplatform (2000) — estimated an elasticity of 0.48 (lower \nbound) and 4.17 (upper bound) for public sector geographic data. \n• Making Information Freely Available initiative, Statistics New \nZealand — estimated elasticities from lowering prices of 6 for \nDigital Boundaries Files, 34 for Street Link Files, 1.5 for Small Area \nPopulation Estimates. \n• The Australian Bureau of Statistics — estimated an elasticity of \n2.33 (short-run) and 3.5 (long-run) for ABS statistics. \n• The Office of Spatial Data Management in Australia — estimated \nan elasticity of 1.65 fundamental spatial data. \nPollock also documented evidence from the telecommunication sector, \nwhich is to some degree comparable to the information sector, to \ncomplement his demand-sensitivity study.   \n• Hausman et al. (1997) — estimated an elasticity of 1.61 for the \nintroduction of voice messaging and 0.51 for the introduction of \nmobile phones in the U.S. \n• Goolsbee (2006) — estimated an elasticity of 2.75 for broadband in \nthe U.S. \n• Kridel et al. (2002) — estimated an elasticity of 1.8 for broadband \nin the U.S. \n• Goolsbee and Klenow (2006) — estimated an elasticity of 1.6 for \ninternet usage. \n• Hackl and Westlund (1996) — estimated a range of elasticities \nfrom 0.09 to 1.25 for international telecommunications in Sweden. ","version":"1.10.100"}