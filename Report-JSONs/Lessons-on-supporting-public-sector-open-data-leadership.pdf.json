{"numpages":40,"numrender":40,"info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Adobe InDesign CS6 (Macintosh)","Producer":"Adobe PDF Library 10.0.1","CreationDate":"D:20160509213716+10'00'","ModDate":"D:20160509213717+10'00'","Trapped":{"name":"False"}},"metadata":{"_metadata":{"xmp:createdate":"2016-05-09T21:37:16+10:00","xmp:metadatadate":"2016-05-09T21:37:17+10:00","xmp:modifydate":"2016-05-09T21:37:17+10:00","xmp:creatortool":"Adobe InDesign CS6 (Macintosh)","xmpmm:instanceid":"uuid:9a310a3f-a304-0540-ab69-faeabf413553","xmpmm:originaldocumentid":"xmp.did:F77F1174072068118F62DC097F9B2FBE","xmpmm:documentid":"xmp.id:EF7F34A5C720681183D1D5E0B5344FCC","xmpmm:renditionclass":"proof:pdf","xmpmm:derivedfrom":"xmp.iid:4999BD6CC720681183D1D5E0B5344FCCxmp.did:F044E8ED5820681183D1D5E0B5344FCCxmp.did:F77F1174072068118F62DC097F9B2FBEdefault","xmpmm:history":"convertedfrom application/x-indesign to application/pdfAdobe InDesign CS6 (Macintosh)/2016-05-09T21:37:16+10:00","dc:format":"application/pdf","pdf:producer":"Adobe PDF Library 10.0.1","pdf:trapped":"False"}},"text":"\n\nODI-WP-2016-003 \n2016-04-20\nLessons on\nsupporting\npublic sector\nopen data\nleadership\nOpen Data Institute\n\n2 Lessons on supporting public sector open data leadership | Open Data Institute 2016\nTable of contents\nAuthors: Fiona Smith and Liz Carolan (Open Data Institute)\nExecutive summary 3\nIntroduction                                                                                                                  5\nEvaluating different methods to support open data leadership 8\nPeer leadership networks 8\nOpen data training for civil servants 18\nStrategic assessments for open data 23\nLearning about cross-cutting issues  28\nExternal context and constraints  28\nProject management and governance  29\nConclusion: the future of supporting open data leadership 31\nAbout this report 33\nAppendix                                                                                                                     35\n\n3 Lessons on supporting public sector open data leadership | Open Data Institute 2016\n1. Executive summary\nAs open data initiatives mature, we need a generation of entrepreneurial public sector \nleaders who are able to successfully navigate through reform, from early adoption to wide-\nscale implementation.\nThis paper presents a summary of the lessons learned from the Open Data Institute’s \nexperience supporting open data leaders around the world. We aim to help practitioners \nand researchers working in good governance and open data to understand effective \ntechniques for building leadership capacity, particularly for implementing transformational \nreforms within government.\nThe lessons in this paper are drawn from testing different methods of delivering capacity \nbuilding and advice to leaders through peer networks, training and strategic assessments. \nFrom our research, we found:\n1. Peer networks help boost personal and professional \ndevelopment, but more research is required to understand how to scale \ntheir impact. A peer network (the ‘Open Data Leaders Network’) benefited \nthe personal development of individual members, in particular through \nenhancing their social capital and challenging their thinking. More time and \nresearch is required to understand whether this will translate to impact at the \ninstitutional or national level.\n2. Training programmes for civil servants are one component of \na broader process of capacity building. Face-to-face and virtual training \nmethods worked well for increasing knowledge especially on technical \nsubjects such as licensing. But affecting long-term behavioural and culture \nchange may require a long-term form of multi-faceted engagement, built on a \nrelationship of trust between trainees and training partners.\n3. Strategic assessments should be reframed in participatory \nterms to promote ownership of results and follow-up actions. The \nassessment tool we piloted provided rigorous guidelines for structuring a \nreview of a team’s ongoing progress implementing their open data initiative. \nUsing the tool to promote dialogue, reflection, and to generate a list of \ncollectively agreed priorities – as opposed to a one-off event – could deepen \nthe outcomes.\n4. Leadership programmes should incorporate a degree of \nflexibility, and plans should be adapted as external circumstances \nchange. Prior country scoping in the form of desk research, stakeholder \n\n4 Lessons on supporting public sector open data leadership | Open Data Institute 2016\ninterviews and learning needs assessment was crucial in tailoring the design \nof leadership support programmes. An adaptive and responsive approach is \nespecially important in more fragile operating contexts.\n5. Teams providing leadership support or training activities should \nconduct ongoing reviews of their own effectiveness. Reflecting on \nour own practice throughout the cycle of design and implementation was \nbeneficial to promote continuous learning about how effective methods \nwere. In future, we should standardise this approach and ensure feedback \nflows between participants and our own delivery team.\nThroughout the year, we also observed external trends that impact on sustainable open \ndata implementation. These included fragile governance conditions, weak feedback \nloops with data users and uncertainty around data ownership and use. These challenges \nare complex and cannot be solved by one leader alone, but are important to consider in \nshaping appropriate leadership support programmes.\nWe also gained general insights into managing leadership support programmes in \ndeveloping countries. For example, we learned the need to combine careful risk \nassessment with an adaptive, flexible approach, and the value of taking a partnership \napproach towards delivering support. These lessons are not specific to open data, and \ncould be transferrable to other sectors.\nFinally, we identified ongoing challenges and research questions which will need to be \naddressed in the next phase of open data’s development and widespread adoption. These \ninclude how to embed early changes catalysed by dynamic leaders into broader systems, \nand how to strengthen feedback loops between governments and data users, to promote \ngreater use and adoption of open data.\n\n5 Lessons on supporting public sector open data leadership | Open Data Institute 2016\n2. Introduction \nBackground \nAround the world, governments of all levels – city, regional and national – are adopting \nopen data policies and portals. Open data is data that anyone can access, use and share. It \nis increasingly seen as a tool to help promote transparency, boost innovation and business \ndevelopment, and solve social challenges such as pollution, transportation and disaster \nmanagement. \nIn 2015, the ODI embarked on an set of projects to understand what works in supporting \nleaders to implement transformational open data reforms. We sought to answer the \nquestion: ‘How do you unlock a sustainable supply of open data in developing countries?’\nThis builds upon our experience engaging with over 30 country governments for bespoke \nopen data training, and our previous research into navigating open data and organisational \nchange. We observed that leaders of open data initiatives often feel isolated, as vanguards \nwho are disrupting the status quo. They share many characteristics of what Everett Rogers \nrefers to as ‘innovators’ in his famous model of how new technologies and ideas spread \nthrough cultures.\n1\n As policy innovators, they are entrepreneurial thought leaders who are \nwilling to take risks, but can find themselves struggling to gain broader traction during the \nimplementation phase of a reform.\nSupporting leaders to shift open data from being a fringe innovation project to embedding \nit into routine systems and culture will be essential if we are to realise data’s potential for \ndriving sustainable and inclusive global development. \nOur theory of change was that a supply of open data can be sustained by empowered, \nlocal leaders overseeing and driving culture change. Based on our experience, we \nbelieved that some of the best ways to support leaders were to connect them with peers \nand experts, promote strategy review processes, and challenge leaders to think more \ninnovatively and to amplify their successes by communicating stories of impact. Central \nto our theory of change was a locally-driven approach, where governments and citizens \ndefine their own goals for social and economic transformation.\nTo test our hypothesis we piloted three different methods of providing leadership \nsupport: 1) peer-leadership networks; 2) training civil servants (in person, and remotely); \nand 3) strategic assessments. We sought to ‘learn through doing’, and to regularly reflect \non and adapt our practice.\n1 Rogers, E. M. (1962). Diffusion of innovations. Glencoe: Free Press.\n\n6 Lessons on supporting public sector open data leadership | Open Data Institute 2016\nOur implementation approach involved hand-picking dynamic individuals to be part of an \nOpen Data Leaders Network (ODLN). The network brings together high-potential leaders \nfrom all over the world to engage in peer-learning, professional development, and to \nexchange promising practices.\nFor the training and strategic assessments, we designed a scoping process to select \nthree focus countries we felt had the right enabling conditions for open data to mature. \nThese conditions included demand for technical assistance, the presence of an open \ndata champion in government, political commitment to open data, and prospects of high \nimpact. Ultimately, we wanted to understand whether having a strong leader was enough \nto achieve transformation, even against challenging conditions such as a closed political \nculture or nascent civil society.\nAfter selecting Burkina Faso, Tanzania and Macedonia as our focus countries, we \ncollaborated with their open data teams to co-design a package of support activities over \nthe following six to nine months. Over the course of the year, we delivered:\n•\tTraining to over 650 civil servants\n•\tSix open data leaders trained to become trainers\n•\tTwo in-depth strategic assessments in Tanzania and Burkina Faso \n\n7 Lessons on supporting public sector open data leadership | Open Data Institute 2016\nResearch methodology \n \nUsing rapid appraisal methods such as surveys, participant observation and focus group \ndiscussions after each major intervention – whether training, assessments or strategic \nsupport – we collected feedback on the content, quality of delivery and evidence of \nmeeting learning outcomes. We also held retrospectives with trainers and partners to \nimprove our curriculum and methods. \nFor the purposes of this paper, we invited an external consultant (Icarus) to help evaluate \nour methods, and analyse the data we had collected over the year. The evaluation involved \na combination of desk review, participant surveys, interviews with trainers and partners, \nand a focus group discussion with the ODI team. The lessons and recommendations \ndistilled from that process are summarised below. See the Appendix for more details about \nthe research methodology.\nWe acknowledge that there are several limitations in our research approach. Given the \nprogramme’s short 12-month timeframe, we were only able to assess effectiveness up to \nthe level of knowledge and skill acquisition.\n2\n Given more time, we would follow up with \nparticipants to track longer-term changes in attitudes, behaviour and institutions. We \nalso note the small sample size of three countries with diverse contexts. We intentionally \nchose different social and political contexts in order to understand whether approaches \nwere transferrable. Repeating the piloted methods in more locations would strengthen the \nvalidity of our results. \n2 Kirkpatrick, D. L. (1998). Evaluating training programs: The four levels. 2nd ed. San Francisco: Berrett-Koehler Publishers.\n\n8 Lessons on supporting public sector open data leadership | Open Data Institute 2016\n3. Evaluating different methods to support open data \nleadership \n \nPeer leadership networks \nWhat are peer leadership networks?  \nPeer networks are horizontal organisational structures that distribute resources and support \nto members (‘nodes’) via social bonds and joint activities (‘links’). They support professional \ndevelopment by sharing and building upon knowledge held by individual members to \nachieve greater collective impact. Increasingly, peer networks are emerging in the public \nsector as a way of connecting policy innovators and diffusing promising practices within \nvarious areas relevant to good governance, including open data.\n3\nOne of the greatest perceived benefits of a peer network is enhancing the social capital \nof members. Social capital, as an asset, is the collection of networks and bonds that \nenable a person to work with others effectively. It is built upon shared norms, values and \nunderstandings which can facilitate co-operation, exchange and innovation.\n4\n \nHow the ODI used peer networks \nWith this in mind, we developed the Open Data Leaders Network (ODLN), a programme \nthat aims to promote peer-learning and to enhance the social capital of civil servants \nresponsible for implementing open data initiatives within different levels of government \naround the world. It was developed in response to global demand for capacity building, \ntraining and support for leaders in order to increase the sustainable supply and use of \ndatasets across government.\n5\n \nAbout the participants \nLeaders were engaged to join the ODLN through the ODI – selected from within our \nexisting networks, through invitation to apply, or by recommendation from other open \ndata leaders. This selection process was intentional, in order to provide geographic and \ngender diversity, but also to provide the conditions for respectful group dynamics. Each of \nthe selected candidates was reviewed against criteria including a strong mandate within \ntheir government for reform, high leadership potential, and a collaborative and collegiate \n3 Gerry, W., Harvey, B., and Smith, F. (2015). How to create and sustain peer networks for open data leaders. London: Open Data \nInstitute.\n4 Keely, B. (2007). Human Capital: How what you know shapes your life. OECD Insights, Paris, OECD Publishing.\n5 See, for example, findings of The World Wide Web Foundation, (2015). The Open Data Barometer Global Report. 2nd ed. \nAvailable online at: http://www.opendatabarometer.org/assets/downloads/Open%20Data%20Barometer%20-%20Global%20\nReport%20-%202nd%20Edition%20-%20PRINT.pdf [Accessed 2016-04-14].\n\n9 Lessons on supporting public sector open data leadership | Open Data Institute 2016\nleadership style. They were also selected based on their bold aspirations for open data in \ntheir context, as the following quotes from participants about their goals indicate.\n“[We want to] become leaders in the publication and use of open data for \nevidence-based policy making, economic growth and transparency.”\n“I want to see open data being released as business as usual and \n(perhaps more importantly) innovative reuse of the data leading to a \nmultitude of social and economic impacts and better participation by \ncitizens, communities and business in government.”\n \n                                                                           –               ODLN               survey               respondents \nDespite being at different stages in their open data journeys, the leaders in the ODLN \nshared several common traits. All participants were dynamic individuals playing a \nleading role in driving open data initiatives in their local contexts, actively participating \nin international or regional open data communities. They also showed traits of ‘network-\nthinking’, such as a willingness to share knowledge and contribute to the advancement of \nthe sector as a whole. They also experienced common challenges in their day-to-day jobs, \nsuch as managing political transitions, engaging the private sector, measuring the impact \nand value of open data, and applying open data towards solving policy challenges.\nA key consideration while forming the ODLN was to ensure a mix of participants from both \ndeveloped and developing countries. From previous experience, we observed that the \nchallenges being faced by open data leaders in different contexts were relatively similar, \nand that exciting data innovation happening in one context could inspire solutions to \nchallenges in another. \nParticipants represented a range of countries – Mexico, Ecuador, the Philippines, Moldova, \nNew Zealand, Morocco, Argentina, Tanzania, Nigeria, Macedonia, the UK, Chile and \nMalaysia – and a variety of institutional structures, including the President’s office, the city \nmayor’s office, planning commission, e-governance department and a semi-privatised \ninnovation agency.\n \n\n10 Lessons on supporting public sector open data leadership | Open Data Institute 2016\nAbout the programme \nThe overall design of the ODLN programme was based on ODI research on network \nbuilding and insights gained from its other support programmes, including startup \nincubation.\n6\n We realised the importance of allowing time for the group to build relationships \nof trust in-person, and providing them with enough space to be able to determine the \nshape of the network they wanted. \nNetwork activities included an inception week in London for training, relationship building \nand knowledge sharing, followed by ongoing communication. In 2015 we conducted two \ninception weeks for cohorts of seven individuals at a time. We adapted the curriculum for \nthe second cohort based on an assessment of learning needs and feedback from the first \ncohort, which revealed a high demand for more challenging content on innovation.\nWhile the learning objectives differed slightly between cohorts, the outcome of the \nprogramme remained to develop strong social and professional links between the \nparticipants. This was to enable the sharing of ideas, inspiration and moral support to help \nthem in their leadership roles, while creating the foundations for a peer network that could \nscale.\nThe training week incorporated reflection and co-working based on current trends in open \ndata theory and practice, managing organisational change, private sector innovation, \ncommunication skills and strategy planning. It was delivered through a number of \nfacilitation methods, including group discussion, abstract thinking and problem-solving \n(eg business canvasses), role play, individual coaching, action learning sets, off-site visits \n(including to a startup incubator), and lecture-style presentations. The training week also \nexposed participants to experts representing diverse perspectives, from startups, global \ninstitutions and the UK Government.\n \n \n6 Gerry et al (2015) as above; Carolan, L. (2015). Small teams, big ideas. [Blog] World Bank Data Blog. Available at: http://blogs.\nworldbank.org/opendata/small-teams-big-ideas-open-data-ambition-runs-start-ups-governments [Accessed 2016-04-14].\n\n11 Lessons on supporting public sector open data leadership | Open Data Institute 2016\nThe Open Data Leaders Network peer network model: key \nfindings \n \nOverall we found positive results from the ODLN peer network model. Members of the \nnetwork scored the usefulness of their participation highly against three criteria: for their \nown personal development, for their open data initiative, and for promoting their work and \nopen data more generally. \nOur findings below are based on participant feedback surveys, ODI team reflections and \ninterviews with trainers. They reinforce what the wider literature suggests: that effective \nnetwork-building requires careful participant selection, the employment of an adaptive, \nflexible model and the promotion of network-thinking from the outset.\n7\n \nWe have organised our findings according to the key components of a peer network: \nunderstanding impacts; selecting members; connecting members; balancing diversity; \nmanaging membership turnover; and network evolution and governance.\n \nUnderstanding network impacts \nReported impacts of peer networks typically include members forming professional \nrelationships, improved professional approaches within a sector, enhanced organisational \ncapacity, and better government policies within a sector as a result of network member \nengagement and advocacy.\n8\nDuring our research we asked network members about their key ‘take-home message’ from \nthe inception week training, as well as the aspects that have been most useful in their work. \n \n \nThree themes emerged:\n•\tAppreciating the crucial role of culture change in the process of \nimplementing open data policies\n•\tUnderstanding how innovation approaches can be relevant and useful in \ntheir work\n•\tEstablishing links with a group of people, with shared interests and \nenthusiasm, who are experiencing similar challenges\nThese themes aligned with the actions that members said they would undertake, having \nattended the training. This suggests that elements of the training matched participants’ needs \nand expectations. Members’ follow-up actions were wide-ranging:\n7 Smith et al (2015). As above.\n8 Ibid.\n\n12 Lessons on supporting public sector open data leadership | Open Data Institute 2016\n“Pursue long-term structural changes and law reform, ask for reasonable \nbudget  and resources to kick-start things.” \n“I have to take the time to be able to strategise more, and to focus more \nopen data-driven innovation.” \n“Innovate (at a policy level, at project level and with team’s creative \nproblem solving). Implement a more effective change management \napproach.”\n \n                                                                           – ODLN training feedback\nWhile it might be premature to see evidence of organisational change, members have \nidentified ways in which their teams, departments or governments have benefited from their \nparticipation in the ODLN. Many members said the network had given them new ideas. \nMany also said that participating in the network had helped them to acquire new insights \ninto how their own open data initiatives were progressing, and to generate increased \nsupport or awareness. Together these findings suggest that peer networks have the \npotential to contribute to mid- to long-term capacity building.\n“ODLN is like a small think tank with [rapidly] responsive people and plenty \nof diverse experience at one place.” \n \n                                                                           –               ODLN               survey               respondent \nSelecting participants \nSelecting the right kinds of participants is key to the success of a peer network, since the \nrationale for connecting peers is to access mutual support and information from others at \nsimilar positions. The ODLN participant selection approach appears to have been effective, \nas feedback from participants suggests that the network reflects the original aspiration of \ninvesting in individuals with high potential to affect change. Participants’ diverse experience \nand knowledge of working with open data created rich opportunities for leaders to learn \nfrom each other.\n“I felt I found a group of people who shared the same enthusiasm and the \nsame shortcomings in the daily work with open data.”\n \n                                                                           – ODLN survey respondent \nParticipant feedback from the first ODLN cohort exposed a need to increase diversity of \nperspectives. For the second cohort, therefore, we invited participants from cities, regions, and \nvaried institutions. As the network grows and original members are promoted to new positions, \nwe need to continually review our approach to membership and ongoing governance.\n\n13 Lessons on supporting public sector open data leadership | Open Data Institute 2016\nConnecting members and offering face-to-face training \nA critical component of convening a peer network is connecting people. Bringing people \ntogether for an intensive week of training and building relationships of trust is a resource-\nheavy approach, both for the organiser and in terms of the amount of time attendees have \nto take out of their professional lives to attend. It therefore needs to be impactful in order to \njustify the investment. \nDuring the inception training week we used a number of activities to promote bonding, \nincluding group problem-solving, action-learning sets in pairs, excursions to other startup \nincubators, and social activities. Small group and pair selection was directed by ODI \nfacilitators in order to ensure a balance of personality types and learning styles. Open social \ntime (like getting lost in the city together), and space for problem-solving independent from \ntrainers helped to create a sense of closeness and solidarity.\nAfter each training session or presentation, we also dedicated time to group reflection. \nThis allowed for pattern recognition, and helped members to develop a sense of ‘tribe’ \nor common endeavour. It was also important to create a safe space for members to have \nprivate conversations and brainstorm joint actions independently.\nOverall, the training week appears to be a worthwhile investment, although adaptations \ncould be made to content and resourcing to increase effectiveness and resource \nefficiency (see learning on ‘project governance and management’ below). The training \nweek contributes to several factors that are pivotal in building a peer network: making \nconnections where none otherwise exist; developing relationships of trust and respect; \nleveraging collective expertise and resources; cultivating communities of learning; and \npromoting network thinking.\n9\n \n“It was an amazing bonding experience, that created a network where you \ncan openly ask questions on your everyday decisions that you make as a \npractitioner [...] That helps a lot, because we do have challenges: everyone \nworking on an open data national strategy has common challenges (like \nCreative Commons licensing).” \n \n                                                                                          –               ODLN               member \nFace-to-face time is also crucial to laying the foundations of ongoing communication. \nMembers have remained active in the network, engaging with each other through various \nmediums including Twitter, Whatsapp and email. An early attempt to develop a customised \nICT platform for document-sharing and discussion quickly gave way to more informal \n9 Ibid.\n\n14 Lessons on supporting public sector open data leadership | Open Data Institute 2016\nmodes of communication, such as email. This suggests the need to allow members to \nself-select and manage their own tools for collaboration, as opposed to introducing an \nexternally-led solution.\n \nBalancing member diversity \nAn important consideration when convening a peer network is managing member diversity \nto enable group cohesion. We found the following aspects to be helpful when balancing \nmembers’ capacities and cultural backgrounds.\n•\tEnsure members can relate to the experiences of others in the \nroom. One trainer observed an interesting dynamic was created by the \nheavy involvement of UK open data representatives (generally regarded \nas being at the forefront of open data): “There is potential for this to \ncreate a barrier because participants can be threatened by hearing from \na country that is so much further ahead than they are.” It is important, \ntherefore, that varying levels of experience are handled sensitively so \nthat all members feel comfortable and supported, rather than isolated. \nIncluding more than one person from each of the four Open Data \nBarometer groups (High Capacity; Advancing; Capacity Constrained; \nOne-Sided Initiatives)\n10\n could help people to feel at ease and identify \nwith the experience of others in the room.\n•\tOffer members experiences that are relevant to their level of \nunderstanding around open data. For example, a visit to a UK startup \ninitiative may not be relevant to those countries that are ‘Capacity \nConstrained’. When engaging network members, it is important to use \nstories that inform and inspire all of them, regardless of their position in \nthe Open Data Barometer. Ideally, draw upon the pool of stories from \nmembers’ own contexts; this will expand as membership grows.\n•\tOffer a programme that can accommodate different learning \nstyles and facilitate joint working. One trainer noted that the level of \nparticipants’ involvement depended somewhat on their background: \n“One of the biggest challenges was the mixture of learning styles and \nhow to address that in the room so that everyone felt equally confident \nand involved.” For example, some participants appreciated discussing \nformal theory about organisational change management. One of the \nmost well-received training sessions combined classroom-style delivery \n10 The World Wide Web Foundation, (2015). The Open Data Barometer Global Report. 2nd ed, pp.8–9. Available online at: http://\nwww.opendatabarometer.org/assets/downloads/Open%20Data%20Barometer%20-%20Global%20Report%20-%202nd%20\nEdition%20-%20PRINT.pdf [Accessed 2016-04-14].\n\n15 Lessons on supporting public sector open data leadership | Open Data Institute 2016\nwith the opportunity for members to share their experiences in a \npractical way.\n \n“The afternoon session [...] was an opportunity for the participants to work \ntogether and see how beneficial that is. It gave some of the participants \nthe opportunity to speak in their mother tongue and get creative. Many \nparticipants apparently went away with the intention to use this style of \nparticipative teaching within their own countries – this was an unexpected \nproduct of the training session.” \n \n                                                                                          – ODI team member\nManaging membership turnover and job change\n \nThe literature suggests peer networks often have high member turnover rates due to \nindividuals changing jobs, which can be challenging for continuity. However, job change can \nalso positively help to expand a network’s influence.\n11\nThose ODLN members who changed jobs (four of fourteen original members at the time \nof writing) went on to occupy positions where they can influence open data policies while \nremaining engaged with the network. In this instance, high turnover enriches the network. \nHowever, it could pose a challenge if members’ new roles diverge away from open data, to \nthe point where the majority are no longer in a similar field. \n \nFostering network evolution through structures and norms \nConstructing an effective network is an iterative task, which involves developing formal \nstructures, informal norms and defining tasks to guide collective action and accomplish \nshared goals.\n12\n It requires a coordinator or facilitator, with a good understanding of the \n‘science’ of networks, to consolidate the network through preparing, convening and \nsustaining it.\nFor the ODLN, the ODI has taken on the coordination role. After the training week, we \navoided using a top-down approach, as the literature suggests continuing engagement \nneeds to develop organically. Although we joined in conversations via Whatsapp, Twitter \nand Skype, we did not instigate structured engagement. This proved effective as members \n11 Smith et al (2015). As above.\n12 Ibid.\n\n16 Lessons on supporting public sector open data leadership | Open Data Institute 2016\nremain in regular contact, and have not requested a larger coordination role from the ODI. \nIndeed, ODI staff are described as “remarkable co-ordinators and [the] leader of leaders” \n(ODLN survey respondent).\nThe involvement of members from the similar regions has helped to promote ODLN’s \norganic evolution. They can communicate and establish dual-country programmes \nrelatively easily given their similar timezones and cultures. In South America, an effective \ncoalition has formed between some of the ODLN member countries, and there are a group \nof individuals who partner together regularly on regional initiatives. A broader network of \npeople connected to the leaders is coming together, supported through other ODI initiatives \nsuch as ‘Train the Trainer’ and regional open data events, such as the Africa Open Data \nConference.\n \nMapping future membership and network governance \nThere is an appetite for the ODLN to continue: 75% (n:6) of survey respondents stated \nthat they would like more engagement with the network, for example, through further \nopportunities for face-to-face engagement; 25% (n:2) said they would like about the same \nlevel of involvement in the future. Seven members offered to support the ongoing work of the \nnetwork. \n“Continue sharing what we’ve learned and enable other practitioners to \ngain confidence in doing open data work and navigating the uncharted.”\n \n                                                                           – ODLN survey respondents\nThere have been a number of ideas from network participants about how the ODLN can be \ngrown in the future. These include:\n \n•\tHosting in-country, regional, global or inter-cohort meetups\n•\tFacilitating continued ongoing connections through Skype calls, \nwebinars, etc\n•\tMembers producing and sharing one-page briefing papers, or hosting \nthematic discussions\n•\tPursuing further opportunities for training\nUltimately, the ODLN is still an experiment in network-building. We encourage members to \ndevelop their own local chapters, and to connect with ODLN with their existing network.\n \n\n17 Lessons on supporting public sector open data leadership | Open Data Institute 2016\nPeer leadership networks: recommendations\n1. Select initial members of the peer network carefully. Committed \nand energetic members are key to establishing strong networks in their \nformative stages. These might be national, city-level or sector leaders. \nPrior personal contact proved key in identifying people with the right kinds \nof qualities for membership (including the ‘network-thinking’ mindset). As \nnetworks grow and experience turnover, this approach to membership should \nadapt to incorporate new members recommended by existing members, and \nfresh applicants.\n \n \n2. Manage different levels of member experience and backgrounds \nwithin the group sensitively. While the diversity of experience brings a \ncertain richness, it is important to balance differences. The Open Data \nBarometer could be used to classify and understand members’ capacities in \ntheir respective contexts, for example. Accommodate varied learning styles by \nincluding a mixture of theory and practice, and include examples relevant to \ndifferent contexts. Participants should be provided with ample opportunities \nto reflect, and to apply fresh insights through abstract thinking and problem-\nsolving.\n \n3. Build strong foundations for a new network with an intensive \ntraining week. With clear objectives and careful design, intensive training \nweeks can help to facilitate trust, collaboration and network-thinking between \nmembers. They can also provide actions for participants to take back to their \ncountries and implement immediately. Training courses are, however, costly, \nand must be well constructed to justify the investment in time and resources. \nThey also need to be appropriately paced so that members have time to \nattend to their day jobs where necessary. \n \n4. Monitor how network membership evolves. Network membership \nwill inevitably change over time, as members’ roles and positions shift. \nMembers should share comparable functions such that they consider \neach other ‘peers’, and consider the network relevant to their professional \ndevelopment. As networks grow, coordinators should check that the \nmembership base continues to fulfil their original brief, and address significant \nlevels of divergence should this occur.\n\n18 Lessons on supporting public sector open data leadership | Open Data Institute 2016\n5. Collaborate with members in managing the network and making \nfuture plans. For the Open Data Leaders Network, we are planning for a \nfuture where the ODI becomes one partner amongst supporting local and \nregional institutions. We will encourage network members to self-organise, \nengage, and take ownership over the future development of network priorities, \nexpansion and activities. \nOpen data training for civil servants\nWhat is open data training? \nOpen data training – in standards, publishing, change management, licensing, use, \nand policy – can help build the  capacity of civil servants to proactively publish open \ngovernment data and implement impactful open data initiatives.\n13\nAt the ODI, we train civil servants from many country contexts. This takes the form of \nface-to-face, ‘classroom-style’ training and remote or online training, which have varying \nbenefits and weaknesses, depending on how they are delivered and the relationship we \nhave with participants. \nBuilding on our experience in designing open data training courses, we experimented with \ndifferent models for conducting training. These included face-to-face classroom sessions, \nremote or virtual sessions, skills-focused workshops, and coaching.\nTraining topics included the basic principles of open data, how to operationalise and \nemploy open data as a tool for addressing policy challenges, case studies on benefits and \nbusiness models, data science skills and practical aspects of discovery, publication, law \nand licensing. \nLearning outcomes varied from basic understanding of open data, to acquiring specific \nskills for people responsible for publication, to overcoming specific technical challenges \nsuch as licensing.\nWe developed our training methods, content and desired learning outcomes on the basis \nof a training needs assessment. This typically involved conducting an onsite scoping visit, \n13 See, for example, ‘Recommendations for training’ in The Open Data Barometer Global Report, 2nd ed; and Enabling the data \nrevolution: An International Open Data Roadmap (2015). Conference Report. In: 3rd International Open Data Conference. [Online] \nOttawa. Available at: http://1a9vrva76sx19qtvg1ddvt6f.wpengine.netdna-cdn.com/wp-content/uploads/2015/11/opendatacon-\nreport-en-web.pdf [Accessed 2016-04-12]. \n\n19 Lessons on supporting public sector open data leadership | Open Data Institute 2016\na pre-training teleconference call, and a short introductory workshop before delivering a \npackage of different activities over the course of 6-12 months.\nIn Macedonia, we delivered an introductory workshop on open data basics and \nprinciples for senior officials and new data publishers (‘Open data in a day’), a skills-\nbased workshop including data users, civil society, and developers (‘Telling stories \nwith data’), and technical coaching on laws and licensing, delivered remotely.\nIn Tanzania, we conducted an introductory workshop remotely via webinar, an \noffsite workshop on communicating open data and change management for \nthe cross-departmental implementation team (the ‘Open Data Task Force’), and \nstrategic coaching sessions with a small group of senior civil servants to identify \nfuture priorities for their open data initiative.\nIn Burkina Faso, we delivered remote technical coaching on laws and licensing, \nand as in Tanzania, provided strategic coaching sessions to a core team in country \non change management.\nOpen data training for civil servants: key findings \nOverall we found a high demand for training programmes of all types. Where specific \ntraining needs were identified, remote or online training methods are effective and less \ncostly than face-to-face formats. However, remote training alone may not be sufficient \nto build relationships of trust between trainees and trainers, which is important for \ntransforming knowledge into action and behavioural change.\nOur findings below are based on participant feedback surveys, ODI team reflections and \ninterviews with trainers. They are consistent with the literature on public sector change \nmanagement, which suggests that training is an important (but not sufficient) component of \nthe capacity building process.\n14\n \n \nWe have organised our findings to reflect key phases of designing and delivering training, \nincluding: understanding learner needs; selecting delivery formats; ongoing support; and \nassessing outcomes.\n14 Broad, E. et al (2015). Open data in government: how to bring about change. London: Open Data Institute. \n\n20 Lessons on supporting public sector open data leadership | Open Data Institute 2016\nUnderstanding learner needs \nThe training programmes offered to civil servants were tailored to reflect the status \nof their open data initiatives, learning needs, country contexts (such as dynamics \nbetween government and civil society), and the available scale of resources. Solid prior \nunderstanding of the open data issue at hand, the country situation, and the participants’ \nexperience and knowledge, along with sufficient resources to develop, deliver and follow \nup after the training, were key to the success of training according to country team surveys.\n \nSelecting training delivery formats \nOpen data training took place out of country, in-country and virtually. From participant \nfeedback surveys, each option worked effectively. Country teams have reflected that the \ntraining was fully or partially successful in meeting their needs and delivering what it set out \nto do.\n“The trainings were well designed and carried out. The trainers engaged \nthe group effectively thus increasing the efficiency of the trainings through \nactive participation and real life examples.” \n \n                                                            – Country team survey respondent\nRemote training used relatively less programme resources in terms of trainer costs and \ntime. Trainers and participants state that it worked well, and is particularly well-suited to \ntechnical subjects (such as open licensing) where there is information to impart in a didactic \nfashion, rather than in more participative processes to develop behaviours. No technical \nproblems were encountered in our experience, but it is foreseeable that this could be an \nissue in some contexts where internet connection is less reliable. There was a sense of \n‘charisma gap’ at the start of one session, but this quickly dissipated, and there were good \nlevels of interaction between participants and everyone was able to participate fully.\n“As the training progressed they were brainstorming ideas together.” – \nODI Trainer\n\n21 Lessons on supporting public sector open data leadership | Open Data Institute 2016\nOffering ongoing support \nThose teams who underwent training received access to support both before and after \ntheir sessions. However, follow-up support happened mostly on an ad hoc as opposed to \na regular structured basis, with questions and requests posed to the training team as and \nwhen needed. \nOngoing engagement with participants is an area that could receive more focus in future. \nOne of our insights is that investing in leaders requires more than sporadic contact. A \nprocess that engages leaders and their teams over a longer timescale is required to \nmeasure progress and shifting learning needs.\n“We should continue working together to improve [...] Maybe periodical \nmeetings might help, to keep everyone on track.” \n \n                                                            – Country team survey respondent\nAssessing training outcomes\n \nIt is difficult to assess the long-term outcomes of the ODI’s open data training for civil \nservants given its relatively short timescale. However, some short to mid-term reported \nimpacts are as follows.\n•\tMacedonian civil servants made design changes to their open data \nportal to make it more accessible, and applied a Creative Commons \nlicence to their datasets to improve data reusability.\n•\tTanzanian civil servants are reviewing their data policy framework and \nstrategy, with concrete plans to develop a specific open data policy over \nthe next 12 months.\n•\tThe Burkina Open Data Initiative gained recognition as an official project \nof the Burkina Faso government, and has applied a Creative Commons \nlicence to some of its published datasets.\nAs a stand alone intervention, there was low confidence among the ODI team that training \nprogrammes can bring about an open data culture in government. While training might \nform an initial step in the process, it was felt that prolonged and multi-faceted engagement \nbetween teams of civil servants, peers, and experts is required in order to affect behaviour \nchange. Nonetheless bringing people together in a training setting has other benefits: it \nunites teams who are not usually co-located, promotes collaborative work, and imparts \ntechnical information.\n\n22 Lessons on supporting public sector open data leadership | Open Data Institute 2016\nOpen data training for civil servants: recommendations\n1. Conduct a training needs assessment, but also adapt as \ncircumstances change. Opportunities for interaction should be made \navailable to participants before sessions to develop a baseline of training \nneeds. It is also useful for the trainer to be available for follow-up after the \ntraining.\n2. Secure senior sponsorship to ensure outcomes of training \nachieve capacity building goals. Secure the involvement of senior staff \nfrom within the participant’s government to ensure that learning can be \nembedded into team plans, and have a greater chance of being successfully \nimplemented. Try to avoid transitional or busy periods such as elections, as \nthis can affect the momentum to take forward actions agreed through training.\n3. Frame training activities to respond to professional development \ngoals. Training is a familiar concept and an offer that people are likely to \naccept; they may be less likely to attend events described as workshops or \ninformation sharing, for example. Because it is familiar, people feel valued if \nthey are offered training opportunities, particularly if they see it will contribute \nto their professional development and/or lead to some form of certification or \naccreditation.\n4. Combine hard and soft skill development. Vary theoretical \nframeworks and content with practical elements to build soft skills, for \nexample communication techniques to equip civil servants to explain open \ndata to different audiences. Using stories and relatable use cases from similar \ncontexts is also well received, and helps to inspire new ideas and actions.\n5. Deliver ongoing support following a flexible, yet structured \npathway. Investing in individuals requires the trainers to remain in contact, \nwith periodic reviews of progress and ongoing needs. This can be delivered in \nlow-cost ways, such as WebEx online meeting software, or periodic one-on-\none/small group coaching sessions.\n \n\n23 Lessons on supporting public sector open data leadership | Open Data Institute 2016\nStrategic assessments for open data\nWhat are strategic assessments for open data?  \n‘Assessment tools’ are a method for documenting, usually in measurable terms, an \norganisation’s level of knowledge, skills, capacity or performance against predetermined \ncriteria. Strategic assessment tools are typically applied mid-process (that is, during \nimplementation) to reveal a team’s progress towards achieving desired objectives, and \nhighlight opportunities, weaknesses and roadblocks in current approaches.\nAs open data initiatives have expanded around the world, various assessment tools have \nbeen developed to evaluate capabilities to initiate open data policies, legislation, the \nrelease and quality of open datasets, surrounding technology and technical capacity.\nCurrently, most open data initiatives in developing countries follow the World Bank’s Open \nData Readiness Assessment (ODRA) process. Although ODRA provides an initial analysis of \nthe policy environment and current capacities to define first steps towards releasing open \ndata (such as portal design), there is no mechanism for countries to have ongoing progress \nchecks.\n15\n \nWhile the Open Data Barometer and Open Data Index provide helpful comparative analyses \nof impact at a country-level, they do not necessarily assess the level of operational detail \nthat leaders require to overcome implementation barriers. What is missing is a method for \nhelping open data leaders take stock of achievements to date, diagnose ongoing capacity \nor technical gaps, review their project management systems, and refresh their approach in \nresponse to current opportunities. \nWith this in mind, we piloted a new strategic assessment tool for gathering feedback and \nadvice to leaders on the status of their open data initiative. The aim was to equip leaders \nwith useful information to guide internal decision making and planning, but also to help \nthem to identify stories of progress for external communication.\nThe strategic assessment tool\n16\n encompasses multiple dimensions of an open data \ninitiative, including internal capacities, leadership and strategy, team roles and structure, \nexternal engagement and data management systems. \nWe experimented with different modes of delivering the tool in Burkina Faso and Tanzania. \nIn Burkina Faso we followed a highly structured approach, using interviews and small-\ngroup meetings with internal and external stakeholders to gather information, followed by a \n15  Shekhar, S. and Padmanabhan, V. (2016). How to apply assessment tools for shaping successful public sector open data \ninitiatives. London: Open Data Institute\n16  The Open Data Strategic Assessment Tool was developed by the ODI. \n\n24 Lessons on supporting public sector open data leadership | Open Data Institute 2016\npresentation and discussion of our initial findings with the open data team. In Tanzania we \nfollowed a much more fluid approach of informal meetings, small workshops incorporating \nstrategic advice, and a larger discussion forum involving civil society, academic and private \nsector representatives. \nIn both cases the process took approximately five to seven days. This includes planning \ntime with the core open data team, and writing up the results with advice for next steps into \na brief report.\nStrategic assessments for open data: key findings \nOverall, we found the design of the assessment tool itself was comprehensive. Trainers and \ncountry teams alike reported that it introduced a rigorous approach to exploring multiple \ndimensions of an open data initiative. The value was not so much in the technical design \nof the tool in itself, but within the journey of planning the next steps flowing out of the \nassessment with the open data team. \nOur findings are based on participant feedback surveys, ODI team reflections, and \ninterviews with trainers. For ease, we have organised our findings to reflect key phases \nof the strategic assessment process, including: framing the assessment; developing the \nassessment tool; preparing for in-country engagement; and implementing the assessment \ntool.\nFraming the strategic assessment\n \nWithin global development and governance, the term ‘assessment’ is used routinely. \nHowever, the term ‘assessment’ can infer an extractive element. It implies that the country \nis being subjected to a form of testing to see how well they are performing, and that an \nexternal agency is judging them. This can suggest a form of paternalism that may not be \ncompatible with building local leadership.\nIn practice this means that, while rigorous in approach, the assessment tool faces a \nnumber of challenges. Based on ODI team reflection and a literature review of open data \nassessment processes, we observed:\n•\tCountries can see it as something that is being ‘done to them’ and as a \nresult may have little ownership of or interest in the findings.\n•\tThe assessment report can be lengthy and give little in the way of a \nsteer to address priority needs – being faced with a long list of issues \ncan be overwhelming and a barrier to implementation.\n\n25 Lessons on supporting public sector open data leadership | Open Data Institute 2016\n•\tThe lack of a follow-up action planning process aligned to the report \nleaves the responsibility for action primarily with the country and may \nnot lead to significant levels of implementation.\n“Assessment of needs is set with mutual understanding of both parties.” \n \n – Country survey respondent\nThis suggests a need to review how the method is framed (from ‘assessment’ to ‘review \nand refresh’), and to ensure that there is scope for follow-up support.\n \nDeveloping the assessment tool\nFrom the start we set out to ensure the process of developing the assessment tool itself was \niterative, allowing time to deliver, reflect and then adapt the tool based on varied experience. \nWe found sufficient time (4–6 months) was needed to develop the tool, including thorough \nbackground research and working it through with colleagues.\n“It should not be taken as a template, but more as guidelines. You have \nto adapt to what is found on the ground and develop some specific areas \nthat are relevant to the context. Globally it is a great tool to ensure that no \nkey dimensions of an (open data) initiative are forgotten.” \n– ODI facilitator\nPreparing for in-country engagement \nTo be most effective, there should be good knowledge within the team running the \nassessment of the country, current dynamics, policy priorities, and identity of key \nstakeholders. This can be acquired through extensive desk research and through speaking \nwith experts with previous experience of open data in that country.\nIdeally there is also a pre-existing relationship with the open data team. One of the key \nchallenges we experienced was gaining access to key stakeholders for meetings where the \nrelationship was quite new. A combination of prior planning, flexibility and opportunism to \nconstruct the in-country engagement is therefore important.\n“When undertaking the assessment there is a balance to be struck \nbetween making sure that you have identified the key stakeholders in \nadvance so that you are sure you get the right level of input, but there is \nalso a need to adapt when you are there and respond to opportunities that \narise to talk to other people.” \n– ODI team member\n\n26 Lessons on supporting public sector open data leadership | Open Data Institute 2016\nWhen the in-country engagement worked best, it incorporated a combination of some or all \nof the following elements:\n•\tPre-visit, desk-based research\n•\tPre-visit engagement with key individuals, preferably face to face to \nplan meetings\n•\tAt least one week of in-country engagement (combination of meetings \nand workshops)\n•\tAllow free days to allow time for additional interviews and meetings to \nbe set up with key individuals and organisations\nImplementing the assessment tool \nExpertise in open data (both technical and policy elements) is critical for delivering a \nsuccessful assessment. On the ground support is needed to help countries work through \nthe multiple dimensions of the tool, and adapt it to their context. A skilled and experienced \nfacilitator is important to help the team identify the areas that require focus, and work with \nthem to identify achievable actions to take those forward. \n“It’s not about filling in a questionnaire – the assessment tool is a prompt \nthat highlights the areas that need further discussion.” \n                                                                                          –               ODI               facilitator\nHowever, there is a risk the strategic assessment output report itself will be underutilised \nif too lengthy or technical. Making the process more of a dialogue, and narrowing down a \nsmaller list of collectively agreed priorities (eg 2–3) also appears to be more actionable based \non our experience in Burkina Faso. \nStrategic assessments for open data: recommendations\n \n1. Organise the assessment in close co-operation with someone \nwho has sufficient leverage within the government, and secure \ncommitment and interest from high-level officials early. Meetings should be \norganised as a joint activity with the government team, and there should \nbe a clear mandate from a high level official. This helps to ensure greater \nparticipation, and it is more likely actions coming out of the process will be \nimplemented.\n\n27 Lessons on supporting public sector open data leadership | Open Data Institute 2016\n2. Invest in scoping to establish a good prior understanding \nof the local context.  Spending sufficient time in building relationships \nand background research is essential to build trust between the experts \nfacilitating the assessment and the country team, and to deepen \nunderstanding of needs and challenges. Where possible, do at least some of \nthis work face-to-face with the open data leader and other actors, in country. \nScoping has been less successful where it relied on the intelligence of third \nparty organisations.\n3. Incorporate joint prioritisation and action planning, involving \nexperts and the open data leads. Such a joint process of analysis and \nforward planning promotes more ownership of results and action plans. The \nstrategic assessment should become a methodology that co-produces a \nsummary of needs and refines broad strategic direction. This will require a \nre-branding of the tool to describe it as a review or refresh of the open data \ninitiative.\n4. Be flexible to delivery style based on level of engagement \nand maturity level. Employ the tool as a framework, not a template. Not \nall dimensions are relevant to a given country and so flexible application \nis very important. For instance, capacity constrained countries could be \nencouraged to focus on a smaller number of high-priority areas. However \nthere is an argument for at least some standardisation  in terms of process \n– involving scoping,  assessment/review in country, then follow-up support – \nto ensure rigour and to help countries develop a clear pathway.\n5. Facilitate a participatory process including opportunities for \nuser engagement. Workshop-style meetings provide the opportunity for \nopen data leaders and their teams to pause and reflect on their progress, \nor be exposed to different outside perspectives. There is value in providing \nthe space and support for teams to experience this kind of semi-structured \ndialogue. This can help to unearth roadblocks, or unlock innovative new \nsolutions to feed into their strategy. \n\n28 Lessons on supporting public sector open data leadership | Open Data Institute 2016\n4. Learning about cross-cutting issues\nBeyond learning about the effectiveness of individual methods for supporting open data \nleadership, we observed other cross-cutting issues which impact open data initiatives \nrelated to external context and constraints and project management and governance. \nThese are important to consider when designing any open data capacity-building project, \nespecially in developing country contexts. \nExternal context and constraints\n1. The foundations of many open data initiatives remain fragile. \nOpen data portals are now widespread, even in resource-constrained \ncontexts such as Burkina Faso. However, open data initiatives in developing \ncountries are frequently located on the fringe of government activity, not yet \nentrenched in core budgets, and are often perceived as being externally led. \nAll it takes is an election, the loss of a dynamic leader, or the withdrawal of \nexternal support and initiatives risk collapse. Bringing open data initiatives \ninto the central business of government by connecting it to solving policy \nproblems – for example in sectors such as agriculture, health and education \n– is needed to solidify these early foundations.\n2. An empowered local leader driving internal change is necessary, \nbut not enough to embed change. An encouraging six of the eight \nrespondents who completed the ODLN survey say that they have been \nable to partially implement the actions they committed to at the end of the \ninception training. However we have also observed several barriers which \ninhibit an individual leader’s capacity to make deeper inroads. These barriers \nare significant and include change of government, altered government \nspending priorities, and a lack of funding for the initiative. This suggests the \nneed to support a wider group of stakeholders to embrace open data such \nas senior policymakers, finance teams, and Ministers.\n3. Many open data initiatives lack feedback loops between \nusers, intermediaries and producers. Engagement process can be \ndifficult in country contexts where there is an absence of trust between \ngovernment, civil society and intermediaries. There is a need to find the \nright local narrative to motivate open data adoption and use in a way that \nis appropriate for the given context eg innovation, or solving development \nchallenges. Future leadership training should focus on developing \n\n29 Lessons on supporting public sector open data leadership | Open Data Institute 2016\nappropriate business models, narratives, and adapting external engagement \nprocesses.\n4. Clarifying the national data infrastructure is required to manage \nuncertainty. There is widespread uncertainty regarding who ‘owns’ \ndata, how to pay for data, and how to collect and share data internally \nas well as externally to meet the nation’s competing development needs. \nIn many countries the ODI works with, there are multiple data collection \nprocesses operating in isolation, with little overview of the totality of data \nbeing collected, and how the systems could be integrated. A strong open \ndata policy could help to bring clarity and greater confidence around data \npublication and use, both internally and externally. More work to support \ngovernments through the process of strategic assessment and policy \ndevelopment is required going forward.\n \nProject management and governance\n1. Careful country selection, and managing expectations is key. \nWorking in capacity-constrained countries can be challenging. The fact that \nthis was an action research project, testing out different approaches, meant \nthat there was an intrinsic level of uncertainty. To maximise prospects of \nsuccess, we followed a careful country selection process which considered \ncommitment to open data reforms, gaps in open data support, the presence \nof an open data leader or champion/s in a position to effect change, and \nsignificant potential to have a transformative impact on the open data \ninitiative. Where a programme is intended to be experimental in its approach, \ndesigned to invest in pivotal individuals and teams, the degree of risk should \nbe recognised and flexibility permitted to adapt plans as required.\n2. Background research helps minimise risks, but ‘expect the \nunexpected’. Although risk assessment was part of the country selection \nprocess, we could not anticipate all of the changes that were to happen \nduring the lifetime of the programme (such as coups, and civic unrest). \nUndertaking spot risk checks on an ongoing basis was helpful, to monitor \nthe impact of in-country changes on both delivery of the programme and the \nsafety of staff. At times this required decisions to be taken about whether \nspecific activities will continue, and on what timeline. \n\n30 Lessons on supporting public sector open data leadership | Open Data Institute 2016\n3. Look for alternative ways of delivering support which maximise \nexpertise and resources. There is a sense that the overall scale of the \nprogramme was about right – that three countries gave sufficient scope \nto test different approaches in varied situations and contexts, without \nspreading resources too thinly. Approaches that minimised costs proved \neffective, such as delivering training remotely and undertaking as much of \nthe assessment preparation that is possible before country visits. \n4. Draw on a network of partners and experts, including local or \nregionally-based partners, to deliver support. In future there is potential to \ndeliver support through harnessing a broader range of expertise inside and \noutside the ODI, for example in injecting new ODLN content, introducing the \nbusiness perspective, or offering legal expertise. Where there is scope to do \nthis, a diversity of voices can benefit open data leaders by offering different \napproaches to resolving challenges. \n5. Streamline accountability, learning and evaluation processes. As \nthis was an action research project, throughout the year we built in reflective \nactivities with participants and trainers after each core training activity, so \nthat we could adapt activities to follow. This approach proved effective, but \ncould be formalised in future by ensuring participant feedback is shared with \nfuture trainers providing support, and by communicating back to participants \nthe results of their feedback. Having a monitoring, evaluation and learning \nplan from the start of the programme can help. The plan should be reviewed \nand updated frequently to make sure it remains useful.\n \n\n31 Lessons on supporting public sector open data leadership | Open Data Institute 2016\n5. Conclusion \n \nThe future of supporting open data leadership \n \nAs an increasing number of institutions actively publish open data, we need a generation \nof leaders who have a vision for how open data can benefit their country or city, and \nare empowered with the right kinds of skills and social capital to innovate and manage \norganisational change. \nIn 2015 the Open Data Institute sought to explore the idea that a local empowered leader can \ndrive change, by providing three different types of support: access to a peer network, training, \nand strategic assessment. \nLooking back at our original theory of change, a dynamic leader can certainly be instrumental \nin driving open data forward. Yet momentum can be lost if they leave their post, if there is an \nexternal disruption such as an election, or if the policy and institutional foundations of the \nopen data initiative are not secure. \nSupporting leaders and their teams throughout the change management process is key to \nembedding open data as ‘business as usual’. This requires the development of soft skills, not \njust technical skills. It also involves developing an internal culture that encourages risk taking \nand innovation within government. A clearly defined policy and understanding of the broader \ndata infrastructure is also needed to provide a sense of clarity and certainty.\nFrom our overall experience piloting these different methods, we found:\n \n1. Peer networks help boost personal and professional \ndevelopment, but more research is required to understand how to scale \ntheir impact. A peer network (the ‘Open Data Leaders Network’) benefited the \npersonal development of individual members, in particular through enhancing \ntheir social capital and challenging their thinking. More time and research is \nrequired to understand whether this will translate to impact at the institutional \nor national level.\n2. Training programmes for civil servants are one component of \na broader process of capacity building. Face-to-face and virtual training \nmethods worked well for increasing knowledge especially on technical \nsubjects such as licensing. But affecting long-term behavioural and culture \nchange may require a longer term form of multi-faceted engagement built on a \nrelationship of trust between trainees and training partners.\n\n32 Lessons on supporting public sector open data leadership | Open Data Institute 2016\n3. Strategic assessments should be reframed in participatory terms \nto promote ownership of results and follow-up actions. The assessment \ntool we piloted provided rigorous guidelines for structuring a review of a team’s \nongoing progress implementing their open data initiative. Using the tool to \npromote dialogue, reflection, and to generate a list of collectively agreed \npriorities – as opposed to a one-off event – could deepen the outcomes.\n4. Support programmes should incorporate a degree of flexibility, \nand plans should be adapted as external circumstances change. Prior \ncountry scoping in the form of desk research, stakeholder interviews, and \nlearning needs assessment was crucial in tailoring the design of support \nprogrammes. An adaptive and responsive approach is especially important in \nmore fragile operating contexts.\n5. Teams providing leadership support or training activities should \nconduct ongoing reviews of their own effectiveness. Reflecting on \nour own practice throughout the cycle of design and implementation was \nbeneficial to promote continuous learning about how effective methods were. \nIn future, we should standardise this approach, and ensure feedback flows \nbetween participants and the delivery team.\nSeveral questions emerge from our review which requires further exploration:\n•\tWhat is the relationship between policy change or culture change (and \nwhat comes first)? \n•\tHow to evolve from charismatic leadership, so that open data is \nintegrated into systems and can withstand political transitions?\n•\tHow to build on the early successes of the ODLN and scale peer \nnetworks organically?\n•\tWhat are most effective user engagement strategies which can \nstrengthen the feedback loop to motivate greater adoption and use of \nopen data to solve problems?\n \nThese are some of the issues we will be investigating in 2016, as we continue to explore \ndifferent methods of building open data leadership around the world. \nIf you have an idea for network building, are part of a successful peer network, or are \ninterested in finding out more about the ODLN we would love to hear from you. Get in touch \nwith fiona.smith@theodi.org or tweet us at @ODIHQ.\n\n33 Lessons on supporting public sector open data leadership | Open Data Institute 2016\n6. About this report \nThe Open Data Institute (ODI) connects, equips and inspires people around the world to \ninnovate with data. It is independent, nonprofit and nonpartisan, founded in 2012 by Sir Tim \nBerners-Lee and Sir Nigel Shadbolt. From its headquarters in London and via its global \nnetwork of startups, members and nodes, the ODI offers training, research and strategic \nadvice for organisations around the world looking to explore the possibilities of open data.\nThis report was supported by the Open Data for Development (OD4D) programme. OD4D \nis managed by Canada’s International Development Research Centre (IDRC), and it is a \ndonor partnership with the World Bank, the United Kingdom’s Department for International \nDevelopment (DFID) and Global Affairs Canada (GAC). The OD4D network of leading \norganisations are creating locally driven and sustainable open data ecosystems in Latin \nAmerica, the Caribbean, Africa, and Asia and East Europe. OD4D focuses on building up \nthe supply of quality open data, and also on improving the use of that data by leaders in \ngovernment, civil society, the media, and business so that it furthers public interest and \nimproves people’s lives.\nA partnership funded by\n\n34 Lessons on supporting public sector open data leadership | Open Data Institute 2016\n7. Acknowledgements \nWith thanks to the members of the Open Data Leaders Network, the open data teams from \nTanzania, Macedonia, and Burkina Faso, and the ODI team of trainers and consultants (Liz \nCarolan, Richard Stirling, Dawn Duhaney, William Gerry, Emma Truswell, Briony Phillips, Leigh \nDodds, Stephane Boyera, Pierre Chrzanowski) for their invaluable feedback.\nSpecial thanks to Helen Bovey and Nicola Stenberg from Icarus for their evaluation support. \nIcarus is an evaluation, research and facilitation company with a key focus on participation. \nThey designed and facilitated an end of year reflection process to help the ODI synthesise the \nlessons learned contained in this report.\n\n35 Lessons on supporting public sector open data leadership | Open Data Institute 2016\n8. Appendix \nResearch methodology note \nResearch approach \nWe used a mixed method research approach to assess our activities over the course of the \nyear. This involved a combination of evaluation forms (distributed in person directly after \nactivities, and online), participant observation, interviews, and focus group discussions to \nfacilitate reflection. \nTo conduct the final evaluation, we engaged an external consultant, Icarus, to help us \ncollect and analyse results. Icarus employed two surveys: one to ODLN members, and one \nto country team members who had participated in training and/or a strategic assessment. \nIcarus also conducted telephone interviews with ODI trainers and consultants, and facilitated \na focus group discussion with the core ODI team responsible for implementing the support \nprogramme.\n \nResearch questions\nThe survey of ODLN members asked:\n•\tWhat was your role with regards to open data at the time you attended \nthe ODLN training? Are you still in the same role?\n•\tWhat was your experience engaging with the ODI as a whole?\n•\tWhat was the most notable point/take-away from participating in the \nODLN?\n•\tWhat aspects of the ODLN, if any, have been most helpful to you in \ndoing your job?\n•\tTo what extent have you been able to implement the action/s you \ncommitted to at the end of the training?\n•\tTo what extent have you been able to implement the action/s you \ncommitted to at the end of the training?\n•\tTo what extent have you taken part in the network since attending the \ntraining?\n•\tTo what extent have you found membership of and ongoing \n\n36 Lessons on supporting public sector open data leadership | Open Data Institute 2016\nengagement with the ODLN useful?\n•\tOverall, what have been the personal benefits to you of being involved \nin the ODLN?\n•\tOverall, what have been the benefits for your team/department/\ngovernment as a result of you being involved in the ODLN?\n \nThe survey of country team members who participated in training and/or strategic \nassessments asked:\n•\tHow accurate or otherwise do you think the assessment of needs \nproduced by the ODI was?\n•\tTo what extent do you think there was a good alignment between the \nassessment of needs and the training and/or support you received from \nthe ODI?\n•\tHow closely did the training you received from the ODI meet the needs \nof your team/department/government?\n•\tTo what extent was the training provided by the ODI successful in \ndelivering what we expected it to do?\n•\tOverall, what have been the personal benefits to you of being involved \nin this programme with the ODI?\n•\tWhat significant changes around open data, if any, have happened as a \ndirect result of your engagement with the ODI?\n•\tHow confident are you that engaging the programme will make a lasting \ndifference to your team/department/country?\n \nThe interviews with ODI trainers and consultants addressed:\n•\tHow effective was the format of the training provided (virtual, face to \nface etc)?\n•\tTo what extent do you think the training met the local needs?\n•\tWere there sufficient resources to design and deliver the training \neffectively?\n•\tWhat worked well about the training you delivered?\n•\tWere there any aspects of the training that, in retrospect, you would \n\n37 Lessons on supporting public sector open data leadership | Open Data Institute 2016\nhave changed? What are the optimal conditions for facilitating training \nto public servants?\n•\tWhat worked well about the strategic assessment tool – how effective \nwas it in capturing a full picture of the country’s needs?\n•\tWhat improvements would make the assessment tool more useable \nand/or effective?\n•\tWhat are the optimal conditions for conducting open data strategic \nassessments?\n•\tWas the country scoping/selection process effective? Did it result in the \nright kinds of countries receiving the support package?\n•\tTo what extent did in country issues (eg staff changes, elections) and \ninstability impact on the delivery of the programme? How could these \nhave been mitigated against, if at all?\n•\tWere there sufficient/appropriate governance arrangements in place for \nthe programme as a whole?\n \nResearch methodology note \nProfile of respondents to ODLN survey \nWe received 10 surveys responses (out of 14 invitations sent)  from Nigeria, Tanzania, \nMacedonia, Mexico, Argentina, Moldova, Romania, New Zealand, and one not specified. \nFrom the ODLN survey respondents:\n70% (n:7) describe themselves as leading the open data initiative at country level\n20% (n:2) describe themselves as leading the open data initiative at city level\n10% (n:1) describe themselves as open data initiative co-ordinator\n80% (n:8) are still in the same role as when they joined the ODLN\n20% (n:2) are no longer in the same role but both still have open data responsibilities in \ntheir new position\n \nProfile of respondents to country programme surveys  \nWe received five survey responses from the core open data teams in Macedonia (2) and \nBurkina Faso (3), but no country team survey responses were received from Tanzania. \n\n38 Lessons on supporting public sector open data leadership | Open Data Institute 2016\nThese survey responses were supplemented by a desk review of:\n•\tparticipant evaluation forms from ODLN cohorts (1 and 2), submitted \ndirectly after the inception training week\n•\tnotes from ODI team retrospectives on ODLN, training and strategic \nassessment, conducted within one month of implementing activities\n•\ttraining evaluation forms from Macedonia, Tanzania and Burkina Faso, \nsubmitted directly after training activities\nProfile of respondents to trainer interviews\n \nWe conducted semi-structured telephone interviews with trainers David Tarrant, Leigh \nDodds, Melanie Dulong, Briony Phillips. Written feedback against the interview questions \nwas received from Pierre Chrzanowski. Lastly, a focus group was held with five members of \nthe core ODI team.\n \nLimitations \n \nThe mixed methods were designed to be robust, and were undertaken by Icarus to provide \nan independent perspective on the findings. The advantages of this approach include an \nindependent perspective, working with experienced evaluators and analysts, while fitting \nwithin an overall framework to provide a consistent approach.\nHowever, limitations include: the independent research was summative rather than \nformative (happening at the end of the programme rather than throughout), the programme \nteam from Tanzania did not participate in the online survey, the small sample sizes from \nthe countries may mean that the results are partial and as a result there is little scope for \ntriangulation of the data where opinions differ. \nFurthermore, our research only focused on the ODI’s direct inputs. Given that country \nprogrammes and individual leaders typically receive support from multiple sources, it is \ndifficult to directly attribute results or isolate the ODI’s contribution from other inputs.\n\n39 Lessons on supporting public sector open data leadership | Open Data Institute 2016\n8. Bibliography \nBroad, E., Smith, F., Duhaney, D., and Carolan, L. (2015). Open data in government: how to \nbring about change. London: Open Data Institute.\nCarolan, L. (2015). Small teams, big ideas. [Blog] World Bank Data Blog. Available at: http://\nblogs.worldbank.org/opendata/small-teams-big-ideas-open-data-ambition-runs-start-ups-\ngovernments [Accessed 2016-04-14].\nEnabling the data revolution: An International Open Data Roadmap (2015). Conference \nReport. In: 3rd International Open Data Conference. [Online] Ottawa. Available at: \nhttp://1a9vrva76sx19qtvg1ddvt6f.wpengine.netdna-cdn.com/wp-content/uploads/2015/11/\nopendatacon-report-en-web.pdf [Accessed 2016-04-12].  \nKeely, B. (2007). Human Capital: How what you know shapes your life. OECD Insights, \nParis, OECD Publishing.\nKirkpatrick, D. L. (1998). Evaluating training programs: The four levels. 2nd ed. San \nFrancisco: Berrett-Koehler Publishers.\nRogers, E. M. (1962). Diffusion of innovations. Glencoe: Free Press. \nShekhar, S. and Padmanabhan, V. (2016). How to apply assessment tools for shaping \nsuccessful public sector open data initiatives. London: Open Data Institute.\nSmith, F., Harvey, B., and Gerry, W. (2016). How to create and sustain peer networks for \nopen data leaders. London: Open Data Institute.\nThe World Wide Web Foundation, (2015). The Open Data Barometer Global Report. 2nd ed. \nAvailable online at: http://www.opendatabarometer.org/assets/downloads/Open%20Data%20\nBarometer%20-%20Global%20Report%20-%202nd%20Edition%20-%20PRINT.pdf \n[Accessed 2016-04-14].\n\n","version":"1.10.100"}